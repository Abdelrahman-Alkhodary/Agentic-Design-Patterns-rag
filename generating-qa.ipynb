{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b5951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "full_text = ''\n",
    "\n",
    "with open(\"./data/processed/Agentic_Design_Patterns.mmd\", \"r\") as f:\n",
    "    full_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f256c901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: 214275 characters\n",
      "Part 2: 214275 characters\n",
      "Part 3: 214275 characters\n",
      "Part 4: 214278 characters\n"
     ]
    }
   ],
   "source": [
    "def split_into_four_parts(text: str):\n",
    "    length = len(text)\n",
    "    part_size = length // 4  # integer division\n",
    "\n",
    "    parts = [\n",
    "        text[i * part_size : (i + 1) * part_size]\n",
    "        for i in range(3)  # first 3 parts\n",
    "    ]\n",
    "\n",
    "    # last part takes the remainder\n",
    "    parts.append(text[3 * part_size:])\n",
    "\n",
    "    return parts\n",
    "\n",
    "\n",
    "# Example\n",
    "parts = split_into_four_parts(full_text)\n",
    "\n",
    "for i, p in enumerate(parts, start=1):\n",
    "    print(f\"Part {i}: {len(p)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a63344ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./prompts/rag_validation_openai.yml\") as f:\n",
    "    prompts = yaml.safe_load(f)\n",
    "\n",
    "system_prompt = prompts[\"rag_validation_prompt\"][\"system_template\"].format(\n",
    "    text_book=p\n",
    ")\n",
    "user_prompt   = prompts[\"rag_validation_prompt\"][\"user_template\"].format(\n",
    "    num_questions=10,\n",
    "    role=\"student\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc085045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert synthetic data generator for evaluating Retrieval-Augmented Generation (RAG) systems built on top of technical books.\n",
      "Your job is to produce high-quality, deeply grounded, human-sounding technical questions and their correct answers.\n",
      "\n",
      "BOOK PASSAGE (Use this as your ONLY source):\n",
      "  tterns.- Example: Classify the sentiment of the following movie reviews as POSITIVE, NEUTRAL, or\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NEGATIVE:  \n",
      "\n",
      "\n",
      "Review: \"The acting was superb and the story was engaging.\" Sentiment: POSITIVE  \n",
      "\n",
      "\n",
      "Review: \"It was okay, nothing special.\" Sentiment: NEUTRAL  \n",
      "\n",
      "\n",
      "Review: \"I found the plot confusing and the characters unlikable.\" Sentiment: NEGATIVE  \n",
      "\n",
      "\n",
      "Review: \"The visuals were stunning, but the dialogue was weak.\" Sentiment:  \n",
      "\n",
      "\n",
      "Understanding when to apply zero- shot, one- shot, and few- shot prompting techniques, and thoughtfully crafting and organizing examples, are essential for enhancing the effectiveness of agentic systems. These basic methods serve as the groundwork for various prompting strategies.  \n",
      "\n",
      "\n",
      "## Structuring Prompts  \n",
      "\n",
      "\n",
      "Beyond the basic techniques of providing examples, the way you structure your prompt plays a critical role in guiding the language model. Structuring involves using different sections or elements within the prompt to provide distinct types of information, such as instructions, context, or examples, in a clear and organized manner. This helps the model parse the prompt correctly and understand the specific role of each piece of text.  \n",
      "\n",
      "\n",
      "## System Prompting  \n",
      "\n",
      "\n",
      "System prompting sets the overall context and purpose for a language model, defining its intended behavior for an interaction or session. This involves providing instructions or background information that establish rules, a persona, or overall behavior. Unlike specific user queries, a system prompt provides foundational guidelines for the model's responses. It influences the model's tone, style, and general approach throughout the interaction. For example, a system prompt can instruct the model to consistently respond concisely and helpfully or ensure responses are appropriate for a general audience. System prompts are also utilized for safety and toxicity control by including guidelines such as maintaining respectful language.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Furthermore, to maximize their effectiveness, system prompts can undergo automatic prompt optimization through LLM- based iterative refinement. Services like the Vertex AI Prompt Optimizer facilitate this by systematically improving prompts based on user- defined metrics and target data, ensuring the highest possible performance for a given task.  \n",
      "\n",
      "\n",
      "## Example:  \n",
      "\n",
      "\n",
      "You are a helpful and harmless AI assistant. Respond to all queries in a polite and informative manner. Do not generate content that is harmful, biased, or inappropriate  \n",
      "\n",
      "\n",
      "## Role Prompting  \n",
      "\n",
      "\n",
      "Role prompting assigns a specific character, persona, or identity to the language model, often in conjunction with system or contextual prompting. This involves instructing the model to adopt the knowledge, tone, and communication style associated with that role. For example, prompts such as \"Act as a travel guide\" or \"You are an expert data analyst\" guide the model to reflect the perspective and expertise of that assigned role. Defining a role provides a framework for the tone, style, and focused expertise, aiming to enhance the quality and relevance of the output. The desired style within the role can also be specified, for instance, \"a humorous and inspirational style.\"  \n",
      "\n",
      "\n",
      "## Example:  \n",
      "\n",
      "\n",
      "Act as a seasoned travel blogger. Write a short, engaging paragraph about the best hidden gem in Rome.  \n",
      "\n",
      "\n",
      "## Using Delimiters  \n",
      "\n",
      "\n",
      "Effective prompting involves clear distinction of instructions, context, examples, and input for language models. Delimiters, such as triple backticks (\\\\`\\\\`\\\\`), XML tags (\\\\`<instruction\\>, \\\\`<context\\>), or markers (--), can be utilized to visually and programmatically separate these sections. This practice, widely used in prompt engineering, minimizes misinterpretation by the model, ensuring clarity regarding the role of each part of the prompt.  \n",
      "\n",
      "\n",
      "## Example:  \n",
      "\n",
      "\n",
      "<instruction>Summarize the following article, focusing on the main arguments presented by the author.</instruction> <article> [Insert the full text of the article here] </article>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Contextual Enginnering  \n",
      "\n",
      "\n",
      "Contextual EnginneringContext engineering, unlike static system prompts, dynamically provides background information crucial for tasks and conversations. This ever- changing information helps models grasp nuances, recall past interactions, and integrate relevant details, leading to grounded responses and smoother exchanges. Examples include previous dialogue, relevant documents (as in Retrieval Augmented Generation), or specific operational parameters. For instance, when discussing a trip to Japan, one might ask for three family- friendly activities in Tokyo, leveraging the existing conversational context. In agentic systems, context engineering is fundamental to core agent behaviors like memory persistence, decision- making, and coordination across sub- tasks. Agents with dynamic contextual pipelines can sustain goals over time, adapt strategies, and collaborate seamlessly with other agents or tools—qualities essential for long- term autonomy. This methodology posits that the quality of a model's output depends more on the richness of the provided context than on the model's architecture. It signifies a significant evolution from traditional prompt engineering, which primarily focused on optimizing the phrasing of immediate user queries. Context engineering expands its scope to include multiple layers of information.  \n",
      "\n",
      "\n",
      "These layers include:  \n",
      "\n",
      "\n",
      "System prompts: Foundational instructions that define the Al's operational parameters (e.g., \"You are a technical writer; your tone must be formal and precise\"). External data:  \n",
      "\n",
      "\n",
      "- External data:    \n",
      "- Retrieved documents: Information actively fetched from a knowledge base to inform responses (e.g., pulling technical specifications).    \n",
      "- Tool outputs: Results from the AI using an external API for real-time data (e.g., querying a calendar for availability).  \n",
      "\n",
      "\n",
      "The core principle is that even advanced models underperform with a limited or poorly constructed view of their operational environment. This practice reframes the task from merely answering a question to building a comprehensive operational picture for the agent. For example, a context- engineered agent would integrate a user's calendar\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "availability (tool output), the professional relationship with an email recipient (implicit data), and notes from previous meetings (retrieved documents) before responding to a query. This enables the model to generate highly relevant, personalized, and pragmatically useful outputs. The \"engineering\" aspect involves creating robust pipelines to fetch and transform this data at runtime and establishing feedback loops to continually improve context quality.  \n",
      "\n",
      "\n",
      "To implement this, specialized tuning systems, such as Google's Vertex AI prompt optimizer, can automate the improvement process at scale. By systematically evaluating responses against sample inputs and predefined metrics, these tools can enhance model performance and adapt prompts and system instructions across different models without extensive manual rewriting. Providing an optimizer with sample prompts, system instructions, and a template allows it to programmatically refine contextual inputs, offering a structured method for implementing the necessary feedback loops for sophisticated Context Engineering.  \n",
      "\n",
      "\n",
      "This structured approach differentiates a rudimentary AI tool from a more sophisticated, contextually- aware system. It treats context as a primary component, emphasizing what the agent knows, when it knows it, and how it uses that information. This practice ensures the model has a well- rounded understanding of the user's intent, history, and current environment. Ultimately, Context Engineering is a crucial methodology for transforming stateless chatbots into highly capable, situationally- aware systems.  \n",
      "\n",
      "\n",
      "## Structured Output  \n",
      "\n",
      "\n",
      "Often, the goal of prompting is not just to get a free- form text response, but to extract or generate information in a specific, machine- readable format. Requesting structured output, such as JSON, XML, CSV, or Markdown tables, is a crucial structuring technique. By explicitly asking for the output in a particular format and potentially providing a schema or example of the desired structure, you guide the model to organize its response in a way that can be easily parsed and used by other parts of your agentic system or application. Returning JSON objects for data extraction is beneficial as it forces the model to create a structure and can limit hallucinations. Experimenting with output formats is recommended, especially for non- creative tasks like extracting or categorizing data.  \n",
      "\n",
      "\n",
      "## Example:  \n",
      "\n",
      "\n",
      "Extract the following information from the text below and return it as a JSON object with keys \"name\", \"address\", and \"phone_number\".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Text: \"Contact John Smith at 123 Main St, Anytown, CA or call (555) 123- 4567.\"  \n",
      "\n",
      "\n",
      "Effectively utilizing system prompts, role assignments, contextual information, delimiters, and structured output significantly enhances the clarity, control, and utility of interactions with language models, providing a strong foundation for developing reliable agentic systems. Requesting structured output is crucial for creating pipelines where the language model's output serves as the input for subsequent system or processing steps.  \n",
      "\n",
      "\n",
      "Leveraging Pydantic for an Object- Oriented Facade: A powerful technique for enforcing structured output and enhancing interoperability is to use the LLM's generated data to populate instances of Pydantic objects. Pydantic is a Python library for data validation and settings management using Python type annotations. By defining a Pydantic model, you create a clear and enforceable schema for your desired data structure. This approach effectively provides an object- oriented facade to the prompt's output, transforming raw text or semi- structured data into validated, type- hinted Python objects.  \n",
      "\n",
      "\n",
      "You can directly parse a JSON string from an LLM into a Pydantic object using the model_validate_json method. This is particularly useful as it combines parsing and validation in a single step.  \n",
      "\n",
      "\n",
      "from pydantic import BaseModel, EmailStr, Field, ValidationError from typing import List, Optional from datetime import date  \n",
      "\n",
      "\n",
      "\\`\\`\\`python# --- Pydantic Model Definition (from above) ---class User(BaseModel):    name: str = Field(... , description=\"The full name of the user.\")    email: EmailStr = Field(... , description=\"The user's email address.\")    date_of_birth: Optional[date] = Field(None, description=\"The user's date of birth.\")    interests: List[str] = Field(default_factory=list, description=\"A list of the user's interests.\")\\`\\`\\`  \n",
      "\n",
      "\n",
      "\\`\\`\\`python# --- Hypothetical LLM Output ---llm_output_json = \"\"\"{    \"name\": \"Alice Wonderland\",    \"email\": \"alice.w@example.com\",    \"date_of_birth\": \"1995-07-21\",}\\`\\`\\`\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"interests\": [  \"Natural Language Processing\",  \"Python Programming\",  \"Gardening\"  ]  }  }  # --- Parsing and Validation -- try:  # Use the model_validate_json class method to parse the JSON string.  # This single step parses the JSON and validates the data against the User model.  user_object = User.model_validate_json(llm_output_json)  # Now you can work with a clean, type-safe Python object.  print(\"Successfully created User object!\")  print(f\"Name: {user_object.name}\")  print(f\"Email: {user_object.email}\")  print(f\"Date of Birth: {user_object.date_of_birth}\")  print(f\"First Interest: {user_object.interests[0]}\")  # You can access the data like any other Python object attribute.  # Pydantic has already converted the 'date_of_birth' string to a datetime.date object.  print(f\"Type of date_of_birth: {type(user_object.date_of_birth)}\")  except ValidationError as e:  # If the JSON is malformed or the data doesn't match the model's types,  # Pydantic will raise a ValidationError.  print(\"Failed to validate JSON from LLM.\")  print(e)  \n",
      "\n",
      "\n",
      "This Python code demonstrates how to use the Pydantic library to define a data model and validate JSON data. It defines a User model with fields for name, email, date of birth, and interests, including type hints and descriptions. The code then parses a hypothetical JSON output from a Large Language Model (LLM) using the model_validate_json method of the User model. This method handles both JSON parsing and data validation according to the model's structure and types. Finally, the\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "code accesses the validated data from the resulting Python object and includes error handling for ValidationError in case the JSON is invalid.  \n",
      "\n",
      "\n",
      "For XML data, the xmldotid library can be used to convert the XML into a dictionary, which can then be passed to a Pydantic model for parsing. By using Field aliases in your Pydantic model, you can seamlessly map the often verbose or attribute- heavy structure of XML to your object's fields.  \n",
      "\n",
      "\n",
      "This methodology is invaluable for ensuring the interoperability of LLM- based components with other parts of a larger system. When an LLM's output is encapsulated within a Pydantic object, it can be reliably passed to other functions, APIs, or data processing pipelines with the assurance that the data conforms to the expected structure and types. This practice of \"parse, don't validate\" at the boundaries of your system components leads to more robust and maintainable applications.  \n",
      "\n",
      "\n",
      "Effectively utilizing system prompts, role assignments, contextual information, delimiters, and structured output significantly enhances the clarity, control, and utility of interactions with language models, providing a strong foundation for developing reliable agentic systems. Requesting structured output is crucial for creating pipelines where the language model's output serves as the input for subsequent system or processing steps.  \n",
      "\n",
      "\n",
      "Structuring Prompts Beyond the basic techniques of providing examples, the way you structure your prompt plays a critical role in guiding the language model. Structuring involves using different sections or elements within the prompt to provide distinct types of information, such as instructions, context, or examples, in a clear and organized manner. This helps the model parse the prompt correctly and understand the specific role of each piece of text.  \n",
      "\n",
      "\n",
      "## Reasoning and Thought Process Techniques  \n",
      "\n",
      "\n",
      "Large language models excel at pattern recognition and text generation but often face challenges with tasks requiring complex, multi- step reasoning. This appendix focuses on techniques designed to enhance these reasoning capabilities by encouraging models to reveal their internal thought processes. Specifically, it addresses methods to improve logical deduction, mathematical computation, and planning.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Chain of Thought (CoT)  \n",
      "\n",
      "\n",
      "The Chain of Thought (CoT) prompting technique is a powerful method for improving the reasoning abilities of language models by explicitly prompting the model to generate intermediate reasoning steps before arriving at a final answer. Instead of just asking for the result, you instruct the model to \"think step by step.\" This process mirrors how a human might break down a problem into smaller, more manageable parts and work through them sequentially.  \n",
      "\n",
      "\n",
      "CoT helps the LLM generate more accurate answers, particularly for tasks that require some form of calculation or logical deduction, where models might otherwise struggle and produce incorrect results. By generating these intermediate steps, the model is more likely to stay on track and perform the necessary operations correctly.  \n",
      "\n",
      "\n",
      "There are two main variations of CoT:  \n",
      "\n",
      "\n",
      "- Zero-Shot CoT: This involves simply adding the phrase \"Let's think step by step\" (or similar phrasing) to your prompt without providing any examples of the reasoning process. Surprisingly, for many tasks, this simple addition can significantly improve the model's performance by triggering its ability to expose its internal reasoning trace.  \n",
      "- Example (Zero-Shot CoT): If a train travels at 60 miles per hour and covers a distance of 240 miles, how long did the journey take? Let's think step by step.  \n",
      "\n",
      "\n",
      "- Few-Shot CoT: This combines CoT with few-shot prompting. You provide the model with several examples where both the input, the step-by-step reasoning process, and the final output are shown. This gives the model a clearer template for how to perform the reasoning and structure its response, often leading to even better results on more complex tasks compared to zero-shot CoT.  \n",
      "\n",
      "\n",
      "- Example (Few-Shot CoT):  \n",
      "\n",
      "\n",
      "Q: The sum of three consecutive integers is 36. What are the integers?  \n",
      "\n",
      "\n",
      "A: Let the first integer be \\(x\\) . The next consecutive integer is \\(x + 1\\) , and the third is \\(x + 2\\) . The sum is \\(x + (x + 1) + (x + 2) = 3x + 3\\) . We know the sum is 36, so \\(3x + 3 = 36\\) . Subtract 3 from both sides: \\(3x = 33\\) . Divide by 3: \\(x = 11\\) . The integers are 11, \\(11 + 1 = 12\\) , and \\(11 + 2 = 13\\) . The integers are 11, 12, and 13.  \n",
      "\n",
      "\n",
      "Q: Sarah has 5 apples, and she buys 8 more. She eats 3 apples. How many apples does she have left? Let's think step by step.  \n",
      "\n",
      "\n",
      "A: Let's think step by step. Sarah starts with 5 apples. She buys 8 more, so she\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "adds 8 to her initial amount: \\(5 + 8 = 13\\) apples. Then, she eats 3 apples, so we subtract 3 from the total: \\(13 - 3 = 10\\) . Sarah has 10 apples left. The answer is 10.  \n",
      "\n",
      "\n",
      "CoT offers several advantages. It is relatively low- effort to implement and can be highly effective with off- the- shelf LLMs without requiring fine- tuning. A significant benefit is the increased interpretability of the model's output; you can see the reasoning steps it followed, which helps in understanding why it arrived at a particular answer and in debugging if something went wrong. Additionally, CoT appears to improve the robustness of prompts across different versions of language models, meaning the performance is less likely to degrade when a model is updated. The main disadvantage is that generating the reasoning steps increases the length of the output, leading to higher token usage, which can increase costs and response time.  \n",
      "\n",
      "\n",
      "Best practices for CoT include ensuring the final answer is presented after the reasoning steps, as the generation of the reasoning influences the subsequent token predictions for the answer. Also, for tasks with a single correct answer (like mathematical problems), setting the model's temperature to 0 (greedy decoding) is recommended when using CoT to ensure deterministic selection of the most probable next token at each step.  \n",
      "\n",
      "\n",
      "## Self-Consistency  \n",
      "\n",
      "\n",
      "Building on the idea of Chain of Thought, the Self- Consistency technique aims to improve the reliability of reasoning by leveraging the probabilistic nature of language models. Instead of relying on a single greedy reasoning path (as in basic CoT), Self- Consistency generates multiple diverse reasoning paths for the same problem and then selects the most consistent answer among them.  \n",
      "\n",
      "\n",
      "Self- Consistency involves three main steps:  \n",
      "\n",
      "\n",
      "1. Generating Diverse Reasoning Paths: The same prompt (often a CoT prompt) is sent to the LLM multiple times. By using a higher temperature setting, the model is encouraged to explore different reasoning approaches and generate varied step-by-step explanations.  \n",
      "2. Extract the Answer: The final answer is extracted from each of the generated reasoning paths.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3. Choose the Most Common Answer: A majority vote is performed on the extracted answers. The answer that appears most frequently across the diverse reasoning paths is selected as the final, most consistent answer.  \n",
      "\n",
      "\n",
      "This approach improves the accuracy and coherence of responses, particularly for tasks where multiple valid reasoning paths might exist or where the model might be prone to errors in a single attempt. The benefit is a pseudo- probability likelihood of the answer being correct, increasing overall accuracy. However, the significant cost is the need to run the model multiple times for the same query, leading to much higher computation and expense.  \n",
      "\n",
      "\n",
      "## Example (Conceptual):  \n",
      "\n",
      "\n",
      "- Example (Conceptual):  \n",
      "- Prompt: \"Is the statement 'All birds can fly' true or false? Explain your reasoning.\"  \n",
      "- Model Run 1 (High Temp): Reasons about most birds flying, concludes True.  \n",
      "- Model Run 2 (High Temp): Reasons about penguins and ostriches, concludes False.  \n",
      "- Model Run 3 (High Temp): Reasons about birds in general, mentions exceptions briefly, concludes True.  \n",
      "- Self-Consistency Result: Based on majority vote (True appears twice), the final answer is \"True\". (Note: A more sophisticated approach would weigh the reasoning quality).  \n",
      "\n",
      "\n",
      "## Step-Back Prompting  \n",
      "\n",
      "\n",
      "Step- back prompting enhances reasoning by first asking the language model to consider a general principle or concept related to the task before addressing specific details. The response to this broader question is then used as context for solving the original problem.  \n",
      "\n",
      "\n",
      "This process allows the language model to activate relevant background knowledge and wider reasoning strategies. By focusing on underlying principles or higher- level abstractions, the model can generate more accurate and insightful answers, less influenced by superficial elements. Initially considering general factors can provide a stronger basis for generating specific creative outputs. Step- back prompting encourages critical thinking and the application of knowledge, potentially mitigating biases by emphasizing general principles.  \n",
      "\n",
      "\n",
      "## Example:  \n",
      "\n",
      "\n",
      "- Example:  \n",
      "- Prompt 1 (Step- Back): \"What are the key factors that make a good detective story?\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Model Response 1: (Lists elements like red herrings, compelling motive, flawed protagonist, logical clues, satisfying resolution).- Prompt 2 (Original Task + Step-Back Context): \"Using the key factors of a good detective story [insert Model Response 1 here], write a short plot summary for a new mystery novel set in a small town.\"  \n",
      "\n",
      "\n",
      "## Tree of Thoughts (ToT)  \n",
      "\n",
      "\n",
      "Tree of Thoughts (ToT) is an advanced reasoning technique that extends the Chain of Thought method. It enables a language model to explore multiple reasoning paths concurrently, instead of following a single linear progression. This technique utilizes a tree structure, where each node represents a \"thought\"—a coherent language sequence acting as an intermediate step. From each node, the model can branch out, exploring alternative reasoning routes.  \n",
      "\n",
      "\n",
      "ToT is particularly suited for complex problems that require exploration, backtracking, or the evaluation of multiple possibilities before arriving at a solution. While more computationally demanding and intricate to implement than the linear Chain of Thought method, ToT can achieve superior results on tasks necessitating deliberate and exploratory problem- solving. It allows an agent to consider diverse perspectives and potentially recover from initial errors by investigating alternative branches within the \"thought tree.\"  \n",
      "\n",
      "\n",
      "- Example (Conceptual): For a complex creative writing task like \"Develop three different possible endings for a story based on these plot points,\" ToT would allow the model to explore distinct narrative branches from a key turning point, rather than just generating one linear continuation.  \n",
      "\n",
      "\n",
      "These reasoning and thought process techniques are crucial for building agents capable of handling tasks that go beyond simple information retrieval or text generation. By prompting models to expose their reasoning, consider multiple perspectives, or step back to general principles, we can significantly enhance their ability to perform complex cognitive tasks within agentic systems.  \n",
      "\n",
      "\n",
      "## Action and Interaction Techniques  \n",
      "\n",
      "\n",
      "Intelligent agents possess the capability to actively engage with their environment, beyond generating text. This includes utilizing tools, executing external functions, and participating in iterative cycles of observation, reasoning, and action. This section examines prompting techniques designed to enable these active behaviors.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Tool Use / Function Calling  \n",
      "\n",
      "\n",
      "A crucial ability for an agent is using external tools or calling functions to perform actions beyond its internal capabilities. These actions may include web searches, database access, sending emails, performing calculations, or interacting with external APIs. Effective prompting for tool use involves designing prompts that instruct the model on the appropriate timing and methodology for tool utilization.  \n",
      "\n",
      "\n",
      "Modern language models often undergo fine- tuning for \"function calling\" or \"tool use.\" This enables them to interpret descriptions of available tools, including their purpose and parameters. Upon receiving a user request, the model can determine the necessity of tool use, identify the appropriate tool, and format the required arguments for its invocation. The model does not execute the tool directly. Instead, it generates a structured output, typically in JSON format, specifying the tool and its parameters. An agentic system then processes this output, executes the tool, and provides the tool's result back to the model, integrating it into the ongoing interaction.  \n",
      "\n",
      "\n",
      "## Example:  \n",
      "\n",
      "\n",
      "You have access to a weather tool that can get the current weather for a specified city. The tool is called 'get_current_weather' and takes a 'city' parameter (string).  \n",
      "\n",
      "\n",
      "User: What's the weather like in London right now?  \n",
      "\n",
      "\n",
      "- Expected Model Output (Function Call): {  \"tool_code\": \"get_current_weather\",  \"tool_name\": \"get_current_weather\",  \"parameters\": {  \"city\": \"London\"  }  \n",
      "\n",
      "\n",
      "## ReAct (Reason & Act)  \n",
      "\n",
      "\n",
      "ReAct, short for Reason and Act, is a prompting paradigm that combines Chain of Thought- style reasoning with the ability to perform actions using tools in an interleaved manner. ReAct mimics how humans operate – we reason verbally and take actions to gather more information or make progress towards a goal.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The ReAct pattern involves a loop:  \n",
      "\n",
      "\n",
      "1. Thought: The model generates a thought process, explaining its current understanding and plan.  \n",
      "2. Action: Based on the thought, the model decides to perform an action, often using a tool (e.g., Search, Calculator, API call). It outputs the name of the tool and the required input.  \n",
      "3. Observation: The agentic system executes the tool and provides the result (Observation) back to the model.  \n",
      "4. The loop continues with the model generating a new \"Thought\" based on the latest \"Observation,\" leading to further \"Actions\" and \"Observations\" until the task is complete and the model outputs a \"Final Answer.\"  \n",
      "\n",
      "\n",
      "This interleaved process of thinking and acting allows the agent to dynamically gather information, react to tool outputs, and refine its approach, making it particularly effective for tasks requiring interaction with dynamic environments or external knowledge sources.  \n",
      "\n",
      "\n",
      "## Example (Illustrative ReAct Trace):  \n",
      "\n",
      "\n",
      "User: What is the capital of France and its current population?  \n",
      "\n",
      "\n",
      "Thought: The user is asking for two pieces of information: the capital of France and its population. I can use a search tool to find this information. I will start by confirming the capital, although I am likely to know it. Action: Search({\"query\": \"capital of France\"})  \n",
      "\n",
      "\n",
      "Observation: Paris  \n",
      "\n",
      "\n",
      "Thought: Okay, the capital is Paris. Now I need to find the population of Paris. Action: Search({\"query\": \"current population of Paris\"}) Observation: The population of Paris was estimated to be around 2.1 million people in 2023.  \n",
      "\n",
      "\n",
      "Thought: I have found both pieces of information. I can now provide the final answer to the user. Final Answer: The capital of France is Paris, and its estimated population in 2023 was around 2.1 million people.  \n",
      "\n",
      "\n",
      "These techniques are vital for building agents that can actively engage with the world, retrieve real- time information, and perform tasks that require interacting with external systems.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Advanced Techniques  \n",
      "\n",
      "\n",
      "Beyond the foundational, structural, and reasoning patterns, there are several other prompting techniques that can further enhance the capabilities and efficiency of agentic systems. These range from using AI to optimize prompts to incorporating external knowledge and tailoring responses based on user characteristics.  \n",
      "\n",
      "\n",
      "## Automatic Prompt Engineering (APE)  \n",
      "\n",
      "\n",
      "Recognizing that crafting effective prompts can be a complex and iterative process, Automatic Prompt Engineering (APE) explores using language models themselves to generate, evaluate, and refine prompts. This method aims to automate the prompt writing process, potentially enhancing model performance without requiring extensive human effort in prompt design.  \n",
      "\n",
      "\n",
      "The general idea is to have a \"meta- model\" or a process that takes a task description and generates multiple candidate prompts. These prompts are then evaluated based on the quality of the output they produce on a given set of inputs (perhaps using metrics like BLEU or ROUGE, or human evaluation). The best- performing prompts can be selected, potentially refined further, and used for the target task. Using an LLM to generate variations of a user query for training a chatbot is an example of this.  \n",
      "\n",
      "\n",
      "- Example (Conceptual): A developer provides a description: \"I need a prompt that can extract the date and sender from an email.\" An APE system generates several candidate prompts. These are tested on sample emails, and the prompt that consistently extracts the correct information is selected.  \n",
      "\n",
      "\n",
      "Of course. Here is a rephrased and slightly expanded explanation of programmatic prompt optimization using frameworks like DSPy:  \n",
      "\n",
      "\n",
      "Another powerful prompt optimization technique, notably promoted by the DSPy framework, involves treating prompts not as static text but as programmatic modules that can be automatically optimized. This approach moves beyond manual trial- and- error and into a more systematic, data- driven methodology.  \n",
      "\n",
      "\n",
      "The core of this technique relies on two key components:  \n",
      "\n",
      "\n",
      "1. A Goldset (or High-Quality Dataset): This is a representative set of high-quality input-and-output pairs. It serves as the \"ground truth\" that defines what a successful response looks like for a given task.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2. An Objective Function (or Scoring Metric): This is a function that automatically evaluates the LLM's output against the corresponding \"golden\" output from the dataset. It returns a score indicating the quality, accuracy, or correctness of the response.  \n",
      "\n",
      "\n",
      "Using these components, an optimizer, such as a Bayesian optimizer, systematically refines the prompt. This process typically involves two main strategies, which can be used independently or in concert:  \n",
      "\n",
      "\n",
      "- Few-Shot Example Optimization: Instead of a developer manually selecting examples for a few-shot prompt, the optimizer programmatically samples different combinations of examples from the goldset. It then tests these combinations to identify the specific set of examples that most effectively guides the model toward generating the desired outputs.  \n",
      "\n",
      "\n",
      "- Instructional Prompt Optimization: In this approach, the optimizer automatically refines the prompt's core instructions. It uses an LLM as a \"meta-model\" to iteratively mutate and rephrase the prompt's text—adjusting the wording, tone, or structure—to discover which phrasing yields the highest scores from the objective function.  \n",
      "\n",
      "\n",
      "The ultimate goal for both strategies is to maximize the scores from the objective function, effectively \"training\" the prompt to produce results that are consistently closer to the high- quality goldset. By combining these two approaches, the system can simultaneously optimize what instructions to give the model and which examples to show it, leading to a highly effective and robust prompt that is machine- optimized for the specific task.  \n",
      "\n",
      "\n",
      "## Iterative Prompting / Refinement  \n",
      "\n",
      "\n",
      "This technique involves starting with a simple, basic prompt and then iteratively refining it based on the model's initial responses. If the model's output isn't quite right, you analyze the shortcomings and modify the prompt to address them. This is less about an automated process (like APE) and more about a human- driven iterative design loop.  \n",
      "\n",
      "\n",
      "## Example:  \n",
      "\n",
      "\n",
      "- Attempt 1: \"Write a product description for a new type of coffee maker.\" (Result is too generic).- Attempt 2: \"Write a product description for a new type of coffee maker. Highlight its speed and ease of cleaning.\" (Result is better, but lacks detail).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Attempt 3: \"Write a product description for the 'SpeedClean Coffee Pro'. Emphasize its ability to brew a pot in under 2 minutes and its self-cleaning cycle. Target busy professionals.\" (Result is much closer to desired).  \n",
      "\n",
      "\n",
      "## Providing Negative Examples  \n",
      "\n",
      "\n",
      "While the principle of \"Instructions over Constraints\" generally holds true, there are situations where providing negative examples can be helpful, albeit used carefully. A negative example shows the model an input and an undesired output, or an input and an output that should not be generated. This can help clarify boundaries or prevent specific types of incorrect responses.  \n",
      "\n",
      "\n",
      "## Example:  \n",
      "\n",
      "\n",
      "Generate a list of popular tourist attractions in Paris. Do NOT include the Eiffel Tower.  \n",
      "\n",
      "\n",
      "Example of what NOT to do: Input: List popular landmarks in Paris. Output: The Eiffel Tower, The Louvre, Notre Dame Cathedral.  \n",
      "\n",
      "\n",
      "## Using Analogies  \n",
      "\n",
      "\n",
      "Framing a task using an analogy can sometimes help the model understand the desired output or process by relating it to something familiar. This can be particularly useful for creative tasks or explaining complex roles.  \n",
      "\n",
      "\n",
      "## Example:  \n",
      "\n",
      "\n",
      "Act as a \"data chef\". Take the raw ingredients (data points) and prepare a \"summary dish\" (report) that highlights the key flavors (trends) for a business audience.  \n",
      "\n",
      "\n",
      "## Factored Cognition / Decomposition  \n",
      "\n",
      "\n",
      "For very complex tasks, it can be effective to break down the overall goal into smaller, more manageable sub- tasks and prompt the model separately on each sub- task. The results from the sub- tasks are then combined to achieve the final outcome. This is related to prompt chaining and planning but emphasizes the deliberate decomposition of the problem.  \n",
      "\n",
      "\n",
      "Example: To write a research paper:  \n",
      "\n",
      "\n",
      "- Prompt 1: \"Generate a detailed outline for a paper on the impact of AI on the job market.\"- Prompt 2: \"Write the introduction section based on this outline: [insert outline intro].\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Prompt 3: \"Write the section on 'Impact on White-Collar Jobs' based on this outline: [insert outline section].\" (Repeat for other sections).- Prompt N: \"Combine these sections and write a conclusion.\"  \n",
      "\n",
      "\n",
      "## Retrieval Augmented Generation (RAG)  \n",
      "\n",
      "\n",
      "RAG is a powerful technique that enhances language models by giving them access to external, up- to- date, or domain- specific information during the prompting process. When a user asks a question, the system first retrieves relevant documents or data from a knowledge base (e.g., a database, a set of documents, the web). This retrieved information is then included in the prompt as context, allowing the language model to generate a response grounded in that external knowledge. This mitigates issues like hallucination and provides access to information the model wasn't trained on or that is very recent. This is a key pattern for agentic systems that need to work with dynamic or proprietary information.  \n",
      "\n",
      "\n",
      "## Example:  \n",
      "\n",
      "\n",
      "- Example:- User Query: \"What are the new features in the latest version of the Python library 'X'?\"- System Action: Search a documentation database for \"Python library X latest features\".- Prompt to LLM: \"Based on the following documentation snippets: [insert retrieved text], explain the new features in the latest version of Python library 'X'.\"  \n",
      "\n",
      "\n",
      "## Persona Pattern (User Persona):  \n",
      "\n",
      "\n",
      "While role prompting assigns a persona to the model, the Persona Pattern involves describing the user or the target audience for the model's output. This helps the model tailor its response in terms of language, complexity, tone, and the kind of information it provides.  \n",
      "\n",
      "\n",
      "## Example:  \n",
      "\n",
      "\n",
      "You are explaining quantum physics. The target audience is a high school student with no prior knowledge of the subject. Explain it simply and use analogies they might understand.  \n",
      "\n",
      "\n",
      "Explain quantum physics: [Insert basic explanation request]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "These advanced and supplementary techniques provide further tools for prompt engineers to optimize model behavior, integrate external information, and tailor interactions for specific users and tasks within agentic workflows.  \n",
      "\n",
      "\n",
      "## Using Google Gems  \n",
      "\n",
      "\n",
      "Google's AI \"Gems\" (see Fig. 1) represent a user- configurable feature within its large language model architecture. Each \"Gem\" functions as a specialized instance of the core Gemini AI, tailored for specific, repeatable tasks. Users create a Gem by providing it with a set of explicit instructions, which establishes its operational parameters. This initial instruction set defines the Gem's designated purpose, response style, and knowledge domain. The underlying model is designed to consistently adhere to these pre- defined directives throughout a conversation.  \n",
      "\n",
      "\n",
      "This allows for the creation of highly specialized AI agents for focused applications. For example, a Gem can be configured to function as a code interpreter that only references specific programming libraries. Another could be instructed to analyze data sets, generating summaries without speculative commentary. A different Gem might serve as a translator adhering to a particular formal style guide. This process creates a persistent, task- specific context for the artificial intelligence.  \n",
      "\n",
      "\n",
      "Consequently, the user avoids the need to re- establish the same contextual information with each new query. This methodology reduces conversational redundancy and improves the efficiency of task execution. The resulting interactions are more focused, yielding outputs that are consistently aligned with the user's initial requirements. This framework allows for applying fine- grained, persistent user direction to a generalist AI model. Ultimately, Gems enable a shift from general- purpose interaction to specialized, pre- defined AI functionalities.\n",
      "\n",
      "\n",
      "\n",
      "![](images/0.jpg)\n",
      "\n",
      "\n",
      "<center>Fig.1: Example of Google Gem usage. </center>  \n",
      "\n",
      "\n",
      "## Using LLMs to Refine Prompts (The Meta Approach)  \n",
      "\n",
      "\n",
      "We've explored numerous techniques for crafting effective prompts, emphasizing clarity, structure, and providing context or examples. This process, however, can be iterative and sometimes challenging. What if we could leverage the very power of large language models, like Gemini, to help us improve our prompts? This is the essence of using LLMs for prompt refinement – a \"meta\" application where AI assists in optimizing the instructions given to AI.  \n",
      "\n",
      "\n",
      "This capability is particularly \"cool\" because it represents a form of AI self- improvement or at least AI- assisted human improvement in interacting with AI. Instead of solely relying on human intuition and trial- and- error, we can tap into the LLM's understanding of language, patterns, and even common prompting pitfalls to\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "get suggestions for making our prompts better. It turns the LLM into a collaborative partner in the prompt engineering process.  \n",
      "\n",
      "\n",
      "How does this work in practice? You can provide a language model with an existing prompt that you're trying to improve, along with the task you want it to accomplish and perhaps even examples of the output you're currently getting (and why it's not meeting your expectations). You then prompt the LLM to analyze the prompt and suggest improvements.  \n",
      "\n",
      "\n",
      "A model like Gemini, with its strong reasoning and language generation capabilities, can analyze your existing prompt for potential areas of ambiguity, lack of specificity, or inefficient phrasing. It can suggest incorporating techniques we've discussed, such as adding delimiters, clarifying the desired output format, suggesting a more effective persona, or recommending the inclusion of few- shot examples.  \n",
      "\n",
      "\n",
      "The benefits of this meta- prompting approach include:  \n",
      "\n",
      "\n",
      "- Accelerated Iteration: Get suggestions for improvement much faster than pure manual trial and error.- Identification of Blind Spots: An LLM might spot ambiguities or potential misinterpretations in your prompt that you overlooked.- Learning Opportunity: By seeing the types of suggestions the LLM makes, you can learn more about what makes prompts effective and improve your own prompt engineering skills.- Scalability: Potentially automate parts of the prompt optimization process, especially when dealing with a large number of prompts.  \n",
      "\n",
      "\n",
      "It's important to note that the LLM's suggestions are not always perfect and should be evaluated and tested, just like any manually engineered prompt. However, it provides a powerful starting point and can significantly streamline the refinement process.  \n",
      "\n",
      "\n",
      "## Example Prompt for Refinement:  \n",
      "\n",
      "\n",
      "Analyze the following prompt for a language model and suggest ways to improve it to consistently extract the main topic and key entities (people, organizations, locations) from news articles. The current prompt sometimes misses entities or gets the main topic wrong.  \n",
      "\n",
      "\n",
      "Existing Prompt:  \n",
      "\n",
      "\n",
      "\"Summarize the main points and list important names and places from this article: [insert article text]\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Suggestions for Improvement:  \n",
      "\n",
      "\n",
      "In this example, we're using the LLM to critique and enhance another prompt. This meta- level interaction demonstrates the flexibility and power of these models, allowing us to build more effective agentic systems by first optimizing the fundamental instructions they receive. It's a fascinating loop where AI helps us talk better to AI.  \n",
      "\n",
      "\n",
      "## Prompting for Specific Tasks  \n",
      "\n",
      "\n",
      "While the techniques discussed so far are broadly applicable, some tasks benefit from specific prompting considerations. These are particularly relevant in the realm of code and multimodal inputs.  \n",
      "\n",
      "\n",
      "## Code Prompting  \n",
      "\n",
      "\n",
      "Language models, especially those trained on large code datasets, can be powerful assistants for developers. Prompting for code involves using LLMs to generate, explain, translate, or debug code. Various use cases exist:  \n",
      "\n",
      "\n",
      "- Prompts for writing code: Asking the model to generate code snippets or functions based on a description of the desired functionality.    \n",
      "- Example: \"Write a Python function that takes a list of numbers and returns the average.\"- Prompts for explaining code: Providing a code snippet and asking the model to explain what it does, line by line or in a summary.    \n",
      "- Example: \"Explain the following JavaScript code snippet: [insert code].\"- Prompts for translating code: Asking the model to translate code from one programming language to another.    \n",
      "- Example: \"Translate the following Java code to C++: [insert code].\"- Prompts for debugging and reviewing code: Providing code that has an error or could be improved and asking the model to identify issues, suggest fixes, or provide refactoring suggestions.    \n",
      "- Example: \"The following Python code is giving a 'NameError'. What is wrong and how can I fix it? [insert code and traceback].\"  \n",
      "\n",
      "\n",
      "Effective code prompting often requires providing sufficient context, specifying the desired language and version, and being clear about the functionality or issue.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Multimodal Prompting  \n",
      "\n",
      "\n",
      "While the focus of this appendix and much of current LLM interaction is text- based, the field is rapidly moving towards multimodal models that can process and generate information across different modalities (text, images, audio, video, etc.). Multimodal prompting involves using a combination of inputs to guide the model. This refers to using multiple input formats instead of just text.  \n",
      "\n",
      "\n",
      "- Example: Providing an image of a diagram and asking the model to explain the process shown in the diagram (Image Input + Text Prompt). Or providing an image and asking the model to generate a descriptive caption (Image Input + Text Prompt \\(\\rightarrow\\) Text Output).  \n",
      "\n",
      "\n",
      "As multimodal capabilities become more sophisticated, prompting techniques will evolve to effectively leverage these combined inputs and outputs.  \n",
      "\n",
      "\n",
      "## Best Practices and Experimentation  \n",
      "\n",
      "\n",
      "Becoming a skilled prompt engineer is an iterative process that involves continuous learning and experimentation. Several valuable best practices are worth reiterating and emphasizing:  \n",
      "\n",
      "\n",
      "- Provide Examples: Providing one or few-shot examples is one of the most effective ways to guide the model.- Design with Simplicity: Keep your prompts concise, clear, and easy to understand. Avoid unnecessary jargon or overly complex phrasing.- Be Specific about the Output: Clearly define the desired format, length, style, and content of the model's response.- Use Instructions over Constraints: Focus on telling the model what you want it to do rather than what you don't want it to do.- Control the Max Token Length: Use model configurations or explicit prompt instructions to manage the length of the generated output.- Use Variables in Prompts: For prompts used in applications, use variables to make them dynamic and reusable, avoiding hardcoding specific values.- Experiment with Input Formats and Writing Styles: Try different ways of phrasing your prompt (question, statement, instruction) and experiment with different tones or styles to see what yields the best results.- For Few-Shot Prompting with Classification Tasks, Mix Up the Classes: Randomize the order of examples from different categories to prevent overfitting.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Adapt to Model Updates: Language models are constantly being updated. Be prepared to test your existing prompts on new model versions and adjust them to leverage new capabilities or maintain performance.- Experiment with Output Formats: Especially for non-creative tasks, experiment with requesting structured output like JSON or XML.- Experiment Together with Other Prompt Engineers: Collaborating with others can provide different perspectives and lead to discovering more effective prompts.- CoT Best Practices: Remember specific practices for Chain of Thought, such as placing the answer after the reasoning and setting temperature to 0 for tasks with a single correct answer.- Document the Various Prompt Attempts: This is crucial for tracking what works, what doesn't, and why. Maintain a structured record of your prompts, configurations, and results.- Save Prompts in Codebases: When integrating prompts into applications, store them in separate, well-organized files for easier maintenance and version control.- Rely on Automated Tests and Evaluation: For production systems, implement automated tests and evaluation procedures to monitor prompt performance and ensure generalization to new data.  \n",
      "\n",
      "\n",
      "Prompt engineering is a skill that improves with practice. By applying these principles and techniques, and by maintaining a systematic approach to experimentation and documentation, you can significantly enhance your ability to build effective agentic systems.  \n",
      "\n",
      "\n",
      "## Conclusion  \n",
      "\n",
      "\n",
      "This appendix provides a comprehensive overview of prompting, reframing it as a disciplined engineering practice rather than a simple act of asking questions. Its central purpose is to demonstrate how to transform general- purpose language models into specialized, reliable, and highly capable tools for specific tasks. The journey begins with non- negotiable core principles like clarity, conciseness, and iterative experimentation, which are the bedrock of effective communication with AI. These principles are critical because they reduce the inherent ambiguity in natural language, helping to steer the model's probabilistic outputs toward a single, correct intention. Building on this foundation, basic techniques such as zero- shot, one- shot, and few- shot prompting serve as the primary methods for demonstrating expected behavior through examples. These methods provide varying levels of contextual guidance, powerfully shaping the model's response style, tone, and format. Beyond just examples, structuring prompts with explicit roles, system- level instructions, and\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "clear delimiters provides an essential architectural layer for fine- grained control over the model.  \n",
      "\n",
      "\n",
      "The importance of these techniques becomes paramount in the context of building autonomous agents, where they provide the control and reliability necessary for complex, multi- step operations. For an agent to effectively create and execute a plan, it must leverage advanced reasoning patterns like Chain of Thought and Tree of Thoughts. These sophisticated methods compel the model to externalize its logical steps, systematically breaking down complex goals into a sequence of manageable sub- tasks. The operational reliability of the entire agentic system hinges on the predictability of each component's output. This is precisely why requesting structured data like JSON, and programmatically validating it with tools such as Pydantic, is not a mere convenience but an absolute necessity for robust automation. Without this discipline, the agent's internal cognitive components cannot communicate reliably, leading to catastrophic failures within an automated workflow. Ultimately, these structuring and reasoning techniques are what successfully convert a model's probabilistic text generation into a deterministic and trustworthy cognitive engine for an agent.  \n",
      "\n",
      "\n",
      "Furthermore, these prompts are what grant an agent its crucial ability to perceive and act upon its environment, bridging the gap between digital thought and real- world interaction. Action- oriented frameworks like ReAct and native function calling are the vital mechanisms that serve as the agent's hands, allowing it to use tools, query APIs, and manipulate data. In parallel, techniques like Retrieval Augmented Generation (RAG) and the broader discipline of Context Engineering function as the agent's senses. They actively retrieve relevant, real- time information from external knowledge bases, ensuring the agent's decisions are grounded in current, factual reality. This critical capability prevents the agent from operating in a vacuum, where it would be limited to its static and potentially outdated training data. Mastering this full spectrum of prompting is therefore the definitive skill that elevates a generalist language model from a simple text generator into a truly sophisticated agent, capable of performing complex tasks with autonomy, awareness, and intelligence.  \n",
      "\n",
      "\n",
      "## References  \n",
      "\n",
      "\n",
      "Here is a list of resources for further reading and deeper exploration of prompt engineering techniques:  \n",
      "\n",
      "\n",
      "1. Prompt Engineering, https://www.kaggle.com/whitepaper-prompt-engineering\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models, https://arxiv.org/abs/2201.11903  \n",
      "3. Self-Consistency Improves Chain of Thought Reasoning in Language Models, https://arxiv.org/pdf/2203.11171  \n",
      "4. ReAct: Synergizing Reasoning and Acting in Language Models, https://arxiv.org/abs/2210.03629  \n",
      "5. Tree of Thoughts: Deliberate Problem Solving with Large Language Models, https://arxiv.org/pdf/2305.10601  \n",
      "6. Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models, https://arxiv.org/abs/2310.06117  \n",
      "7. DSPy: Programming—not prompting—Foundation Models https://github.com/stanfordnlp/dspy\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Appendix B - AI Agentic Interactions: From GUI to Real World environment  \n",
      "\n",
      "\n",
      "Al agents are increasingly performing complex tasks by interacting with digital interfaces and the physical world. Their ability to perceive, process, and act within these varied environments is fundamentally transforming automation, human- computer interaction, and intelligent systems. This appendix explores how agents interact with computers and their environments, highlighting advancements and projects.  \n",
      "\n",
      "\n",
      "## Interaction: Agents with Computers  \n",
      "\n",
      "\n",
      "The evolution of Al from conversational partners to active, task- oriented agents is being driven by Agent- Computer Interfaces (ACIs). These interfaces allow Al to interact directly with a computer's Graphical User Interface (GUI), enabling it to perceive and manipulate visual elements like icons and buttons just as a human would. This new method moves beyond the rigid, developer- dependent scripts of traditional automation that relied on APIs and system calls. By using the visual \"front door\" of software, Al can now automate complex digital tasks in a more flexible and powerful way, a process that involves several key stages:  \n",
      "\n",
      "\n",
      "- Visual Perception: The agent first captures a visual representation of the screen, essentially taking a screenshot.- GUI Element Recognition: It then analyzes this image to distinguish between various GUI elements. It must learn to \"see\" the screen not as a mere collection of pixels, but as a structured layout with interactive components, discerning a clickable \"Submit\" button from a static banner image or an editable text field from a simple label.- Contextual Interpretation: The ACI module, acting as a bridge between the visual data and the agent's core intelligence (often a Large Language Model or LLM), interprets these elements within the context of the task. It understands that a magnifying glass icon typically means \"search\" or that a series of radio buttons represents a choice. This module is crucial for enhancing the LLM's reasoning, allowing it to form a plan based on visual evidence.- Dynamic Action and Response: The agent then programmatically controls the mouse and keyboard to execute its plan—clicking, typing, scrolling, and dragging. Critically, it must constantly monitor the screen for visual feedback,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dynamically responding to changes, loading screens, pop- up notifications, or errors to successfully navigate multi- step workflows.  \n",
      "\n",
      "\n",
      "This technology is no longer theoretical. Several leading AI labs have developed functional agents that demonstrate the power of GUI interaction:  \n",
      "\n",
      "\n",
      "ChatGPT Operator (OpenAI): Envisioned as a digital partner, ChatGPT Operator is designed to automate tasks across a wide range of applications directly from the desktop. It understands on- screen elements, enabling it to perform actions like transferring data from a spreadsheet into a customer relationship management (CRM) platform, booking a complex travel itinerary across airline and hotel websites, or filling out detailed online forms without needing specialized API access for each service. This makes it a universally adaptable tool aimed at boosting both personal and enterprise productivity by taking over repetitive digital chores.  \n",
      "\n",
      "\n",
      "Google Project Mariner: As a research prototype, Project Mariner operates as an agent within the Chrome browser (see Fig. 1). Its purpose is to understand a user's intent and autonomously carry out web- based tasks on their behalf. For example, a user could ask it to find three apartments for rent within a specific budget and neighborhood; Mariner would then navigate to real estate websites, apply the filters, browse the listings, and extract the relevant information into a document. This project represents Google's exploration into creating a truly helpful and \"agentive\" web experience where the browser actively works for the user.  \n",
      "\n",
      "![](images/0.jpg)\n",
      "\n",
      "\n",
      "<center>Fig.1: Interaction between and Agent and the Web Browser </center>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Anthropic's Computer Use: This feature empowers Anthropic's AI model, Claude, to become a direct user of a computer's desktop environment. By capturing screenshots to perceive the screen and programmatically controlling the mouse and keyboard, Claude can orchestrate workflows that span multiple, unconnected applications. A user could ask it to analyze data in a PDF report, open a spreadsheet application to perform calculations on that data, generate a chart, and then paste that chart into an email draft—a sequence of tasks that previously required constant human input.  \n",
      "\n",
      "\n",
      "Browser Use: This is an open- source library that provides a high- level API for programmatic browser automation. It enables AI agents to interface with web pages by granting them access to and control over the Document Object Model (DOM). The API abstracts the intricate, low- level commands of browser control protocols, into a more simplified and intuitive set of functions. This allows an agent to perform complex sequences of actions, including data extraction from nested elements, form submissions, and automated navigation across multiple pages. As a result, the library facilitates the transformation of unstructured web data into a structured format that an AI agent can systematically process and utilize for analysis or decision- making.  \n",
      "\n",
      "\n",
      "## Interaction: Agents with the Environment  \n",
      "\n",
      "\n",
      "Beyond the confines of a computer screen, AI agents are increasingly designed to interact with complex, dynamic environments, often mirroring the real world. This requires sophisticated perception, reasoning, and actuation capabilities.  \n",
      "\n",
      "\n",
      "Google's Project Astra is a prime example of an initiative pushing the boundaries of agent interaction with the environment. Astra aims to create a universal AI agent that is helpful in everyday life, leveraging multimodal inputs (sight, sound, voice) and outputs to understand and interact with the world contextually. This project focuses on rapid understanding, reasoning, and response, allowing the agent to \"see\" and \"hear\" its surroundings through cameras and microphones and engage in natural conversation while providing real- time assistance. Astra's vision is an agent that can seamlessly assist users with tasks ranging from finding lost items to debugging code, by understanding the environment it observes. This moves beyond simple voice commands to a truly embodied understanding of the user's immediate physical context.  \n",
      "\n",
      "\n",
      "Google's Gemini Live, transforms standard AI interactions into a fluid and dynamic conversation. Users can speak to the AI and receive responses in a natural- sounding voice with minimal delay, and can even interrupt or change topics mid- sentence, prompting the AI to adapt immediately. The interface expands beyond voice, allowing\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "users to incorporate visual information by using their phone's camera, sharing their screen, or uploading files for a more context- aware discussion. More advanced versions can even perceive a user's tone of voice and intelligently filter out irrelevant background noise to better understand the conversation. These capabilities combine to create rich interactions, such as receiving live instructions on a task by simply pointing a camera at it.  \n",
      "\n",
      "\n",
      "OpenAl's GPT- 4o model is an alternative designed for \"omni\" interaction, meaning it can reason across voice, vision, and text. It processes these inputs with low latency that mirrors human response times, which allows for real- time conversations. For example, users can show the Al a live video feed to ask questions about what is happening, or use it for language translation. OpenAI provides developers with a \"Realtime API\" to build applications requiring low- latency, speech- to- speech interactions.  \n",
      "\n",
      "\n",
      "OpenAl's ChatGPT Agent represents a significant architectural advancement over its predecessors, featuring an integrated framework of new capabilities. Its design incorporates several key functional modalities: the capacity for autonomous navigation of the live internet for real- time data extraction, the ability to dynamically generate and execute computational code for tasks like data analysis, and the functionality to interface directly with third- party software applications. The synthesis of these functions allows the agent to orchestrate and complete complex, sequential workflows from a singular user directive. It can therefore autonomously manage entire processes, such as performing market analysis and generating a corresponding presentation, or planning logistical arrangements and executing the necessary transactions. In parallel with the launch, OpenAI has proactively addressed the emergent safety considerations inherent in such a system. An accompanying \"System Card\" delineates the potential operational hazards associated with an Al capable of performing actions online, acknowledging the new vectors for misuse. To mitigate these risks, the agent's architecture includes engineered safeguards, such as requiring explicit user authorization for certain classes of actions and deploying robust content filtering mechanisms. The company is now engaging its initial user base to further refine these safety protocols through a feedback- driven, iterative process.  \n",
      "\n",
      "\n",
      "Seeing Al, a complimentary mobile application from Microsoft, empowers individuals who are blind or have low vision by offering real- time narration of their surroundings. The app leverages artificial intelligence through the device's camera to identify and describe various elements, including objects, text, and even people. Its core functionalities encompass reading documents, recognizing currency, identifying\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "products through barcodes, and describing scenes and colors. By providing enhanced access to visual information, Seeing AI ultimately fosters greater independence for visually impaired users.  \n",
      "\n",
      "\n",
      "Anthropic's Claude 4 Series Anthropic's Claude 4 is another alternative with capabilities for advanced reasoning and analysis. Though historically focused on text, Claude 4 includes robust vision capabilities, allowing it to process information from images, charts, and documents. The model is suited for handling complex, multi- step tasks and providing detailed analysis. While the real- time conversational aspect is not its primary focus compared to other models, its underlying intelligence is designed for building highly capable AI agents.  \n",
      "\n",
      "\n",
      "## Vibe Coding: Intuitive Development with AI  \n",
      "\n",
      "\n",
      "Beyond direct interaction with GUIs and the physical world, a new paradigm is emerging in how developers build software with AI: \"vibe coding.\" This approach moves away from precise, step- by- step instructions and instead relies on a more intuitive, conversational, and iterative interaction between the developer and an AI coding assistant. The developer provides a high- level goal, a desired \"vibe,\" or a general direction, and the AI generates code to match.  \n",
      "\n",
      "\n",
      "This process is characterized by:  \n",
      "\n",
      "\n",
      "- Conversational Prompts: Instead of writing detailed specifications, a developer might say, \"Create a simple, modern-looking landing page for a new app,\" or, \"Refactor this function to be more Pythonic and readable.\" The AI interprets the \"vibe\" of \"modern\" or \"Pythonic\" and generates the corresponding code.- Iterative Refinement: The initial output from the AI is often a starting point. The developer then provides feedback in natural language, such as, \"That's a good start, but can you make the buttons blue?\" or, \"Add some error handling to that.\" This back-and-forth continues until the code meets the developer's expectations.- Creative Partnership: In vibe coding, the AI acts as a creative partner, suggesting ideas and solutions that the developer may not have considered. This can accelerate the development process and lead to more innovative outcomes.- Focus on \"What\" not \"How\": The developer focuses on the desired outcome (the \"what\") and leaves the implementation details (the \"how\") to the AI. This\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "allows for rapid prototyping and exploration of different approaches without getting bogged down in boilerplate code.  \n",
      "\n",
      "\n",
      "- Optional Memory Banks: To maintain context across longer interactions, developers can use \"memory banks\" to store key information, preferences, or constraints. For example, a developer might save a specific coding style or a set of project requirements to the AI's memory, ensuring that future code generations remain consistent with the established \"vibe\" without needing to repeat the instructions.  \n",
      "\n",
      "\n",
      "Vibe coding is becoming increasingly popular with the rise of powerful AI models like GPT- 4, Claude, and Gemini, which are integrated into development environments. These tools are not just auto- completing code; they are actively participating in the creative process of software development, making it more accessible and efficient. This new way of working is changing the nature of software engineering, emphasizing creativity and high- level thinking over rote memorization of syntax and APIs.  \n",
      "\n",
      "\n",
      "## Key takeaways  \n",
      "\n",
      "\n",
      "- AI agents are evolving from simple automation to visually controlling software through graphical user interfaces, much like a human would.- The next frontier is real-world interaction, with projects like Google's Astra using cameras and microphones to see, hear, and understand their physical surroundings.- Leading technology companies are converging these digital and physical capabilities to create universal AI assistants that operate seamlessly across both domains.- This shift is creating a new class of proactive, context-aware AI companions capable of assisting with a vast range of tasks in users' daily lives.  \n",
      "\n",
      "\n",
      "## Conclusion  \n",
      "\n",
      "\n",
      "Agents are undergoing a significant transformation, moving from basic automation to sophisticated interaction with both digital and physical environments. By leveraging visual perception to operate Graphical User Interfaces, these agents can now manipulate software just as a human would, bypassing the need for traditional APIs. Major technology labs are pioneering this space with agents capable of automating complex, multi- application workflows directly on a user's desktop. Simultaneously, the next frontier is expanding into the physical world, with initiatives like Google's Project Astra using cameras and microphones to contextually engage with their surroundings.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "These advanced systems are designed for multimodal, real- time understanding that mirrors human interaction.  \n",
      "\n",
      "\n",
      "These advanced systems are designed for multimodal, real- time understanding that mirrors human interaction.The ultimate vision is a convergence of these digital and physical capabilities, creating universal AI assistants that operate seamlessly across all of a user's environments. This evolution is also reshaping software creation itself through \"vibe coding,\" a more intuitive and conversational partnership between developers and AI. This new method prioritizes high- level goals and creative intent, allowing developers to focus on the desired outcome rather than implementation details. This shift accelerates development and fosters innovation by treating AI as a creative partner. Ultimately, these advancements are paving the way for a new era of proactive, context- aware AI companions capable of assisting with a vast array of tasks in our daily lives.  \n",
      "\n",
      "\n",
      "## References  \n",
      "\n",
      "\n",
      "1. Open AI Operator, https://openai.com/index/introducing-operator/  \n",
      "2. Open AI ChatGPT Agent: https://openai.com/index/introducing-chatgpt-agent/  \n",
      "3. Browser Use: https://docs.browser-use.com/introduction  \n",
      "4. Project Mariner, https://deepmind.google/models/project-mariner/  \n",
      "5. Anthropic Computer use: https://docs.anthropic.com/en/docs/build-with-claude/computer-use  \n",
      "6. Project Astra, https://deepmind.google/models/project-astra/  \n",
      "7. Gemini Live, https://gemini.google/overview/gemini-live/?hl=en  \n",
      "8. OpenAI's GPT-4, https://openai.com/index/gpt-4-research/  \n",
      "9. Claude 4, https://www.anthropic.com/news/claude-4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Appendix C - Quick overview of Agentic Frameworks  \n",
      "\n",
      "\n",
      "## LangChain  \n",
      "\n",
      "\n",
      "LangChain is a framework for developing applications powered by LLMs. Its core strength lies in its LangChain Expression Language (LCEL), which allows you to \"pipe\" components together into a chain. This creates a clear, linear sequence where the output of one step becomes the input for the next. It's built for workflows that are Directed Acyclic Graphs (DAGs), meaning the process flows in one direction without loops.  \n",
      "\n",
      "\n",
      "Use it for:  \n",
      "\n",
      "\n",
      "Use it for:- Simple RAG: Retrieve a document, create a prompt, get an answer from an LLM.- Summarization: Take user text, feed it to a summarization prompt, and return the output.- Extraction: Extract structured data (like JSON) from a block of text.  \n",
      "\n",
      "\n",
      "Python  \n",
      "\n",
      "\n",
      "Python# A simple LCEL chain conceptually# (This is not runnable code, just illustrates the flow)chain = prompt | model | output_parse  \n",
      "\n",
      "\n",
      "## LangGraph  \n",
      "\n",
      "\n",
      "LangGraph is a library built on top of LangChain to handle more advanced agentic systems. It allows you to define your workflow as a graph with nodes (functions or LCEL chains) and edges (conditional logic). Its main advantage is the ability to create cycles, allowing the application to loop, retry, or call tools in a flexible order until a task is complete. It explicitly manages the application state, which is passed between nodes and updated throughout the process.  \n",
      "\n",
      "\n",
      "Use it for:  \n",
      "\n",
      "\n",
      "Multi- agent Systems: A supervisor agent routes tasks to specialized worker agents, potentially looping until the goal is met.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Plan-and-Execute Agents: An agent creates a plan, executes a step, and then loops back to update the plan based on the result.- Human-in-the-Loop: The graph can wait for human input before deciding which node to go to next.  \n",
      "\n",
      "\n",
      "\n",
      "<table><tr><td>Feature</td><td>LangChain</td><td>LangGraph</td></tr><tr><td>Core Abstraction</td><td>Chain (using LCEL)</td><td>Graph of Nodes</td></tr><tr><td>Workflow Type</td><td>Linear (Directed Acyclic Graph)</td><td>Cyclical (Graphs with loops)</td></tr><tr><td>State Management</td><td>Generally stateless per run</td><td>Explicit and persistent state object</td></tr><tr><td>Primary Use</td><td>Simple, predictable sequences</td><td>Complex, dynamic, stateful agents</td></tr></table>  \n",
      "\n",
      "\n",
      "Which One Should You Use?  \n",
      "\n",
      "\n",
      "- Choose LangChain when your application has a clear, predictable, and linear flow of steps. If you can define the process from A to B to C without needing to loop back, LangChain with LCEL is the perfect tool.- Choose LangGraph when you need your application to reason, plan, or operate in a loop. If your agent needs to use tools, reflect on the results, and potentially try again with a different approach, you need the cyclical and stateful nature of LangGraph.  \n",
      "\n",
      "\n",
      "Python  \n",
      "\n",
      "\n",
      "# Graph state class State(TypedDict): topic: str joke: str story: str poem: str combined_output: str  \n",
      "\n",
      "\n",
      "# Nodes def call_llm_1(state: State): \"\"\"First LLM call to generate initial joke\"\" msg = llm.invoke(f\"Write a joke about {state['topic']}\") return {\"joke\": msg.content}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def call_llm_2(state: State):  \"\"\"Second LLM call to generate story\"\"\"  msg = llm.invoke(f\"Write a story about {state['topic']}\")  return {\"story\": msg.content}  def call_llm_3(state: State):  \"\"\"Third LLM call to generate poem\"\"\"  msg = llm.invoke(f\"Write a poem about {state['topic']}\")  return {\"poem\": msg.content}  def aggregator(state: State):  \"\"\"Combine the joke and story into a single output\"\"\"  combined = f\"Here's a story, joke, and poem about  {state['topic']}\\n\\n\"  combined += f\"STORY:\\n{state['story']}\\n\\n\"  combined += f\"JOKE:\\n{state['joke']}\\n\\n\"  combined += f\"POEM:\\n{state['poem']}\"  return {\"combined_output\": combined}  # Build workflow  parallel_builder = StateGraph(State)  # Add nodes  parallel_builder.add_node(\"call_llm_1\", call_llm_1)  parallel_builder.add_node(\"call_llm_2\", call_llm_2)  parallel_builder.add_node(\"call_llm_3\", call_llm_3)  parallel_builder.add_node(\"aggregator\", aggregator)  # Add edges to connect nodes  parallel_builder.add_edge(START, \"call_llm_1\")  parallel_builder.add_edge(START, \"call_llm_2\")  parallel_builder.add_edge(START, \"call_llm_3\")  parallel_builder.add_edge(\"call_llm_1\", \"aggregator\")  parallel_builder.add_edge(\"call_llm_2\", \"aggregator\")  parallel_builder.add_edge(\"call_llm_3\", \"aggregator\")  parallel_builder.add_edge(\"aggregator\", END)  parallel_workflow = parallel_builder.compile()  # Show workflow  display(Image(parallel_workflow.get_graph().draw_mermaid_png()))  # Invoke  state = parallel_workflow.invoke({\"topic\": \"cats\"})  print(state[\"combined_output\"])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This code defines and runs a LangGraph workflow that operates in parallel. Its main purpose is to simultaneously generate a joke, a story, and a poem about a given topic and then combine them into a single, formatted text output.  \n",
      "\n",
      "\n",
      "## Google's ADK  \n",
      "\n",
      "\n",
      "Google's Agent Development Kit, or ADK, provides a high- level, structured framework for building and deploying applications composed of multiple, interacting AI agents. It contrasts with LangChain and LangGraph by offering a more opinionated and production- oriented system for orchestrating agent collaboration, rather than providing the fundamental building blocks for an agent's internal logic.  \n",
      "\n",
      "\n",
      "LangChain operates at the most foundational level, offering the components and standardized interfaces to create sequences of operations, such as calling a model and parsing its output. LangGraph extends this by introducing a more flexible and powerful control flow; it treats an agent's workflow as a stateful graph. Using LangGraph, a developer explicitly defines nodes, which are functions or tools, and edges, which dictate the path of execution. This graph structure allows for complex, cyclical reasoning where the system can loop, retry tasks, and make decisions based on an explicitly managed state object that is passed between nodes. It gives the developer fine- grained control over a single agent's thought process or the ability to construct a multi- agent system from first principles.  \n",
      "\n",
      "\n",
      "Google's ADK abstracts away much of this low- level graph construction. Instead of asking the developer to define every node and edge, it provides pre- built architectural patterns for multi- agent interaction. For instance, ADK has built- in agent types like SequentialAgent or ParallelAgent, which manage the flow of control between different agents automatically. It is architected around the concept of a \"team\" of agents, often with a primary agent delegating tasks to specialized sub- agents. State and session management are handled more implicitly by the framework, providing a more cohesive but less granular approach than LangGraph's explicit state passing. Therefore, while LangGraph gives you the detailed tools to design the intricate wiring of a single robot or a team, Google's ADK gives you a factory assembly line designed to build and manage a fleet of robots that already know how to work together.  \n",
      "\n",
      "\n",
      "# Python  \n",
      "\n",
      "\n",
      "from google. adk. agents import LlmAgent from google. adk. tools import google_search  \n",
      "\n",
      "\n",
      "dice_agent = LlmAgent()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model=\"gemini- 2.0- flash- exp\", name=\"question_answer_agent\", description=\"A helpful assistant agent that can answer questions.\", instruction=\"\"\"Respond to the query using google search\"\"\", tools=[google_search], }  \n",
      "\n",
      "\n",
      "This code creates a search- augmented agent. When this agent receives a question, it will not just rely on its pre- existing knowledge. Instead, following its instructions, it will use the Google Search tool to find relevant, real- time information from the web and then use that information to construct its answer.  \n",
      "\n",
      "\n",
      "## Crew.AI  \n",
      "\n",
      "\n",
      "CrewAI offers an orchestration framework for building multi- agent systems by focusing on collaborative roles and structured processes. It operates at a higher level of abstraction than foundational toolkits, providing a conceptual model that mirrors a human team. Instead of defining the granular flow of logic as a graph, the developer defines the actors and their assignments, and CrewAI manages their interaction.  \n",
      "\n",
      "\n",
      "The core components of this framework are Agents, Tasks, and the Crew. An Agent is defined not just by its function but by a persona, including a specific role, a goal, and a backstory, which guides its behavior and communication style. A Task is a discrete unit of work with a clear description and expected output, assigned to a specific Agent. The Crew is the cohesive unit that contains the Agents and the list of Tasks, and it executes a predefined Process. This process dictates the workflow, which is typically either sequential, where the output of one task becomes the input for the next in line, or hierarchical, where a manager- like agent delegates tasks and coordinates the workflow among other agents.  \n",
      "\n",
      "\n",
      "When compared to other frameworks, CrewAI occupies a distinct position. It moves away from the low- level, explicit state management and control flow of LangGraph, where a developer wires together every node and conditional edge. Instead of building a state machine, the developer designs a team charter. While Googles ADK provides a comprehensive, production- oriented platform for the entire agent lifecycle, CrewAI concentrates specifically on the logic of agent collaboration and for simulating a team of specialists  \n",
      "\n",
      "\n",
      "Python\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@crew def crew(self) -> Crew: \"\"\"Creates the research crew\"\" return Crew( agents=self.agents, tasks=self.tasks, process=Process.sequential, verbose=True, )  \n",
      "\n",
      "\n",
      "This code sets up a sequential workflow for a team of AI agents, where they tackle a list of tasks in a specific order, with detailed logging enabled to monitor their progress.  \n",
      "\n",
      "\n",
      "## Other agent development framework  \n",
      "\n",
      "\n",
      "Microsoft AutoGen: AutoGen is a framework centered on orchestrating multiple agents that solve tasks through conversation. Its architecture enables agents with distinct capabilities to interact, allowing for complex problem decomposition and collaborative resolution. The primary advantage of AutoGen is its flexible, conversation- driven approach that supports dynamic and complex multi- agent interactions. However, this conversational paradigm can lead to less predictable execution paths and may require sophisticated prompt engineering to ensure tasks converge efficiently.  \n",
      "\n",
      "\n",
      "Llamalndex: Llamalndex is fundamentally a data framework designed to connect large language models with external and private data sources. It excels at creating sophisticated data ingestion and retrieval pipelines, which are essential for building knowledgeable agents that can perform RAG. While its data indexing and querying capabilities are exceptionally powerful for creating context- aware agents, its native tools for complex agentic control flow and multi- agent orchestration are less developed compared to agent- first frameworks. Llamalndex is optimal when the core technical challenge is data retrieval and synthesis.  \n",
      "\n",
      "\n",
      "Haystack: Haystack is an open- source framework engineered for building scalable and production- ready search systems powered by language models. Its architecture is composed of modular, interoperable nodes that form pipelines for document retrieval, question answering, and summarization. The main strength of Haystack is its focus on performance and scalability for large- scale information retrieval tasks, making it suitable for enterprise- grade applications. A potential trade- off is that its design, optimized for search pipelines, can be more rigid for implementing highly dynamic and creative agentic behaviors.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MetaGPT: MetaGPT implements a multi- agent system by assigning roles and tasks based on a predefined set of Standard Operating Procedures (SOPs). This framework structures agent collaboration to mimic a software development company, with agents taking on roles like product managers or engineers to complete complex tasks. This SOP- driven approach results in highly structured and coherent outputs, which is a significant advantage for specialized domains like code generation. The framework's primary limitation is its high degree of specialization, making it less adaptable for general- purpose agentic tasks outside of its core design.  \n",
      "\n",
      "\n",
      "SuperAGI: SuperAGI is an open- source framework designed to provide a complete lifecycle management system for autonomous agents. It includes features for agent provisioning, monitoring, and a graphical interface, aiming to enhance the reliability of agent execution. The key benefit is its focus on production- readiness, with built- in mechanisms to handle common failure modes like looping and to provide observability into agent performance. A potential drawback is that its comprehensive platform approach can introduce more complexity and overhead than a more lightweight, library- based framework.  \n",
      "\n",
      "\n",
      "Semantic Kernel: Developed by Microsoft, Semantic Kernel is an SDK that integrates large language models with conventional programming code through a system of \"plugins\" and \"planners.\" It allows an LLM to invoke native functions and orchestrate workflows, effectively treating the model as a reasoning engine within a larger software application. Its primary strength is its seamless integration with existing enterprise codebases, particularly in .NET and Python environments. The conceptual overhead of its plugin and planner architecture can present a steeper learning curve compared to more straightforward agent frameworks.  \n",
      "\n",
      "\n",
      "Strands Agents: An AWS lightweight and flexible SDK that uses a model- driven approach for building and running AI agents. It is designed to be simple and scalable, supporting everything from basic conversational assistants to complex multi- agent autonomous systems. The framework is model- agnostic, offering broad support for various LLM providers, and includes native integration with the MCP for easy access to external tools. Its core advantage is its simplicity and flexibility, with a customizable agent loop that is easy to get started with. A potential trade- off is that its lightweight design means developers may need to build out more of the surrounding operational infrastructure, such as advanced monitoring or lifecycle management systems, which more comprehensive frameworks might provide out- of- the- box.  \n",
      "\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The landscape of agentic frameworks offers a diverse spectrum of tools, from low- level libraries for defining agent logic to high- level platforms for orchestrating multi- agent collaboration. At the foundational level, LangChain enables simple, linear workflows, while LangGraph introduces stateful, cyclical graphs for more complex reasoning. Higher- level frameworks like CrewAI and Google's ADK shift the focus to orchestrating teams of agents with predefined roles, while others like LlamaIndex specialize in data- intensive applications. This variety presents developers with a core trade- off between the granular control of graph- based systems and the streamlined development of more opinionated platforms. Consequently, selecting the right framework hinges on whether the application requires a simple sequence, a dynamic reasoning loop, or a managed team of specialists. Ultimately, this evolving ecosystem empowers developers to build increasingly sophisticated AI systems by choosing the precise level of abstraction their project demands.  \n",
      "\n",
      "\n",
      "## References  \n",
      "\n",
      "\n",
      "1. LangChain, https://www.langchain.com/  \n",
      "2. LangGraph, https://www.langchain.com/langgraph  \n",
      "3. Google's ADK, https://google.github.io/adk-docs/  \n",
      "4. Crew.AI, https://docs.crewai.com/en/introduction\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Appendix D - Building an Agent with AgentSpace  \n",
      "\n",
      "\n",
      "## Overview  \n",
      "\n",
      "\n",
      "AgentSpace is a platform designed to facilitate an \"agent- driven enterprise\" by integrating artificial intelligence into daily workflows. At its core, it provides a unified search capability across an organization's entire digital footprint, including documents, emails, and databases. This system utilizes advanced AI models, like Google's Gemini, to comprehend and synthesize information from these varied sources.  \n",
      "\n",
      "\n",
      "The platform enables the creation and deployment of specialized AI \"agents\" that can perform complex tasks and automate processes. These agents are not merely chatbots; they can reason, plan, and execute multi- step actions autonomously. For instance, an agent could research a topic, compile a report with citations, and even generate an audio summary.  \n",
      "\n",
      "\n",
      "To achieve this, AgentSpace constructs an enterprise knowledge graph, mapping the relationships between people, documents, and data. This allows the AI to understand context and deliver more relevant and personalized results. The platform also includes a no- code interface called Agent Designer for creating custom agents without requiring deep technical expertise.  \n",
      "\n",
      "\n",
      "Furthermore, AgentSpace supports a multi- agent system where different AI agents can communicate and collaborate through an open protocol known as the Agent2Agent (A2A) Protocol. This interoperability allows for more complex and orchestrated workflows. Security is a foundational component, with features like role- based access controls and data encryption to protect sensitive enterprise information. Ultimately, AgentSpace aims to enhance productivity and decision- making by embedding intelligent, autonomous systems directly into an organization's operational fabric.  \n",
      "\n",
      "\n",
      "## How to build an Agent with AgentSpace UI  \n",
      "\n",
      "\n",
      "Figure 1 illustrates how to access AgentSpace by selecting AI Applications from the Google Cloud Console.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Which app type do you want to build?  \n",
      "\n",
      "\n",
      "Select the type of application you want to create  \n",
      "\n",
      "\n",
      "Search and assistant  \n",
      "\n",
      "![](images/0.jpg)\n",
      "\n",
      "\n",
      "<center>Fig. 1: How to use Google Cloud Console to access AgentSpace </center>  \n",
      "\n",
      "\n",
      "Your agent can be connected to various services, including Calendar, Google Mail, Workaday, Jira, Outlook, and Service Now (see Fig. 2).  \n",
      "\n",
      "![](images/1.jpg)\n",
      "\n",
      "\n",
      "<center>Fig. 2: Integrate with diverse services, including Google and third-party platforms. </center>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Agent can then utilize its own prompt, chosen from a gallery of pre-made prompts provided by Google, as illustrated in Fig. 3. \n",
      "\n",
      "![](images/0.jpg)\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "<center>Fig.3: Google's Gallery of Pre-assembled prompts</center> \n",
      "\n",
      "\n",
      "In alternative you can create your own prompt as in Fig.4, which will be then used by your agent\n",
      "\n",
      "\n",
      "\n",
      "![](images/0.jpg)\n",
      "\n",
      "\n",
      "<center>Fig.4: Customizing the Agent's Prompt </center>  \n",
      "\n",
      "\n",
      "AgentSpace offers a number of advanced features such as integration with datastores to store your own data, integration with Google Knowledge Graph or with your private Knowledge Graph, Web interface for exposing your agent to the Web, and Analytics to monitor usage, and more (see Fig. 5)\n",
      "\n",
      "\n",
      "\n",
      "![](images/0.jpg)\n",
      "\n",
      "\n",
      "<center>Fig. 5: AgentSpace advanced capabilities </center>  \n",
      "\n",
      "\n",
      "Upon completion, the AgentSpace chat interface (Fig. 6) will be accessible.  \n",
      "\n",
      "\n",
      "# Hello, student  \n",
      "\n",
      "![](images/1.jpg)\n",
      "\n",
      "\n",
      "<center>Fig. 6: The AgentSpace User Interface for initiating a chat with your Agent. </center>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Conclusion  \n",
      "\n",
      "\n",
      "ConclusionIn conclusion, AgentSpace provides a functional framework for developing and deploying AI agents within an organization's existing digital infrastructure. The system's architecture links complex backend processes, such as autonomous reasoning and enterprise knowledge graph mapping, to a graphical user interface for agent construction. Through this interface, users can configure agents by integrating various data services and defining their operational parameters via prompts, resulting in customized, context- aware automated systems.  \n",
      "\n",
      "\n",
      "This approach abstracts the underlying technical complexity, enabling the construction of specialized multi- agent systems without requiring deep programming expertise. The primary objective is to embed automated analytical and operational capabilities directly into workflows, thereby increasing process efficiency and enhancing data- driven analysis. For practical instruction, hands- on learning modules are available, such as the \"Build a Gen AI Agent with Agentspace\" lab on Google Cloud Skills Boost, which provides a structured environment for skill acquisition.  \n",
      "\n",
      "\n",
      "## References  \n",
      "\n",
      "\n",
      "References1. Create a no- code agent with Agent Designer, https://cloud.google.com/agentspace/agentspace- enterprise/docs/agent- designer2. Google Cloud Skills Boost, https://www.cloudskillsboost.google/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Appendix E - AI Agents on the CLI  \n",
      "\n",
      "\n",
      "## Introduction  \n",
      "\n",
      "\n",
      "The developer's command line, long a bastion of precise, imperative commands, is undergoing a profound transformation. It is evolving from a simple shell into an intelligent, collaborative workspace powered by a new class of tools: AI Agent Command- Line Interfaces (CLIs). These agents move beyond merely executing commands; they understand natural language, maintain context about your entire codebase, and can perform complex, multi- step tasks that automate significant parts of the development lifecycle.  \n",
      "\n",
      "\n",
      "This guide provides an in- depth look at four leading players in this burgeoning field, exploring their unique strengths, ideal use cases, and distinct philosophies to help you determine which tool best fits your workflow. It is important to note that many of the example use cases provided for a specific tool can often be accomplished by the other agents as well. The key differentiator between these tools frequently lies in the quality, efficiency, and nuance of the results they are able to achieve for a given task. There are specific benchmarks designed to measure these capabilities, which will be discussed in the following sections.  \n",
      "\n",
      "\n",
      "## Claude CLI (Claude Code)  \n",
      "\n",
      "\n",
      "Anthropic's Claude CLI is engineered as a high- level coding agent with a deep, holistic understanding of a project's architecture. Its core strength is its \"agentic\" nature, allowing it to create a mental model of your repository for complex, multi- step tasks. The interaction is highly conversational, resembling a pair programming session where it explains its plans before executing. This makes it ideal for professional developers working on large- scale projects involving significant refactoring or implementing features with broad architectural impacts.  \n",
      "\n",
      "\n",
      "## Example Use Cases:  \n",
      "\n",
      "\n",
      "1. Large-Scale Refactoring: You can instruct it: \"Our current user authentication relies on session cookies. Refactor the entire codebase to use stateless JWTs, updating the login/logout endpoints, middleware, and frontend token handling.\" Claude will then read all relevant files and perform the coordinated changes.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2. API Integration: After being provided with an OpenAPI specification for a new weather service, you could say: \"Integrate this new weather API. Create a service module to handle the API calls, add a new component to display the weather, and update the main dashboard to include it.\"3. Documentation Generation: Pointing it to a complex module with poorly documented code, you can ask: \"Analyze the ./src/utils/data_processing.js file. Generate comprehensive TSDoc comments for every function, explaining its purpose, parameters, and return value.\"  \n",
      "\n",
      "\n",
      "Claude CLI functions as a specialized coding assistant, with inherent tools for core development tasks, including file ingestion, code structure analysis, and edit generation. Its deep integration with Git facilitates direct branch and commit management. The agent's extensibility is mediated by the Multi- tool Control Protocol (MCP), enabling users to define and integrate custom tools. This allows for interactions with private APIs, database queries, and execution of project- specific scripts. This architecture positions the developer as the arbiter of the agent's functional scope, effectively characterizing Claude as a reasoning engine augmented by user- defined tooling.  \n",
      "\n",
      "\n",
      "## Gemini CLI  \n",
      "\n",
      "\n",
      "Google's Gemini CLI is a versatile, open- source AI agent designed for power and accessibility. It stands out with the advanced Gemini 2.5 Pro model, a massive context window, and multimodal capabilities (processing images and text). Its open- source nature, generous free tier, and \"Reason and Act\" loop make it a transparent, controllable, and excellent all- rounder for a broad audience, from hobbyists to enterprise developers, especially those within the Google Cloud ecosystem.  \n",
      "\n",
      "\n",
      "## Example Use Cases:  \n",
      "\n",
      "\n",
      "1. Multimodal Development: You provide a screenshot of a web component from a design file (gemini describe component.png) and instruct it: \"Write the HTML and CSS code to build a React component that looks exactly like this. Make sure it's responsive.\"2. Cloud Resource Management: Using its built-in Google Cloud integration, you can command: \"Find all GKE clusters in the production project that are running versions older than 1.28 and generate a gcloud command to upgrade them one by one.\"3. Enterprise Tool Integration (via MCP): A developer provides Gemini with a custom tool called get-employee-details that connects to the company's internal HR API. The prompt is: \"Draft a welcome document for our new hire. First, use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "the get- employee- details - - id=E90210 tool to fetch their name and team, and then populate the welcome_template.md with that information.\"  \n",
      "\n",
      "\n",
      "4. Large-Scale Refactoring: A developer needs to refactor a large Java codebase to replace a deprecated logging library with a new, structured logging framework. They can use Gemini with a prompt like: Read all \\*.java files in the 'src/main/java' directory. For each file, replace all instances of the 'org.apache.log4j' import and its 'Logger' class with 'org.slf4j.Logger' and 'LoggerFactory'. Rewrite the logger instantiation and all .info(), .debug(), and .error() calls to use the new structured format with key-value pairs.  \n",
      "\n",
      "\n",
      "Gemini CLI is equipped with a suite of built- in tools that allow it to interact with its environment. These include tools for file system operations (like reading and writing), a shell tool for running commands, and tools for accessing the internet via web fetching and searching. For broader context, it uses specialized tools to read multiple files at once and a memory tool to save information for later sessions. This functionality is built on a secure foundation: sandboxing isolates the model's actions to prevent risk, while MCP servers act as a bridge, enabling Gemini to safely connect to your local environment or other APIs.  \n",
      "\n",
      "\n",
      "## Aider  \n",
      "\n",
      "\n",
      "Aider is an open- source AI coding assistant that acts as a true pair programmer by working directly on your files and committing changes to Git. Its defining feature is its directness; it applies edits, runs tests to validate them, and automatically commits every successful change. Being model- agnostic, it gives users complete control over cost and capabilities. Its git- centric workflow makes it perfect for developers who value efficiency, control, and a transparent, auditable trail of all code modifications.  \n",
      "\n",
      "\n",
      "## Example Use Cases:  \n",
      "\n",
      "\n",
      "1. Test-Driven Development (TDD): A developer can say: \"Create a failing test for a function that calculates the factorial of a number.\" After Aider writes the test and it fails, the next prompt is: \"Now, write the code to make the test pass.\" Aider implements the function and runs the test again to confirm.  \n",
      "2. Precise Bug Squashing: Given a bug report, you can instruct Aider: \"The calculate_total function in billing.py fails on leap years. Add the file to the context, fix the bug, and verify your fix against the existing test suite.\"  \n",
      "3. Dependency Updates: You could instruct it: \"Our project uses an outdated version of the 'requests' library. Please go through all Python files, update the import statements and any deprecated function calls to be compatible with the latest version, and then update requirements.txt.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## GitHub Copilot CLI  \n",
      "\n",
      "\n",
      "GitHub Copilot CLI extends the popular AI pair programmer into the terminal, with its primary advantage being its native, deep integration with the GitHub ecosystem. It understands the context of a project within GitHub. Its agent capabilities allow it to be assigned a GitHub issue, work on a fix, and submit a pull request for human review.  \n",
      "\n",
      "\n",
      "## Example Use Cases:  \n",
      "\n",
      "\n",
      "1. Automated Issue Resolution: A manager assigns a bug ticket (e.g., \"Issue #123: Fix off-by-one error in pagination\") to the Copilot agent. The agent then checks out a new branch, writes the code, and submits a pull request referencing the issue, all without manual developer intervention.  \n",
      "2. Repository-Aware Q&A: A new developer on the team can ask: \"Where in this repository is the database connection logic defined, and what environment variables does it require?\" Copilot CLI uses its awareness of the entire repo to provide a precise answer with file paths.  \n",
      "3. Shell Command Helper: When unsure about a complex shell command, a user can ask: gh? find all files larger than 50MB, compress them, and place them in an archive folder. Copilot will generate the exact shell command needed to perform the task.  \n",
      "\n",
      "\n",
      "## Terminal-Bench: A Benchmark for AI Agents in Command-Line Interfaces  \n",
      "\n",
      "\n",
      "Terminal- Bench is a novel evaluation framework designed to assess the proficiency of AI agents in executing complex tasks within a command- line interface. The terminal is identified as an optimal environment for AI agent operation due to its text- based, sandboxed nature. The initial release, Terminal- Bench- Core- v0, comprises 80 manually curated tasks spanning domains such as scientific workflows and data analysis. To ensure equitable comparisons, Terminus, a minimalistic agent, was developed to serve as a standardized testbed for various language models. The framework is designed for extensibility, allowing for the integration of diverse agents through containerization or direct connections. Future developments include enabling massively parallel evaluations and incorporating established benchmarks. The project encourages open- source contributions for task expansion and collaborative framework enhancement.  \n",
      "\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The emergence of these powerful AI command- line agents marks a fundamental shift in software development, transforming the terminal into a dynamic and collaborative environment. As we've seen, there is no single \"best\" tool; instead, a vibrant ecosystem is forming where each agent offers a specialized strength. The ideal choice depends entirely on the developer's needs: Claude for complex architectural tasks, Gemini for versatile and multimodal problem- solving, Aider for git- centric and direct code editing, and GitHub Copilot for seamless integration into the GitHub workflow. As these tools continue to evolve, proficiency in leveraging them will become an essential skill, fundamentally changing how developers build, debug, and manage software.  \n",
      "\n",
      "\n",
      "## References  \n",
      "\n",
      "\n",
      "1. Anthropic. Claude. https://docs.anthropic.com/en/docs/claude-code/cli-reference  \n",
      "2. Google Gemini Cli https://github.com/google-gemini/gemini-cli  \n",
      "3. Aider. https://aider.chat/  \n",
      "4. GitHub Copilot CLI https://docs.github.com/en/copilot/github-copilot-enterprise/copilot-cli  \n",
      "5. Terminal Bench: https://www.tbench.ai/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Appendix G - Coding Agents  \n",
      "\n",
      "\n",
      "## Vibe Coding: A Starting Point  \n",
      "\n",
      "\n",
      "\"Vibe coding\" has become a powerful technique for rapid innovation and creative exploration. This practice involves using LLMs to generate initial drafts, outline complex logic, or build quick prototypes, significantly reducing initial friction. It is invaluable for overcoming the \"blank page\" problem, enabling developers to quickly transition from a vague concept to tangible, runnable code. Vibe coding is particularly effective when exploring unfamiliar APIs or testing novel architectural patterns, as it bypasses the immediate need for perfect implementation. The generated code often acts as a creative catalyst, providing a foundation for developers to critique, refactor, and expand upon. Its primary strength lies in its ability to accelerate the initial discovery and ideation phases of the software lifecycle. However, while vibe coding excels at brainstorming, developing robust, scalable, and maintainable software demands a more structured approach, shifting from pure generation to a collaborative partnership with specialized coding agents.  \n",
      "\n",
      "\n",
      "## Agents as Team Members  \n",
      "\n",
      "\n",
      "While the initial wave focused on raw code generation—the \"vibe code\" perfect for ideation—the industry is now shifting towards a more integrated and powerful paradigm for production work. The most effective development teams are not merely delegating tasks to Agent; they are augmenting themselves with a suite of sophisticated coding agents. These agents act as tireless, specialized team members, amplifying human creativity and dramatically increasing a team's scalability and velocity.  \n",
      "\n",
      "\n",
      "This evolution is reflected in statements from industry leaders. In early 2025, Alphabet CEO Sundar Pichai noted that at Google, \"over \\(30\\%\\) of new code is now assisted or generated by our Gemini models, fundamentally changing our development velocity. Microsoft made a similar claim. This industry- wide shift signals that the true frontier is not replacing developers, but empowering them. The goal is an augmented relationship where humans guide the architectural vision and creative problem- solving, while agents handle specialized, scalable tasks like testing, documentation, and review.  \n",
      "\n",
      "\n",
      "This chapter presents a framework for organizing a human- agent team based on the core philosophy that human developers act as creative leads and architects, while AI agents function as force multipliers. This framework rests upon three foundational principles:  \n",
      "\n",
      "\n",
      "1. Human-Led Orchestration: The developer is the team lead and project architect. They are always in the loop, orchestrating the workflow, setting the high-level goals, and making the final decisions. The agents are powerful, but they are supportive collaborators. The developer directs which agent to engage, provides the necessary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "context, and, most importantly, exercises the final judgment on any Agent- generated output, ensuring it aligns with the project's quality standards and long- term vision.  \n",
      "\n",
      "\n",
      "2. The Primacy of Context: An agent's performance is entirely dependent on the quality and completeness of its context. A powerful LLM with poor context is useless. Therefore, our framework prioritizes a meticulous, human-led approach to context curation. Automated, black-box context retrieval is avoided. The developer is responsible for assembling the perfect \"briefing\" for their Agent team member. This includes:  \n",
      "\n",
      "\n",
      "- The Complete Codebase: Providing all relevant source code so the agent understands the existing patterns and logic.- External Knowledge: Supplying specific documentation, API definitions, or design documents.- The Human Brief: Articulating clear goals, requirements, pull request descriptions, and style guides.  \n",
      "\n",
      "\n",
      "3. Direct Model Access: To achieve state-of-the-art results, the agents must be powered by direct access to frontier models (e.g., Gemini 2.5 PRO, Claude Opus 4, OpenAI, DeepSeek, etc). Using less powerful models or routing requests through intermediary platforms that obscure or truncate context will degrade performance. The framework is built on creating the purest possible dialogue between the human lead and the raw capabilities of the underlying model, ensuring each agent operates at its peak potential.  \n",
      "\n",
      "\n",
      "The framework is structured as a team of specialized agents, each designed for a core function in the development lifecycle. The human developer acts as the central orchestrator, delegating tasks and integrating the results.  \n",
      "\n",
      "\n",
      "## Core Components  \n",
      "\n",
      "\n",
      "To effectively leverage a frontier Large Language Model, this framework assigns distinct development roles to a team of specialized agents. These agents are not separate applications but are conceptual personas invoked within the LLM through carefully crafted, role- specific prompts and contexts. This approach ensures that the model's vast capabilities are precisely focused on the task at hand, from writing initial code to performing a nuanced, critical review.  \n",
      "\n",
      "\n",
      "The Orchestrator: The Human Developer: In this collaborative framework, the human developer acts as the Orchestrator, serving as the central intelligence and ultimate authority over the AI agents.  \n",
      "\n",
      "\n",
      "- Role: Team Lead, Architect, and final decision-maker. The orchestrator defines tasks, prepares the context, and validates all work done by the agents.- Interface: The developer's own terminal, editor, and the native web UI of the chosen Agents.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Context Staging Area: As the foundation for any successful agent interaction, the Context Staging Area is where the human developer meticulously prepares a complete and task- specific briefing.  \n",
      "\n",
      "\n",
      "- Role: A dedicated workspace for each task, ensuring agents receive a complete and accurate briefing.- Implementation: A temporary directory (task-context/) containing markdown files for goals, code files, and relevant docs  \n",
      "\n",
      "\n",
      "The Specialist Agents: By using targeted prompts, we can build a team of specialist agents, each tailored for a specific development task.  \n",
      "\n",
      "\n",
      "- The Scaffolder Agent: The Implementer  \n",
      "\n",
      "\n",
      "- Purpose: Writes new code, implements features, or creates boilerplate based on detailed specifications.- Invocation Prompt: \"You are a senior software engineer. Based on the requirements in O1_BRIEF.md and the existing patterns in O2_CODE/, implement the feature...\"  \n",
      "\n",
      "\n",
      "- The Test Engineer Agent: The Quality Guard  \n",
      "\n",
      "\n",
      "- Purpose: Writes comprehensive unit tests, integration tests, and end-to-end tests for new or existing code.- Invocation Prompt: \"You are a quality assurance engineer. For the code provided in O2_CODE/, write a full suite of unit tests using [Testing Framework, e.g., pytest]. Cover all edge cases and adhere to the project's testing philosophy.\"  \n",
      "\n",
      "\n",
      "- The Documenter Agent: The Scribe  \n",
      "\n",
      "\n",
      "- Purpose: Generates clear, concise documentation for functions, classes, APIs, or entire codebases.- Invocation Prompt: \"You are a technical writer. Generate markdown documentation for the API endpoints defined in the provided code. Include request/response examples and explain each parameter.\"  \n",
      "\n",
      "\n",
      "- The Optimizer Agent: The Refactoring Partner  \n",
      "\n",
      "\n",
      "- Purpose: Proposes performance optimizations and code refactoring to improve readability, maintainability, and efficiency.- Invocation Prompt: \"Analyze the provided code for performance bottlenecks or areas that could be refactored for clarity. Propose specific changes with explanations for why they are an improvement.\"  \n",
      "\n",
      "\n",
      "- The Process Agent: The Code Supervisor  \n",
      "\n",
      "\n",
      "- Critique: The agent performs an initial pass, identifying potential bugs, style violations, and logical flaws, much like a static analysis tool.- Reflection: The agent then analyzes its own critique. It synthesizes the findings, prioritizes the most critical issues, dismisses pedantic or low-impact suggestions, and provides a high-level, actionable summary for the human developer.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Invocation Prompt: \"You are a principal engineer conducting a code review. First, perform a detailed critique of the changes. Second, reflect on your critique to provide a concise, prioritized summary of the most important feedback.\"  \n",
      "\n",
      "\n",
      "Ultimately, this human- led model creates a powerful synergy between the developer's strategic direction and the agents' tactical execution. As a result, developers can transcend routine tasks, focusing their expertise on the creative and architectural challenges that deliver the most value.  \n",
      "\n",
      "\n",
      "## Practical Implementation  \n",
      "\n",
      "\n",
      "## Setup Checklist  \n",
      "\n",
      "\n",
      "To effectively implement the human- agent team framework, the following setup is recommended, focusing on maintaining control while improving efficiency.  \n",
      "\n",
      "\n",
      "1. Provision Access to Frontier Models Secure API keys for at least two leading large language models, such as Gemini 2.5 Pro and Claude 4 Opus. This dual-provider approach allows for comparative analysis and hedges against single-platform limitations or downtime. These credentials should be managed securely as you would any other production secret.  \n",
      "\n",
      "\n",
      "2. Implement a Local Context Orchestrator Instead of ad-hoc scripts, use a lightweight CLI tool or a local agent runner to manage context. These tools should allow you to define a simple configuration file (e.g., context.toml) in your project root that specifies which files, directories, or even URLs to compile into a single payload for the LLM prompt. This ensures you retain full, transparent control over what the model sees on every request.  \n",
      "\n",
      "\n",
      "3. Establish a Version-Controlled Prompt Library Create a dedicated /prompts directory within your project's Git repository. In it, store the invocation prompts for each specialist agent (e.g., reviewer.md, documenter.md, tester.md) as markdown files. Treating your prompts as code allows the entire team to collaborate on, refine, and version the instructions given to your AI agents over time.  \n",
      "\n",
      "\n",
      "4. Integrate Agent Workflows with Git Hooks Automate your review rhythm by using local Git hooks. For instance, a pre-commit hook can be configured to automatically trigger the Reviewer Agent on your staged changes. The agent's critique-and-reflection summary can be presented directly in your terminal, providing immediate feedback before you finalize the commit and baking the quality assurance step directly into your development process.\n",
      "\n",
      "\n",
      "\n",
      "![](images/0.jpg)\n",
      "\n",
      "\n",
      "<center>Fig. 1: Coding Specialist Examples </center>  \n",
      "\n",
      "\n",
      "## Principles for Leading the Augmented Team  \n",
      "\n",
      "\n",
      "Successfully leading this framework requires evolving from a sole contributor into the lead of a human- Al team, guided by the following principles:  \n",
      "\n",
      "\n",
      "- Maintain Architectural Ownership Your role is to set the strategic direction and own the high-level architecture. You define the \"what\" and the \"why,\" using the agent team to accelerate the \"how.\" You are the final arbiter of design, ensuring every component aligns with the project's long-term vision and quality standards.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Master the Art of the Brief The quality of an agent's output is a direct reflection of the quality of its input. Master the art of the brief by providing clear, unambiguous, and comprehensive context for every task. Think of your prompt not as a simple command, but as a complete briefing package for a new, highly capable team member.- Act as the Ultimate Quality Gate An agent's output is always a proposal, never a command. Treat the Reviewer Agent's feedback as a powerful signal, but you are the ultimate quality gate. Apply your domain expertise and project-specific knowledge to validate, challenge, and approve all changes, acting as the final guardian of the codebase's integrity.- Engage in Iterative Dialogue The best results emerge from conversation, not monologue. If an agent's initial output is imperfect, don't discard it—refine it. Provide corrective feedback, add clarifying context, and prompt for another attempt. This iterative dialogue is crucial, especially with the Reviewer Agent, whose \"Reflection\" output is designed to be the start of a collaborative discussion, not just a final report.  \n",
      "\n",
      "\n",
      "## Conclusion  \n",
      "\n",
      "\n",
      "The future of code development has arrived, and it is augmented. The era of the lone coder has given way to a new paradigm where developers lead teams of specialized AI agents. This model doesn't diminish the human role; it elevates it by automating routine tasks, scaling individual impact, and achieving a development velocity previously unimaginable.  \n",
      "\n",
      "\n",
      "By offloading tactical execution to Agents, developers can now dedicate their cognitive energy to what truly matters: strategic innovation, resilient architectural design, and the creative problem- solving required to build products that delight users. The fundamental relationship has been redefined; it is no longer a contest of human versus machine, but a partnership between human ingenuity and AI, working as a single, seamlessly integrated team.  \n",
      "\n",
      "\n",
      "## References  \n",
      "\n",
      "\n",
      "1. AI is responsible for generating more than \\(30\\%\\) of the code at Google https://www.reddit.com/r/singularity/comments/1k7rxo0/ai_is_now_writing_well_over_30_of_the_code_at/ \n",
      "2. AI is responsible for generating more than \\(30\\%\\) of the code at Microsoft https://www.businesstoday.in/tech-today/news/story/30-of-microsofts-code-is-now-ai-generated-says-ceo-satya-nadella-474167-2025-04-30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Appendix G - Coding Agents  \n",
      "\n",
      "\n",
      "## Vibe Coding: A Starting Point  \n",
      "\n",
      "\n",
      "\"Vibe coding\" has become a powerful technique for rapid innovation and creative exploration. This practice involves using LLMs to generate initial drafts, outline complex logic, or build quick prototypes, significantly reducing initial friction. It is invaluable for overcoming the \"blank page\" problem, enabling developers to quickly transition from a vague concept to tangible, runnable code. Vibe coding is particularly effective when exploring unfamiliar APIs or testing novel architectural patterns, as it bypasses the immediate need for perfect implementation. The generated code often acts as a creative catalyst, providing a foundation for developers to critique, refactor, and expand upon. Its primary strength lies in its ability to accelerate the initial discovery and ideation phases of the software lifecycle. However, while vibe coding excels at brainstorming, developing robust, scalable, and maintainable software demands a more structured approach, shifting from pure generation to a collaborative partnership with specialized coding agents.  \n",
      "\n",
      "\n",
      "## Agents as Team Members  \n",
      "\n",
      "\n",
      "While the initial wave focused on raw code generation—the \"vibe code\" perfect for ideation—the industry is now shifting towards a more integrated and powerful paradigm for production work. The most effective development teams are not merely delegating tasks to Agent; they are augmenting themselves with a suite of sophisticated coding agents. These agents act as tireless, specialized team members, amplifying human creativity and dramatically increasing a team's scalability and velocity.  \n",
      "\n",
      "\n",
      "This evolution is reflected in statements from industry leaders. In early 2025, Alphabet CEO Sundar Pichai noted that at Google, \"over \\(30\\%\\) of new code is now assisted or generated by our Gemini models, fundamentally changing our development velocity. Microsoft made a similar claim. This industry- wide shift signals that the true frontier is not replacing developers, but empowering them. The goal is an augmented relationship where humans guide the architectural vision and creative problem- solving, while agents handle specialized, scalable tasks like testing, documentation, and review.  \n",
      "\n",
      "\n",
      "This chapter presents a framework for organizing a human- agent team based on the core philosophy that human developers act as creative leads and architects, while AI agents function as force multipliers. This framework rests upon three foundational principles:  \n",
      "\n",
      "\n",
      "1. Human-Led Orchestration: The developer is the team lead and project architect. They are always in the loop, orchestrating the workflow, setting the high-level goals, and making the final decisions. The agents are powerful, but they are supportive collaborators. The developer directs which agent to engage, provides the necessary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "context, and, most importantly, exercises the final judgment on any Agent- generated output, ensuring it aligns with the project's quality standards and long- term vision.  \n",
      "\n",
      "\n",
      "2. The Primacy of Context: An agent's performance is entirely dependent on the quality and completeness of its context. A powerful LLM with poor context is useless. Therefore, our framework prioritizes a meticulous, human-led approach to context curation. Automated, black-box context retrieval is avoided. The developer is responsible for assembling the perfect \"briefing\" for their Agent team member. This includes:  \n",
      "\n",
      "\n",
      "- The Complete Codebase: Providing all relevant source code so the agent understands the existing patterns and logic.- External Knowledge: Supplying specific documentation, API definitions, or design documents.- The Human Brief: Articulating clear goals, requirements, pull request descriptions, and style guides.  \n",
      "\n",
      "\n",
      "3. Direct Model Access: To achieve state-of-the-art results, the agents must be powered by direct access to frontier models (e.g., Gemini 2.5 PRO, Claude Opus 4, OpenAI, DeepSeek, etc). Using less powerful models or routing requests through intermediary platforms that obscure or truncate context will degrade performance. The framework is built on creating the purest possible dialogue between the human lead and the raw capabilities of the underlying model, ensuring each agent operates at its peak potential.  \n",
      "\n",
      "\n",
      "The framework is structured as a team of specialized agents, each designed for a core function in the development lifecycle. The human developer acts as the central orchestrator, delegating tasks and integrating the results.  \n",
      "\n",
      "\n",
      "## Core Components  \n",
      "\n",
      "\n",
      "To effectively leverage a frontier Large Language Model, this framework assigns distinct development roles to a team of specialized agents. These agents are not separate applications but are conceptual personas invoked within the LLM through carefully crafted, role- specific prompts and contexts. This approach ensures that the model's vast capabilities are precisely focused on the task at hand, from writing initial code to performing a nuanced, critical review.  \n",
      "\n",
      "\n",
      "The Orchestrator: The Human Developer: In this collaborative framework, the human developer acts as the Orchestrator, serving as the central intelligence and ultimate authority over the AI agents.  \n",
      "\n",
      "\n",
      "- Role: Team Lead, Architect, and final decision-maker. The orchestrator defines tasks, prepares the context, and validates all work done by the agents.- Interface: The developer's own terminal, editor, and the native web UI of the chosen Agents.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Context Staging Area: As the foundation for any successful agent interaction, the Context Staging Area is where the human developer meticulously prepares a complete and task- specific briefing.  \n",
      "\n",
      "\n",
      "- Role: A dedicated workspace for each task, ensuring agents receive a complete and accurate briefing.- Implementation: A temporary directory (task-context/) containing markdown files for goals, code files, and relevant docs  \n",
      "\n",
      "\n",
      "The Specialist Agents: By using targeted prompts, we can build a team of specialist agents, each tailored for a specific development task.  \n",
      "\n",
      "\n",
      "- The Scaffolder Agent: The Implementer  \n",
      "\n",
      "\n",
      "- Purpose: Writes new code, implements features, or creates boilerplate based on detailed specifications.- Invocation Prompt: \"You are a senior software engineer. Based on the requirements in O1_BRIEF.md and the existing patterns in O2_CODE/, implement the feature...\"  \n",
      "\n",
      "\n",
      "- The Test Engineer Agent: The Quality Guard  \n",
      "\n",
      "\n",
      "- Purpose: Writes comprehensive unit tests, integration tests, and end-to-end tests for new or existing code.- Invocation Prompt: \"You are a quality assurance engineer. For the code provided in O2_CODE/, write a full suite of unit tests using [Testing Framework, e.g., pytest]. Cover all edge cases and adhere to the project's testing philosophy.\"  \n",
      "\n",
      "\n",
      "- The Documenter Agent: The Scribe  \n",
      "\n",
      "\n",
      "- Purpose: Generates clear, concise documentation for functions, classes, APIs, or entire codebases.- Invocation Prompt: \"You are a technical writer. Generate markdown documentation for the API endpoints defined in the provided code. Include request/response examples and explain each parameter.\"  \n",
      "\n",
      "\n",
      "- The Optimizer Agent: The Refactoring Partner  \n",
      "\n",
      "\n",
      "- Purpose: Proposes performance optimizations and code refactoring to improve readability, maintainability, and efficiency.- Invocation Prompt: \"Analyze the provided code for performance bottlenecks or areas that could be refactored for clarity. Propose specific changes with explanations for why they are an improvement.\"  \n",
      "\n",
      "\n",
      "- The Process Agent: The Code Supervisor  \n",
      "\n",
      "\n",
      "- Critique: The agent performs an initial pass, identifying potential bugs, style violations, and logical flaws, much like a static analysis tool.- Reflection: The agent then analyzes its own critique. It synthesizes the findings, prioritizes the most critical issues, dismisses pedantic or low-impact suggestions, and provides a high-level, actionable summary for the human developer.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Invocation Prompt: \"You are a principal engineer conducting a code review. First, perform a detailed critique of the changes. Second, reflect on your critique to provide a concise, prioritized summary of the most important feedback.\"  \n",
      "\n",
      "\n",
      "Ultimately, this human- led model creates a powerful synergy between the developer's strategic direction and the agents' tactical execution. As a result, developers can transcend routine tasks, focusing their expertise on the creative and architectural challenges that deliver the most value.  \n",
      "\n",
      "\n",
      "## Practical Implementation  \n",
      "\n",
      "\n",
      "## Setup Checklist  \n",
      "\n",
      "\n",
      "To effectively implement the human- agent team framework, the following setup is recommended, focusing on maintaining control while improving efficiency.  \n",
      "\n",
      "\n",
      "1. Provision Access to Frontier Models Secure API keys for at least two leading large language models, such as Gemini 2.5 Pro and Claude 4 Opus. This dual-provider approach allows for comparative analysis and hedges against single-platform limitations or downtime. These credentials should be managed securely as you would any other production secret.  \n",
      "\n",
      "\n",
      "2. Implement a Local Context Orchestrator Instead of ad-hoc scripts, use a lightweight CLI tool or a local agent runner to manage context. These tools should allow you to define a simple configuration file (e.g., context.toml) in your project root that specifies which files, directories, or even URLs to compile into a single payload for the LLM prompt. This ensures you retain full, transparent control over what the model sees on every request.  \n",
      "\n",
      "\n",
      "3. Establish a Version-Controlled Prompt Library Create a dedicated /prompts directory within your project's Git repository. In it, store the invocation prompts for each specialist agent (e.g., reviewer.md, documenter.md, tester.md) as markdown files. Treating your prompts as code allows the entire team to collaborate on, refine, and version the instructions given to your AI agents over time.  \n",
      "\n",
      "\n",
      "4. Integrate Agent Workflows with Git Hooks Automate your review rhythm by using local Git hooks. For instance, a pre-commit hook can be configured to automatically trigger the Reviewer Agent on your staged changes. The agent's critique-and-reflection summary can be presented directly in your terminal, providing immediate feedback before you finalize the commit and baking the quality assurance step directly into your development process.\n",
      "\n",
      "\n",
      "\n",
      "![](images/0.jpg)\n",
      "\n",
      "\n",
      "<center>Fig. 1: Coding Specialist Examples </center>  \n",
      "\n",
      "\n",
      "## Principles for Leading the Augmented Team  \n",
      "\n",
      "\n",
      "Successfully leading this framework requires evolving from a sole contributor into the lead of a human- Al team, guided by the following principles:  \n",
      "\n",
      "\n",
      "- Maintain Architectural Ownership Your role is to set the strategic direction and own the high-level architecture. You define the \"what\" and the \"why,\" using the agent team to accelerate the \"how.\" You are the final arbiter of design, ensuring every component aligns with the project's long-term vision and quality standards.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Master the Art of the Brief The quality of an agent's output is a direct reflection of the quality of its input. Master the art of the brief by providing clear, unambiguous, and comprehensive context for every task. Think of your prompt not as a simple command, but as a complete briefing package for a new, highly capable team member.- Act as the Ultimate Quality Gate An agent's output is always a proposal, never a command. Treat the Reviewer Agent's feedback as a powerful signal, but you are the ultimate quality gate. Apply your domain expertise and project-specific knowledge to validate, challenge, and approve all changes, acting as the final guardian of the codebase's integrity.- Engage in Iterative Dialogue The best results emerge from conversation, not monologue. If an agent's initial output is imperfect, don't discard it—refine it. Provide corrective feedback, add clarifying context, and prompt for another attempt. This iterative dialogue is crucial, especially with the Reviewer Agent, whose \"Reflection\" output is designed to be the start of a collaborative discussion, not just a final report.  \n",
      "\n",
      "\n",
      "## Conclusion  \n",
      "\n",
      "\n",
      "The future of code development has arrived, and it is augmented. The era of the lone coder has given way to a new paradigm where developers lead teams of specialized AI agents. This model doesn't diminish the human role; it elevates it by automating routine tasks, scaling individual impact, and achieving a development velocity previously unimaginable.  \n",
      "\n",
      "\n",
      "By offloading tactical execution to Agents, developers can now dedicate their cognitive energy to what truly matters: strategic innovation, resilient architectural design, and the creative problem- solving required to build products that delight users. The fundamental relationship has been redefined; it is no longer a contest of human versus machine, but a partnership between human ingenuity and AI, working as a single, seamlessly integrated team.  \n",
      "\n",
      "\n",
      "## References  \n",
      "\n",
      "\n",
      "1. AI is responsible for generating more than \\(30\\%\\) of the code at Google https://www.reddit.com/r/singularity/comments/1k7rxo0/ai_is_now_writing_well_over_30_of_the_code_at/ \n",
      "2. AI is responsible for generating more than \\(30\\%\\) of the code at Microsoft https://www.businesstoday.in/tech-today/news/story/30-of-microsofts-code-is-now-ai-generated-says-ceo-satya-nadella-474167-2025-04-30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Conclusion  \n",
      "\n",
      "\n",
      "Throughout this book we have journeyed from the foundational concepts of agentic AI to the practical implementation of sophisticated, autonomous systems. We began with the premise that building intelligent agents is akin to creating a complex work of art on a technical canvas—a process that requires not just a powerful cognitive engine like a large language model, but also a robust set of architectural blueprints. These blueprints, or agentic patterns, provide the structure and reliability needed to transform simple, reactive models into proactive, goal- oriented entities capable of complex reasoning and action.  \n",
      "\n",
      "\n",
      "This concluding chapter will synthesize the core principles we have explored. We will first review the key agentic patterns, grouping them into a cohesive framework that underscores their collective importance. Next, we will examine how these individual patterns can be composed into more complex systems, creating a powerful synergy. Finally, we will look ahead to the future of agent development, exploring the emerging trends and challenges that will shape the next generation of intelligent systems.  \n",
      "\n",
      "\n",
      "## Review of key agentic principles  \n",
      "\n",
      "\n",
      "The 21 patterns detailed in this guide represent a comprehensive toolkit for agent development. While each pattern addresses a specific design challenge, they can be understood collectively by grouping them into foundational categories that mirror the core competencies of an intelligent agent.  \n",
      "\n",
      "\n",
      "1. Core Execution and Task Decomposition: At the most fundamental level, agents must be able to execute tasks. The patterns of Prompt Chaining, Routing, Parallelization, and Planning form the bedrock of an agent's ability to act. Prompt Chaining provides a simple yet powerful method for breaking down a problem into a linear sequence of discrete steps, ensuring that the output of one operation logically informs the next. When workflows require more dynamic behavior, Routing introduces conditional logic, allowing an agent to select the most appropriate path or tool based on the context of the input. Parallelization optimizes efficiency by enabling the concurrent execution of independent sub-tasks, while the Planning pattern elevates the agent from a mere executor to a strategist, capable of formulating a multi-step plan to achieve a high-level objective.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2. Interaction with the External Environment: An agent's utility is significantly enhanced by its ability to interact with the world beyond its immediate internal state. The Tool Use (Function Calling) pattern is paramount here, providing the mechanism for agents to leverage external APIs, databases, and other software systems. This grounds the agent's operations in real-world data and capabilities. To effectively use these tools, agents must often access specific, relevant information from vast repositories. The Knowledge Retrieval pattern, particularly Retrieval-Augmented Generation (RAG), addresses this by enabling agents to query knowledge bases and incorporate that information into their responses, making them more accurate and contextually aware.  \n",
      "\n",
      "\n",
      "3. State, Learning, and Self-Improvement: For an agent to perform more than just single-turn tasks, it must possess the ability to maintain context and improve over time. The Memory Management pattern is crucial for endowing agents with both short-term conversational context and long-term knowledge retention. Beyond simple memory, truly intelligent agents exhibit the capacity for self-improvement. The Reflection and Self-Correction patterns enable an agent to critique its own output, identify errors or shortcomings, and iteratively refine its work, leading to a higher quality final result. The Learning and Adaptation pattern takes this a step further, allowing an agent's behavior to evolve based on feedback and experience, making it more effective over time.  \n",
      "\n",
      "\n",
      "4. Collaboration and Communication: Many complex problems are best solved through collaboration. The Multi-Agent Collaboration pattern allows for the creation of systems where multiple specialized agents, each with a distinct role and set of capabilities, work together to achieve a common goal. This division of labor enables the system to tackle multifaceted problems that would be intractable for a single agent. The effectiveness of such systems hinges on clear and efficient communication, a challenge addressed by the Inter-Agent Communication (A2A) and Model Context Protocol (MCP) patterns, which aim to standardize how agents and tools exchange information.  \n",
      "\n",
      "\n",
      "These principles, when applied through their respective patterns, provide a robust framework for building intelligent systems. They guide the developer in creating agents that are not only capable of performing complex tasks but are also structured, reliable, and adaptable.  \n",
      "\n",
      "\n",
      "## Combining Patterns for Complex Systems  \n",
      "\n",
      "\n",
      "The true power of agentic design emerges not from the application of a single pattern in isolation, but from the artful composition of multiple patterns to create\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sophisticated, multi- layered systems. The agentic canvas is rarely populated by a single, simple workflow; instead, it becomes a tapestry of interconnected patterns that work in concert to achieve a complex objective.  \n",
      "\n",
      "\n",
      "Consider the development of an autonomous AI research assistant, a task that requires a combination of planning, information retrieval, analysis, and synthesis. Such a system would be a prime example of pattern composition:  \n",
      "\n",
      "\n",
      "- Initial Planning: A user query, such as \"Analyze the impact of quantum computing on the cybersecurity landscape,\" would first be received by a Planner agent. This agent would leverage the Planning pattern to decompose the high-level request into a structured, multi-step research plan. This plan might include steps like \"Identify foundational concepts of quantum computing,\" \"Research common cryptographic algorithms,\" \"Find expert analyses on quantum threats to cryptography,\" and \"Synthesize findings into a structured report.\"  \n",
      "\n",
      "\n",
      "- Information Gathering with Tool Use: To execute this plan, the agent would rely heavily on the Tool Use pattern. Each step of the plan would trigger a call to a Google Search or vertex_ai_search tool. For more structured data, it might use tools to query academic databases like ArXiv or financial data APIs.  \n",
      "\n",
      "\n",
      "- Collaborative Analysis and Writing: A single agent might handle this, but a more robust architecture would employ Multi-Agent Collaboration. A \"Researcher\" agent could be responsible for executing the search plan and gathering raw information. Its output—a collection of summaries and source links—would then be passed to a \"Writer\" agent. This specialist agent, using the initial plan as its outline, would synthesize the collected information into a coherent draft.  \n",
      "\n",
      "\n",
      "- Iterative Reflection and Refinement: A first draft is rarely perfect. The Reflection pattern could be implemented by introducing a third \"Critic\" agent. This agent's sole purpose would be to review the Writer's draft, checking for logical inconsistencies, factual inaccuracies, or areas lacking clarity. Its critique would be fed back to the Writer agent, which would then leverage the Self-Correction pattern to refine its output, incorporating the feedback to produce a higher-quality final report.  \n",
      "\n",
      "\n",
      "- State Management: Throughout this entire process, a Memory Management system would be essential. It would maintain the state of the research plan, store the information gathered by the Researcher, hold the drafts created by the Writer, and track the feedback from the Critic, ensuring that context is preserved across the entire multi-step, multi-agent workflow.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In this example, at least five distinct agentic patterns are woven together. The Planning pattern provides the high- level structure, Tool Use grounds the operation in real- world data, Multi- Agent Collaboration enables specialization and division of labor, Reflection ensures quality, and Memory Management maintains coherence. This composition transforms a set of individual capabilities into a powerful, autonomous system capable of tackling a task that would be far too complex for a single prompt or a simple chain.  \n",
      "\n",
      "\n",
      "## Looking to the Future  \n",
      "\n",
      "\n",
      "The composition of agentic patterns into complex systems, as illustrated by our AI research assistant, is not the end of the story but rather the beginning of a new chapter in software development. As we look ahead, several emerging trends and challenges will define the next generation of intelligent systems, pushing the boundaries of what is possible and demanding even greater sophistication from their creators.  \n",
      "\n",
      "\n",
      "The journey toward more advanced agentic AI will be marked by a drive for greater autonomy and reasoning. The patterns we have discussed provide the scaffolding for goal- oriented behavior, but the future will require agents that can navigate ambiguity, perform abstract and causal reasoning, and even exhibit a degree of common sense. This will likely involve tighter integration with novel model architectures and neuro- symbolic approaches that blend the pattern- matching strengths of LLMs with the logical rigor of classical AI. We will see a shift from human- in- the- loop systems, where the agent is a co- pilot, to human- on- the- loop systems, where agents are trusted to execute complex, long- running tasks with minimal oversight, reporting back only when the objective is complete or a critical exception occurs.  \n",
      "\n",
      "\n",
      "This evolution will be accompanied by the rise of agentic ecosystems and standardization. The Multi- Agent Collaboration pattern highlights the power of specialized agents, and the future will see the emergence of open marketplaces and platforms where developers can deploy, discover, and orchestrate fleets of agents- as- a- service. For this to succeed, the principles behind the Model Context Protocol (MCP) and Inter- Agent Communication (A2A) will become paramount, leading to industry- wide standards for how agents, tools, and models exchange not just data, but also context, goals, and capabilities.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A prime example of this growing ecosystem is the \"Awesome Agents\" GitHub repository, a valuable resource that serves as a curated list of open- source AI agents, frameworks, and tools. It showcases the rapid innovation in the field by organizing cutting- edge projects for applications ranging from software development to autonomous research and conversational AI.  \n",
      "\n",
      "\n",
      "However, this path is not without its formidable challenges. The core issues of safety, alignment, and robustness will become even more critical as agents become more autonomous and interconnected. How do we ensure an agent's learning and adaptation do not cause it to drift from its original purpose? How do we build systems that are resilient to adversarial attacks and unpredictable real- world scenarios? Answering these questions will require a new set of \"safety patterns\" and a rigorous engineering discipline focused on testing, validation, and ethical alignment.  \n",
      "\n",
      "\n",
      "## Final Thoughts  \n",
      "\n",
      "\n",
      "Throughout this guide, we have framed the construction of intelligent agents as an art form practiced on a technical canvas. These Agentic Design patterns are your palette and your brushstrokes—the foundational elements that allow you to move beyond simple prompts and create dynamic, responsive, and goal- oriented entities. They provide the architectural discipline needed to transform the raw cognitive power of a large language model into a reliable and purposeful system.  \n",
      "\n",
      "\n",
      "The true craft lies not in mastering a single pattern but in understanding their interplay—in seeing the canvas as a whole and composing a system where planning, tool use, reflection, and collaboration work in harmony. The principles of agentic design are the grammar of a new language of creation, one that allows us to instruct machines not just on what to do, but on how to be.  \n",
      "\n",
      "\n",
      "The field of agentic AI is one of the most exciting and rapidly evolving domains in technology. The concepts and patterns detailed here are not a final, static dogma but a starting point—a solid foundation upon which to build, experiment, and innovate. The future is not one where we are simply users of AI, but one where we are the architects of intelligent systems that will help us solve the world's most complex problems. The canvas is before you, the patterns are in your hands. Now, it is time to build.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Glossary  \n",
      "\n",
      "\n",
      "Fundamental Concepts  \n",
      "\n",
      "\n",
      "Prompt: A prompt is the input, typically in the form of a question, instruction, or statement, that a user provides to an AI model to elicit a response. The quality and structure of the prompt heavily influence the model's output, making prompt engineering a key skill for effectively using AI.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Context Window: The context window is the maximum number of tokens an AI model can process at once, including both the input and its generated output. This fixed size is a critical limitation, as information outside the window is ignored, while larger windows enable more complex conversations and document analysis.  \n",
      "\n",
      "\n",
      "In- Context Learning: In- context learning is an AI's ability to learn a new task from examples provided directly in the prompt, without requiring any retraining. This powerful feature allows a single, general- purpose model to be adapted to countless specific tasks on the fly.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Zero- Shot, One- Shot, & Few- Shot Prompting: These are prompting techniques where a model is given zero, one, or a few examples of a task to guide its response. Providing more examples generally helps the model better understand the user's intent and improves its accuracy for the specific task.  \n",
      "\n",
      "\n",
      "Multimodality: Multimodality is an AI's ability to understand and process information across multiple data types like text, images, and audio. This allows for more versatile and human- like interactions, such as describing an image or answering a spoken question.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Grounding: Grounding is the process of connecting a model's outputs to verifiable, real- world information sources to ensure factual accuracy and reduce hallucinations. This is often achieved with techniques like RAG to make AI systems more trustworthy.  \n",
      "\n",
      "\n",
      "Core AI Model Architectures  \n",
      "\n",
      "\n",
      "Transformers: The Transformer is the foundational neural network architecture for most modern LLMs. Its key innovation is the self- attention mechanism, which efficiently processes long sequences of text and captures complex relationships between words.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Recurrent Neural Network (RNN): The Recurrent Neural Network is a foundational architecture that preceded the Transformer. RNNs process information sequentially, using loops to maintain a \"memory\" of previous inputs, which made them suitable for tasks like text and speech processing.  \n",
      "\n",
      "\n",
      "Mixture of Experts (MoE): Mixture of Experts is an efficient model architecture where a \"router\" network dynamically selects a small subset of \"expert\" networks to handle any given input. This allows models to have a massive number of parameters while keeping computational costs manageable.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Diffusion Models: Diffusion models are generative models that excel at creating high- quality images. They work by adding random noise to data and then training a model to meticulously reverse the process, allowing them to generate novel data from a random starting point.  \n",
      "\n",
      "\n",
      "Mamba: Mamba is a recent AI architecture using a Selective State Space Model (SSM) to process sequences with high efficiency, especially for very long contexts. Its selective mechanism allows it to focus on relevant information while filtering out noise, making it a potential alternative to the Transformer.  \n",
      "\n",
      "\n",
      "The LLM Development Lifecycle\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The development of a powerful language model follows a distinct sequence. It begins with Pre- training, where a massive base model is built by training it on a vast dataset of general internet text to learn language, reasoning, and world knowledge. Next is Fine- tuning, a specialization phase where the general model is further trained on smaller, task- specific datasets to adapt its capabilities for a particular purpose. The final stage is Alignment, where the specialized model's behavior is adjusted to ensure its outputs are helpful, harmless, and aligned with human values.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Pre- training Techniques: Pre- training is the initial phase where a model learns general knowledge from vast amounts of data. The top techniques for this involve different objectives for the model to learn from. The most common is Causal Language Modeling (CLM), where the model predicts the next word in a sentence. Another is Masked Language Modeling (MLM), where the model fills in intentionally hidden words in a text. Other important methods include Denoising Objectives, where the model learns to restore a corrupted input to its original state, Contrastive Learning, where it learns to distinguish between similar and dissimilar pieces of data, and Next Sentence Prediction\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(NSP), where it determines if two sentences logically follow each other.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fine- tuning Techniques: Fine- tuning is the process of adapting a general pre- trained model to a specific task using a smaller, specialized dataset. The most common approach is Supervised Fine- Tuning (SFT), where the model is trained on labeled examples of correct input- output pairs. A popular variant is Instruction Tuning, which focuses on training the model to better follow user commands. To make this process more efficient, Parameter- Efficient Fine- Tuning (PEFT) methods are used, with top techniques including LoRA (Low- Rank Adaptation), which only updates a small number of parameters, and its memory- optimized version, QLoRA. Another technique,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieval- Augmented Generation (RAG), enhances the model by connecting it to an external knowledge source during the fine- tuning or inference stage.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Alignment & Safety Techniques: Alignment is the process of ensuring an Al model's behavior aligns with human values and expectations, making it helpful and harmless. The most prominent technique is Reinforcement Learning from Human Feedback (RLHF), where a \"reward model\" trained on human preferences guides the Al's learning process, often using an algorithm like Proximal Policy Optimization (PPO) for stability. Simpler alternatives have emerged, such as Direct Preference Optimization (DPO), which bypasses the need for a separate reward model, and Kahneman- Tversky Optimization (KTO), which simplifies data collection further. To ensure safe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "deployment, Guardrails are implemented as a final safety layer to filter outputs and block harmful actions in real- time.  \n",
      "\n",
      "\n",
      "Enhancing AI Agent CapabilitiesAI agents are systems that can perceive their environment and take autonomous actions to achieve goals. Their effectiveness is enhanced by robust reasoning frameworks.  \n",
      "\n",
      "\n",
      "Chain of Thought (CoT): This prompting technique encourages a model to explain its reasoning step- by- step before giving a final answer. This process of \"thinking out loud\" often leads to more accurate results on complex reasoning tasks.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tree of Thoughts (ToT): Tree of Thoughts is an advanced reasoning framework where an agent explores multiple reasoning paths simultaneously, like branches on a tree. It allows the agent to self- evaluate different lines of thought and choose the most promising one to pursue, making it more effective at complex problem- solving.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ReAct (Reason and Act): ReAct is an agent framework that combines reasoning and acting in a loop. The agent first \"thinks\" about what to do, then takes an \"action\" using a tool, and uses the resulting observation to inform its next thought, making it highly effective at solving complex tasks.  \n",
      "\n",
      "\n",
      "Planning: This is an agent's ability to break down a high- level goal into a sequence of smaller, manageable sub- tasks. The agent then creates a plan to execute these steps in order, allowing it to handle complex, multi- step assignments.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Deep Research: Deep research refers to an agent's capability to autonomously explore a topic in- depth by iteratively searching for information, synthesizing findings, and identifying new questions. This allows the agent to build a comprehensive understanding of a subject far beyond a single search query.  \n",
      "\n",
      "\n",
      "Critique Model: A critique model is a specialized AI model trained to review, evaluate, and provide feedback on the output of another AI model. It acts as an automated critic, helping to identify errors, improve reasoning, and ensure the final output meets a desired quality standard.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Index of Terms  \n",
      "\n",
      "\n",
      "This index of terms was generated using Gemini Pro 2.5. The prompt and reasoning steps are included at the end to demonstrate the time- saving benefits and for educational purposes.  \n",
      "\n",
      "\n",
      "## A  \n",
      "\n",
      "\n",
      "- A/B Testing \n",
      "- Chapter 3: Parallelization- Action Selection \n",
      "- Chapter 20: Prioritization- Adaptation \n",
      "- Chapter 9: Learning and Adaptation- Adaptive Task Allocation \n",
      "- Chapter 16: Resource-Aware Optimization- Adaptive Tool Use & Selection \n",
      "- Chapter 16: Resource-Aware Optimization- Agent \n",
      "- What makes an AI system an Agent?- Agent-Computer Interfaces (ACIs) \n",
      "- Appendix B- Agent-Driven Economy \n",
      "- What makes an AI system an Agent?- Agent as a Tool \n",
      "- Chapter 7: Multi-Agent Collaboration- Agent Cards \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Agent Development Kit (ADK) \n",
      "- Chapter 2: Routing, Chapter 3: Parallelization, Chapter 4: Reflection, Chapter 5: Tool Use, Chapter 7: Multi-Agent Collaboration, Chapter 8: Memory Management, Chapter 12: Exception Handling and Recovery, Chapter 13: Human-in-the-Loop, Chapter 15: Inter-Agent Communication (A2A), Chapter 16: Resource-Aware Optimization, Chapter 19: Evaluation and Monitoring, Appendix C- Agent Discovery \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Agent Trajectories \n",
      "- Chapter 19: Evaluation and Monitoring- Agentic Design Patterns \n",
      "- Introduction- Agentic RAG \n",
      "- Chapter 14: Knowledge Retrieval (RAG)- Agentic Systems \n",
      "- Introduction- AI Co-scientist \n",
      "- Chapter 21: Exploration and Discovery- Alignment \n",
      "- Glossary- AlphaEvolve \n",
      "- Chapter 9: Learning and Adaptation- Analogies \n",
      "- Appendix A- Anomaly Detection \n",
      "- Chapter 19: Evaluation and Monitoring- Anthropic's Claude 4 Series \n",
      "- Appendix B- Anthropic's Computer Use \n",
      "- Appendix B- API Interaction \n",
      "- Chapter 10: Model Context Protocol (MCP)- Artifacts \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Asynchronous Polling \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Audit Logs \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Automated Metrics \n",
      "- Chapter 19: Evaluation and Monitoring- Automatic Prompt Engineering (APE) \n",
      "- Appendix A- Autonomy \n",
      "- Introduction- A2A (Agent-to-Agent) \n",
      "- Chapter 15: Inter-Agent Communication (A2A)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Behavioral Constraints - Chapter 18: Guardrails/Safety Patterns- Browser Use - Appendix B  \n",
      "\n",
      "\n",
      "C  \n",
      "\n",
      "\n",
      "- Callbacks - Chapter 18: Guardrails/Safety Patterns- Causal Language Modeling (CLM) - Glossary- Chain of Debates (CoD) - Chapter 17: Reasoning Techniques- Chain-of-Thought (CoT) - Chapter 17: Reasoning Techniques, Appendix A- Chatbots - Chapter 8: Memory Management- ChatMessageHistory - Chapter 8: Memory Management- Checkpoint and Rollback - Chapter 18: Guardrails/Safety Patterns- Chunking - Chapter 14: Knowledge Retrieval (RAG)- Clarity and Specificity - Appendix A- Client Agent - Chapter 15: Inter-Agent Communication (A2A)- Code Generation - Chapter 1: Prompt Chaining, Chapter 4: Reflection- Code Prompting - Appendix A- CoD (Chain of Debates) - Chapter 17: Reasoning Techniques- CoT (Chain of Thought) - Chapter 17: Reasoning Techniques, Appendix A- Collaboration - Chapter 7: Multi-Agent Collaboration- Compliance - Chapter 19: Evaluation and Monitoring- Conciseness - Appendix A- Content Generation - Chapter 1: Prompt Chaining, Chapter 4: Reflection- Context Engineering - Chapter 1: Prompt Chaining- Context Window - Glossary- Contextual Pruning & Summarization - Chapter 16: Resource-Aware Optimization- Contextual Prompting - Appendix A- Contractor Model - Chapter 19: Evaluation and Monitoring- ConversationBufferMemory - Chapter 8: Memory Management- Conversational Agents - Chapter 1: Prompt Chaining, Chapter 4: Reflection- Cost-Sensitive Exploration - Chapter 16: Resource-Aware Optimization- CrewAI - Chapter 3: Parallelization, Chapter 5: Tool Use, Chapter 6: Planning, Chapter 7: Multi-Agent Collaboration, Chapter 18: Guardrails/Safety Patterns, Appendix C- Critique Agent - Chapter 16: Resource-Aware Optimization- Critique Model - Glossary- Customer Support - Chapter 13: Human-in-the-Loop  \n",
      "\n",
      "\n",
      "D  \n",
      "\n",
      "\n",
      "- Data Extraction - Chapter 1: Prompt Chaining- Data Labeling - Chapter 13: Human-in-the-Loop- Database Integration - Chapter 10: Model Context Protocol (MCP)- DatabaseSessionService - Chapter 8: Memory Management\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Debate and Consensus \n",
      "- Chapter 7: Multi-Agent Collaboration- Decision Augmentation \n",
      "- Chapter 13: Human-in-the-Loop- Decomposition \n",
      "- Appendix A- Deep Research \n",
      "- Chapter 6: Planning, Chapter 17: Reasoning Techniques, Glossary- Delimiters \n",
      "- Appendix A- Denoising Objectives \n",
      "- Glossary- Dependencies \n",
      "- Chapter 20: Prioritization- Diffusion Models \n",
      "- Glossary- Direct Preference Optimization (DPO) \n",
      "- Chapter 9: Learning and Adaptation- Discoverability \n",
      "- Chapter 10: Model Context Protocol (MCP)- Drift Detection \n",
      "- Chapter 19: Evaluation and Monitoring- Dynamic Model Switching \n",
      "- Chapter 16: Resource-Aware Optimization- Dynamic Re-prioritization \n",
      "- Chapter 20: Prioritization  \n",
      "\n",
      "\n",
      "## E  \n",
      "\n",
      "\n",
      "- Embeddings \n",
      "- Chapter 14: Knowledge Retrieval (RAG)- Embodiment \n",
      "- What makes an AI system an Agent?- Energy-Efficient Deployment \n",
      "- Chapter 16: Resource-Aware Optimization- Episodic Memory \n",
      "- Chapter 8: Memory Management- Error Detection \n",
      "- Chapter 12: Exception Handling and Recovery- Error Handling \n",
      "- Chapter 12: Exception Handling and Recovery- Escalation Policies \n",
      "- Chapter 13: Human-in-the-Loop- Evaluation \n",
      "- Chapter 19: Evaluation and Monitoring- Exception Handling \n",
      "- Chapter 12: Exception Handling and Recovery- Expert Teams \n",
      "- Chapter 7: Multi-Agent Collaboration- Exploration and Discovery \n",
      "- Chapter 21: Exploration and Discovery- External Moderation APIs \n",
      "- Chapter 18: Guardrails/Safety Patterns  \n",
      "\n",
      "\n",
      "## F  \n",
      "\n",
      "\n",
      "- Factored Cognition \n",
      "- Appendix A- FastMCP \n",
      "- Chapter 10: Model Context Protocol (MCP)- Fault Tolerance \n",
      "- Chapter 18: Guardrails/Safety Patterns- Few-Shot Learning \n",
      "- Chapter 9: Learning and Adaptation- Few-Shot Prompting \n",
      "- Appendix A- Fine-tuning \n",
      "- Glossary- Formalized Contract \n",
      "- Chapter 19: Evaluation and Monitoring- Function Calling \n",
      "- Chapter 5: Tool Use, Appendix A  \n",
      "\n",
      "\n",
      "## G  \n",
      "\n",
      "\n",
      "- Gemini Live \n",
      "- Appendix B- Gems \n",
      "- Appendix A- Generative Media Orchestration \n",
      "- Chapter 10: Model Context Protocol (MCP)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Goal Setting \n",
      "- Chapter 11: Goal Setting and Monitoring- GoD (Graph of Debates) \n",
      "- Chapter 17: Reasoning Techniques- Google Agent Development Kit (ADK) \n",
      "- Chapter 2: Routing, Chapter 3: Parallelization, Chapter 4: Reflection, Chapter 5: Tool Use, Chapter 7: Multi-Agent Collaboration, Chapter 8: Memory Management, Chapter 12: Exception Handling and Recovery, Chapter 13: Human-in-the-Loop, Chapter 15: Inter-Agent Communication (A2A), Chapter 16: Resource-Aware Optimization, Chapter 19: Evaluation and Monitoring, Appendix C- Google Co-Scientist \n",
      "- Chapter 21: Exploration and Discovery- Google DeepResearch \n",
      "- Chapter 6: Planning- Google Project Mariner \n",
      "- Appendix B- Graceful Degradation \n",
      "- Chapter 12: Exception Handling and Recovery, Chapter 16: Resource-Aware Optimization- Graph of Debates (GoD) \n",
      "- Chapter 17: Reasoning Techniques- Grounding \n",
      "- Glossary- Guardrails \n",
      "- Chapter 18: Guardrails/Safety Patterns  \n",
      "\n",
      "\n",
      "## H  \n",
      "\n",
      "\n",
      "- Haystack \n",
      "- Appendix C- Hierarchical Decomposition \n",
      "- Chapter 19: Evaluation and Monitoring- Hierarchical Structures \n",
      "- Chapter 7: Multi-Agent Collaboration- HITL (Human-in-the-Loop) \n",
      "- Chapter 13: Human-in-the-Loop- Human-in-the-Loop (HITL) \n",
      "- Chapter 13: Human-in-the-Loop- Human-on-the-loop \n",
      "- Chapter 13: Human-in-the-Loop- Human Oversight \n",
      "- Chapter 13: Human-in-the-Loop, Chapter 18: Guardrails/Safety Patterns  \n",
      "\n",
      "\n",
      "## I  \n",
      "\n",
      "\n",
      "- In-Context Learning \n",
      "- Glossary- InMemoryMemoryService \n",
      "- Chapter 8: Memory Management- InMemorySessionService \n",
      "- Chapter 8: Memory Management- Input Validation/Sanitization \n",
      "- Chapter 18: Guardrails/Safety Patterns- Instructions Over Constraints \n",
      "- Appendix A- Inter-Agent Communication (A2A) \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Intervention and Correction \n",
      "- Chapter 13: Human-in-the-Loop- IoT Device Control \n",
      "- Chapter 10: Model Context Protocol (MCP)- Iterative Prompting / Refinement \n",
      "- Appendix A  \n",
      "\n",
      "\n",
      "## J  \n",
      "\n",
      "\n",
      "- Jailbreaking \n",
      "- Chapter 18: Guardrails/Safety Patterns  \n",
      "\n",
      "\n",
      "## K  \n",
      "\n",
      "\n",
      "- Kahneman-Tversky Optimization (KTO) \n",
      "- Glossary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Knowledge Retrieval (RAG) - Chapter 14: Knowledge Retrieval (RAG)  \n",
      "\n",
      "\n",
      "L  \n",
      "\n",
      "\n",
      "- LangChain - Chapter 1: Prompt Chaining, Chapter 2: Routing, Chapter 3: Parallelization, Chapter 4: Reflection, Chapter 5: Tool Use, Chapter 8: Memory Management, Chapter 20: Prioritization, Appendix C- LangGraph - Chapter 1: Prompt Chaining, Chapter 2: Routing, Chapter 3:Parallelization, Chapter 4: Reflection, Chapter 5: Tool Use, Chapter 8:Memory Management, Appendix C- Latency Monitoring - Chapter 19: Evaluation and Monitoring- Learned Resource Allocation Policies - Chapter 16: Resource-Aware Optimization- Learning and Adaptation - Chapter 9: Learning and Adaptation- LLM-as-a-Judge - Chapter 19: Evaluation and Monitoring- LlamaIndex - Appendix C- LoRA (Low-Rank Adaptation) - Glossary- Low-Rank Adaptation (LoRA) - Glossary  \n",
      "\n",
      "\n",
      "M  \n",
      "\n",
      "\n",
      "- Mamba - Glossary- Masked Language Modeling (MLM) - Glossary- MASS (Multi-Agent System Search) - Chapter 17: Reasoning Techniques- MCP (Model Context Protocol) - Chapter 10: Model Context Protocol (MCP)- Memory Management - Chapter 8: Memory Management- Memory-Based Learning - Chapter 9: Learning and Adaptation- MetaGPT - Appendix C- Microsoft AutoGen - Appendix C- Mixture of Experts (MoE) - Glossary- Model Context Protocol (MCP) - Chapter 10: Model Context Protocol (MCP)- Modularity - Chapter 18: Guardrails/Safety Patterns- Monitoring - Chapter 11: Goal Setting and Monitoring, Chapter 19: Evaluation and Monitoring- Multi-Agent Collaboration - Chapter 7: Multi-Agent Collaboration- Multi-Agent System Search (MASS) - Chapter 17: Reasoning Techniques- Multimodality - Glossary- Multimodal Prompting - Appendix A  \n",
      "\n",
      "\n",
      "N  \n",
      "\n",
      "\n",
      "- Negative Examples - Appendix A- Next Sentence Prediction (NSP) - Glossary  \n",
      "\n",
      "\n",
      "O  \n",
      "\n",
      "\n",
      "- Observability - Chapter 18: Guardrails/Safety Patterns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- One-Shot Prompting \n",
      "- Appendix A- Online Learning \n",
      "- Chapter 9: Learning and Adaptation- OpenAI Deep Research API \n",
      "- Chapter 6: Planning- OpenEvolve \n",
      "- Chapter 9: Learning and Adaptation- OpenRouter \n",
      "- Chapter 16: Resource-Aware Optimization- Output Filtering/Post-processing \n",
      "- Chapter 18: Guardrails/Safety Patterns  \n",
      "\n",
      "\n",
      "## P  \n",
      "\n",
      "\n",
      "- PAL (Program-Aided Language Models) \n",
      "- Chapter 17: Reasoning Techniques- Parallelization \n",
      "- Chapter 3: Parallelization- Parallelization & Distributed Computing Awareness \n",
      "- Chapter 16: Resource-Aware Optimization- Parameter-Efficient Fine-Tuning (PEFT) \n",
      "- Glossary- PEFT (Parameter-Efficient Fine-Tuning) \n",
      "- Glossary- Performance Tracking \n",
      "- Chapter 19: Evaluation and Monitoring- Persona Pattern \n",
      "- Appendix A- Personalization \n",
      "- What makes an AI system an Agent?- Planning \n",
      "- Chapter 6: Planning, Glossary- Prioritization \n",
      "- Chapter 20: Prioritization- Principle of Least Privilege \n",
      "- Chapter 18: Guardrails/Safety Patterns- Proactive Resource Prediction \n",
      "- Chapter 16: Resource-Aware Optimization- Procedural Memory \n",
      "- Chapter 8: Memory Management- Program-Aided Language Models (PAL) \n",
      "- Chapter 17: Reasoning Techniques- Project Astra \n",
      "- Appendix B- Prompt \n",
      "- Glossary- Prompt Chaining \n",
      "- Chapter 1: Prompt Chaining- Prompt Engineering \n",
      "- Appendix A- Proximal Policy Optimization (PPO) \n",
      "- Chapter 9: Learning and Adaptation- Push Notifications \n",
      "- Chapter 15: Inter-Agent Communication (A2A)  \n",
      "\n",
      "\n",
      "## Q  \n",
      "\n",
      "\n",
      "- QLoRA \n",
      "- Glossary- Quality-Focused Iterative Execution \n",
      "- Chapter 19: Evaluation and Monitoring  \n",
      "\n",
      "\n",
      "## R  \n",
      "\n",
      "\n",
      "- RAG (Retrieval-Augmented Generation) \n",
      "- Chapter 8: Memory Management, Chapter 14: Knowledge Retrieval (RAG), Appendix A- ReAct (Reason and Act) \n",
      "- Chapter 17: Reasoning Techniques, Appendix A, Glossary- Reasoning \n",
      "- Chapter 17: Reasoning Techniques- Reasoning-Based Information Extraction \n",
      "- Chapter 10: Model Context Protocol (MCP)- Recovery \n",
      "- Chapter 12: Exception Handling and Recovery- Recurrent Neural Network (RNN) \n",
      "- Glossary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Reflection - Chapter 4: Reflection- Reinforcement Learning - Chapter 9: Learning and Adaptation- Reinforcement Learning from Human Feedback (RLHF) - Glossary- Reinforcement Learning with Verifiable Rewards (RLVR) - Chapter 17: Reasoning Techniques- Remote Agent - Chapter 15: Inter-Agent Communication (A2A)- Request/Response (Polling) - Chapter 15: Inter-Agent Communication (A2A)- Resource-Aware Optimization - Chapter 16: Resource-Aware Optimization- Retrieval-Augmented Generation (RAG) - Chapter 8: Memory Management, Chapter 14: Knowledge Retrieval (RAG), Appendix A- RLHF (Reinforcement Learning from Human Feedback) - Glossary- RLVR (Reinforcement Learning with Verifiable Rewards) - Chapter 17: Reasoning Techniques- RNN (Recurrent Neural Network) - Glossary- Role Prompting - Appendix A- Router Agent - Chapter 16: Resource-Aware Optimization- Routing - Chapter 2: Routing  \n",
      "\n",
      "\n",
      "## S  \n",
      "\n",
      "\n",
      "- Safety - Chapter 18: Guardrails/Safety Patterns- Scaling Inference Law - Chapter 17: Reasoning Techniques- Scheduling - Chapter 20: Prioritization- Self-Consistency - Appendix A- Self-Correction - Chapter 4: Reflection, Chapter 17: Reasoning Techniques- Self-Improving Coding Agent (SICA) - Chapter 9: Learning and Adaptation- Self-Refinement - Chapter 17: Reasoning Techniques- Semantic Kernel - Appendix C- Semantic Memory - Chapter 8: Memory Management- Semantic Similarity - Chapter 14: Knowledge Retrieval (RAG)- Separation of Concerns - Chapter 18: Guardrails/Safety Patterns- Sequential Handoffs - Chapter 7: Multi-Agent Collaboration- Server-Sent Events (SSE) - Chapter 15: Inter-Agent Communication (A2A)- Session - Chapter 8: Memory Management- SICA (Self-Improving Coding Agent) - Chapter 9: Learning and Adaptation- SMART Goals - Chapter 11: Goal Setting and Monitoring- State - Chapter 8: Memory Management- State Rollback - Chapter 12: Exception Handling and Recovery- Step-Back Prompting - Appendix A- Streaming Updates - Chapter 15: Inter-Agent Communication (A2A)- Structured Logging - Chapter 18: Guardrails/Safety Patterns- Structured Output - Chapter 1: Prompt Chaining, Appendix A- SuperAGI - Appendix C- Supervised Fine-Tuning (SFT) - Glossary- Supervised Learning - Chapter 9: Learning and Adaptation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- System Prompting - Appendix A  \n",
      "\n",
      "\n",
      "T  \n",
      "\n",
      "\n",
      "- Task Evaluation - Chapter 20: Prioritization- Text Similarity - Chapter 14: Knowledge Retrieval (RAG)- Token Usage - Chapter 19: Evaluation and Monitoring- Tool Use - Chapter 5: Tool Use, Appendix A- Tool Use Restrictions - Chapter 18: Guardrails/Safety Patterns- ToT (Tree of Thoughts) - Chapter 17: Reasoning Techniques, Appendix A, Glossary- Transformers - Glossary- Tree of Thoughts (ToT) - Chapter 17: Reasoning Techniques, Appendix A, Glossary  \n",
      "\n",
      "\n",
      "U  \n",
      "\n",
      "\n",
      "- Unsupervised Learning - Chapter 9: Learning and Adaptation- User Persona - Appendix A  \n",
      "\n",
      "\n",
      "V  \n",
      "\n",
      "\n",
      "- Validation - Chapter 3: Parallelization- Vector Search - Chapter 14: Knowledge Retrieval (RAG)- VertexAiRagMemoryService - Chapter 8: Memory Management- VertexAiSessionService - Chapter 8: Memory Management- Vibe Coding - Appendix B- Visual Perception - Appendix B  \n",
      "\n",
      "\n",
      "W  \n",
      "\n",
      "\n",
      "- Webhooks - Chapter 15: Inter-Agent Communication (A2A)  \n",
      "\n",
      "\n",
      "Z  \n",
      "\n",
      "\n",
      "- Zero-Shot Learning - Chapter 9: Learning and Adaptation- Zero-Shot Prompting - Appendix A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Prompt  \n",
      "\n",
      "\n",
      "Below is the prompt that was utilized to create this index of terms.  \n",
      "\n",
      "\n",
      "do you read https://docs.google.com/document/d/1rsaK53T3Lg5KoGwwf8ukOUvbeLRLth-V0LnOIFDxBryE/ edit?tab=t.0 and all the related documents in the first page Please extract all the titles for each chapter. and print them. Then process the content of all the individual chapters, and create a detailed index used for publishing, a list of words or phrases ('headings') and associated pointers ('locators') to where useful material relating to that heading can be found in a document or collection of documents. I don't want a sample index. I want the full index, with 100 index terms  \n",
      "\n",
      "\n",
      "## Gemini 2.5: Reasoning Steps  \n",
      "\n",
      "\n",
      "## Beginning Index Creation  \n",
      "\n",
      "\n",
      "I've initiated the process by reading the Google Doc provided. Currently, I'm focusing on understanding the user's request: extracting chapter titles to build a detailed index. I'm carefully reviewing the document, looking for clear structural elements that would indicate chapter breaks. I'm hoping to identify consistent formatting or keywords that will guide the indexing process.  \n",
      "\n",
      "\n",
      "## Defining Index Extraction Process  \n",
      "\n",
      "\n",
      "I'm now fully immersed in the task. I've broken down the user's request into actionable steps. My initial focus is using Workspaces to access the main Google Doc. Following this, I'll parse the document to locate and retrieve related documents, which will also be accessed using the same tool. Finally, I will extract all chapter titles from all the documents, and create a comprehensive index. I've planned the detailed process.  \n",
      "\n",
      "\n",
      "## Refining the Extraction Strategy  \n",
      "\n",
      "\n",
      "The user's instructions are clear: read a Google Doc, its related documents, and build a detailed index of chapter titles. I've devised a multi- step plan. First, Workspaces will access the main Google Doc. Then, I'll parse it to find and read related documents, also using Workspaces. I'm now focusing on extracting titles and forming the detailed index with the required terms. I'm prioritizing accuracy to meet the user's specific demands for a comprehensive index.  \n",
      "\n",
      "\n",
      "## 1. Establish user intent:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I've determined the user wants a chapter title list and comprehensive index from the Google Doc and related documents. Now I need to figure out the most effective method for this extraction and indexing process. I'm exploring potential API functionalities to streamline this task, and will need to assess the best strategy for handling different document structures.  \n",
      "\n",
      "\n",
      "## 3. Considering Tool Use  \n",
      "\n",
      "\n",
      "I've extracted the chapter URLs from the main document using a regular expression. Now, I'm ready to utilize Workspaces to retrieve the actual content of each chapter. Once I have the text for each chapter, I'll proceed with indexing.  \n",
      "\n",
      "\n",
      "## Accessing chapter content:  \n",
      "\n",
      "\n",
      "I've successfully identified the URLs for each chapter from the main document, which I can now use with Workspaces. My next step is to retrieve the content from these URLs, which will then allow me to generate the index. I'm focusing on efficiency, aiming to process this information quickly.  \n",
      "\n",
      "\n",
      "## Fetching Chapter Content  \n",
      "\n",
      "\n",
      "I've successfully identified the chapter URLs from the main document and am ready to utilize Workspaces. My plan involves extracting these URLs, batching the calls for efficiency, and then processing the retrieved content to create the desired index. This ensures all relevant information is captured, paving the way for a comprehensive and accurate result.  \n",
      "\n",
      "\n",
      "## Initiating URL Retrieval  \n",
      "\n",
      "\n",
      "I've now successfully extracted the chapter URLs from the main document. Currently, I'm setting up calls to the Workspaces tool, preparing to fetch the content of each chapter. The goal is to obtain the necessary text for indexing. This information will then facilitate the creation of the index with at least 100 terms as requested.  \n",
      "\n",
      "\n",
      "## Initiating Chapter Extraction  \n",
      "\n",
      "\n",
      "I've successfully identified and extracted the chapter URLs from the main document, which I've included above. I am now proceeding to use Workspaces for each URL to obtain the chapter content. The goal is to obtain the necessary text for indexing. This information will then facilitate the creationof the index with at least 100 terms as requested. I've begun to retrieve this information.  \n",
      "\n",
      "\n",
      "## Orchestrating Chapter Retrieval\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I've extracted the chapter URLs and initiated a call to Workspaces. I'm currently retrieving the content for each chapter. To ensure a smooth process, I'm batching the calls to prevent any rate- limiting issues. This should enable me to efficiently compile the text needed for the index.  \n",
      "\n",
      "\n",
      "## Decoding User Request  \n",
      "\n",
      "\n",
      "I've determined the user's need. They require two primary deliverables: first, a comprehensive list of chapter titles extracted from Google Docs, and second, a detailed index containing a minimum of one hundred key terms. The process of extracting titles seems straightforward, while curating the index will involve more nuanced analysis.  \n",
      "\n",
      "\n",
      "## Extracting Titles and Indexing  \n",
      "\n",
      "\n",
      "I've successfully identified the user's need: extracting chapter titles from the provided documents and compiling a comprehensive index. I've fetched the content of 31 Google Docs, including the main document and its chapters. I've confirmed that no additional tools are needed. My plan involves two steps: first, extracting chapter titles from the document filenames, and second, meticulously processing the text to build the index with key terms and chapter locators.  \n",
      "\n",
      "\n",
      "## Developing an Extraction Plan  \n",
      "\n",
      "\n",
      "I've refined my approach to tackle the user's request. I've now formulated a precise plan. Firstly, I will compile the chapter titles from the filenames of the 31 fetched documents. Secondly, and more complexly, I will meticulously analyze the content to create a comprehensive, alphabetically ordered index exceeding 100 entries. I have finalized my extraction and indexing strategy and can now commence execution.  \n",
      "\n",
      "\n",
      "## Crafting the Extraction Strategy  \n",
      "\n",
      "\n",
      "My approach is well- defined. I will compile chapter titles from the filenames of the 31 fetched documents. Subsequently, I'll analyze the content meticulously to construct an alphabetically organized index exceeding 100 entries. I've finalized the extraction and indexing strategy and can now commence implementation. The user's goal of a detailed index, covering content from diverse chapters and appendices within the Agentic Design Patterns series, is now within reach. I'll focus on delivering a thorough response, going beyond a mere sample index.  \n",
      "\n",
      "\n",
      "## Defining the Approach  \n",
      "\n",
      "\n",
      "I've clarified the user's need. I will extract chapter titles from the document filenames. Following that, I will carefully create an index exceeding 100 entries, arranging them\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "alphabetically and noting their chapter locations. I am prepared to begin the indexing and extraction process.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Glossary  \n",
      "\n",
      "\n",
      "Fundamental Concepts  \n",
      "\n",
      "\n",
      "Prompt: A prompt is the input, typically in the form of a question, instruction, or statement, that a user provides to an AI model to elicit a response. The quality and structure of the prompt heavily influence the model's output, making prompt engineering a key skill for effectively using AI.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Context Window: The context window is the maximum number of tokens an AI model can process at once, including both the input and its generated output. This fixed size is a critical limitation, as information outside the window is ignored, while larger windows enable more complex conversations and document analysis.  \n",
      "\n",
      "\n",
      "In- Context Learning: In- context learning is an AI's ability to learn a new task from examples provided directly in the prompt, without requiring any retraining. This powerful feature allows a single, general- purpose model to be adapted to countless specific tasks on the fly.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Zero- Shot, One- Shot, & Few- Shot Prompting: These are prompting techniques where a model is given zero, one, or a few examples of a task to guide its response. Providing more examples generally helps the model better understand the user's intent and improves its accuracy for the specific task.  \n",
      "\n",
      "\n",
      "Multimodality: Multimodality is an AI's ability to understand and process information across multiple data types like text, images, and audio. This allows for more versatile and human- like interactions, such as describing an image or answering a spoken question.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Grounding: Grounding is the process of connecting a model's outputs to verifiable, real- world information sources to ensure factual accuracy and reduce hallucinations. This is often achieved with techniques like RAG to make AI systems more trustworthy.  \n",
      "\n",
      "\n",
      "Core AI Model Architectures  \n",
      "\n",
      "\n",
      "Transformers: The Transformer is the foundational neural network architecture for most modern LLMs. Its key innovation is the self- attention mechanism, which efficiently processes long sequences of text and captures complex relationships between words.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Recurrent Neural Network (RNN): The Recurrent Neural Network is a foundational architecture that preceded the Transformer. RNNs process information sequentially, using loops to maintain a \"memory\" of previous inputs, which made them suitable for tasks like text and speech processing.  \n",
      "\n",
      "\n",
      "Mixture of Experts (MoE): Mixture of Experts is an efficient model architecture where a \"router\" network dynamically selects a small subset of \"expert\" networks to handle any given input. This allows models to have a massive number of parameters while keeping computational costs manageable.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Diffusion Models: Diffusion models are generative models that excel at creating high- quality images. They work by adding random noise to data and then training a model to meticulously reverse the process, allowing them to generate novel data from a random starting point.  \n",
      "\n",
      "\n",
      "Mamba: Mamba is a recent AI architecture using a Selective State Space Model (SSM) to process sequences with high efficiency, especially for very long contexts. Its selective mechanism allows it to focus on relevant information while filtering out noise, making it a potential alternative to the Transformer.  \n",
      "\n",
      "\n",
      "The LLM Development Lifecycle\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The development of a powerful language model follows a distinct sequence. It begins with Pre- training, where a massive base model is built by training it on a vast dataset of general internet text to learn language, reasoning, and world knowledge. Next is Fine- tuning, a specialization phase where the general model is further trained on smaller, task- specific datasets to adapt its capabilities for a particular purpose. The final stage is Alignment, where the specialized model's behavior is adjusted to ensure its outputs are helpful, harmless, and aligned with human values.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Pre- training Techniques: Pre- training is the initial phase where a model learns general knowledge from vast amounts of data. The top techniques for this involve different objectives for the model to learn from. The most common is Causal Language Modeling (CLM), where the model predicts the next word in a sentence. Another is Masked Language Modeling (MLM), where the model fills in intentionally hidden words in a text. Other important methods include Denoising Objectives, where the model learns to restore a corrupted input to its original state, Contrastive Learning, where it learns to distinguish between similar and dissimilar pieces of data, and Next Sentence Prediction\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(NSP), where it determines if two sentences logically follow each other.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fine- tuning Techniques: Fine- tuning is the process of adapting a general pre- trained model to a specific task using a smaller, specialized dataset. The most common approach is Supervised Fine- Tuning (SFT), where the model is trained on labeled examples of correct input- output pairs. A popular variant is Instruction Tuning, which focuses on training the model to better follow user commands. To make this process more efficient, Parameter- Efficient Fine- Tuning (PEFT) methods are used, with top techniques including LoRA (Low- Rank Adaptation), which only updates a small number of parameters, and its memory- optimized version, QLoRA. Another technique,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieval- Augmented Generation (RAG), enhances the model by connecting it to an external knowledge source during the fine- tuning or inference stage.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Alignment & Safety Techniques: Alignment is the process of ensuring an Al model's behavior aligns with human values and expectations, making it helpful and harmless. The most prominent technique is Reinforcement Learning from Human Feedback (RLHF), where a \"reward model\" trained on human preferences guides the Al's learning process, often using an algorithm like Proximal Policy Optimization (PPO) for stability. Simpler alternatives have emerged, such as Direct Preference Optimization (DPO), which bypasses the need for a separate reward model, and Kahneman- Tversky Optimization (KTO), which simplifies data collection further. To ensure safe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "deployment, Guardrails are implemented as a final safety layer to filter outputs and block harmful actions in real- time.  \n",
      "\n",
      "\n",
      "Enhancing AI Agent CapabilitiesAI agents are systems that can perceive their environment and take autonomous actions to achieve goals. Their effectiveness is enhanced by robust reasoning frameworks.  \n",
      "\n",
      "\n",
      "Chain of Thought (CoT): This prompting technique encourages a model to explain its reasoning step- by- step before giving a final answer. This process of \"thinking out loud\" often leads to more accurate results on complex reasoning tasks.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tree of Thoughts (ToT): Tree of Thoughts is an advanced reasoning framework where an agent explores multiple reasoning paths simultaneously, like branches on a tree. It allows the agent to self- evaluate different lines of thought and choose the most promising one to pursue, making it more effective at complex problem- solving.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ReAct (Reason and Act): ReAct is an agent framework that combines reasoning and acting in a loop. The agent first \"thinks\" about what to do, then takes an \"action\" using a tool, and uses the resulting observation to inform its next thought, making it highly effective at solving complex tasks.  \n",
      "\n",
      "\n",
      "Planning: This is an agent's ability to break down a high- level goal into a sequence of smaller, manageable sub- tasks. The agent then creates a plan to execute these steps in order, allowing it to handle complex, multi- step assignments.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Deep Research: Deep research refers to an agent's capability to autonomously explore a topic in- depth by iteratively searching for information, synthesizing findings, and identifying new questions. This allows the agent to build a comprehensive understanding of a subject far beyond a single search query.  \n",
      "\n",
      "\n",
      "Critique Model: A critique model is a specialized AI model trained to review, evaluate, and provide feedback on the output of another AI model. It acts as an automated critic, helping to identify errors, improve reasoning, and ensure the final output meets a desired quality standard.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Index of Terms  \n",
      "\n",
      "\n",
      "This index of terms was generated using Gemini Pro 2.5. The prompt and reasoning steps are included at the end to demonstrate the time- saving benefits and for educational purposes.  \n",
      "\n",
      "\n",
      "## A  \n",
      "\n",
      "\n",
      "- A/B Testing \n",
      "- Chapter 3: Parallelization- Action Selection \n",
      "- Chapter 20: Prioritization- Adaptation \n",
      "- Chapter 9: Learning and Adaptation- Adaptive Task Allocation \n",
      "- Chapter 16: Resource-Aware Optimization- Adaptive Tool Use & Selection \n",
      "- Chapter 16: Resource-Aware Optimization- Agent \n",
      "- What makes an AI system an Agent?- Agent-Computer Interfaces (ACIs) \n",
      "- Appendix B- Agent-Driven Economy \n",
      "- What makes an AI system an Agent?- Agent as a Tool \n",
      "- Chapter 7: Multi-Agent Collaboration- Agent Cards \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Agent Development Kit (ADK) \n",
      "- Chapter 2: Routing, Chapter 3: Parallelization, Chapter 4: Reflection, Chapter 5: Tool Use, Chapter 7: Multi-Agent Collaboration, Chapter 8: Memory Management, Chapter 12: Exception Handling and Recovery, Chapter 13: Human-in-the-Loop, Chapter 15: Inter-Agent Communication (A2A), Chapter 16: Resource-Aware Optimization, Chapter 19: Evaluation and Monitoring, Appendix C- Agent Discovery \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Agent Trajectories \n",
      "- Chapter 19: Evaluation and Monitoring- Agentic Design Patterns \n",
      "- Introduction- Agentic RAG \n",
      "- Chapter 14: Knowledge Retrieval (RAG)- Agentic Systems \n",
      "- Introduction- AI Co-scientist \n",
      "- Chapter 21: Exploration and Discovery- Alignment \n",
      "- Glossary- AlphaEvolve \n",
      "- Chapter 9: Learning and Adaptation- Analogies \n",
      "- Appendix A- Anomaly Detection \n",
      "- Chapter 19: Evaluation and Monitoring- Anthropic's Claude 4 Series \n",
      "- Appendix B- Anthropic's Computer Use \n",
      "- Appendix B- API Interaction \n",
      "- Chapter 10: Model Context Protocol (MCP)- Artifacts \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Asynchronous Polling \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Audit Logs \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Automated Metrics \n",
      "- Chapter 19: Evaluation and Monitoring- Automatic Prompt Engineering (APE) \n",
      "- Appendix A- Autonomy \n",
      "- Introduction- A2A (Agent-to-Agent) \n",
      "- Chapter 15: Inter-Agent Communication (A2A)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Behavioral Constraints - Chapter 18: Guardrails/Safety Patterns- Browser Use - Appendix B  \n",
      "\n",
      "\n",
      "C  \n",
      "\n",
      "\n",
      "- Callbacks - Chapter 18: Guardrails/Safety Patterns- Causal Language Modeling (CLM) - Glossary- Chain of Debates (CoD) - Chapter 17: Reasoning Techniques- Chain-of-Thought (CoT) - Chapter 17: Reasoning Techniques, Appendix A- Chatbots - Chapter 8: Memory Management- ChatMessageHistory - Chapter 8: Memory Management- Checkpoint and Rollback - Chapter 18: Guardrails/Safety Patterns- Chunking - Chapter 14: Knowledge Retrieval (RAG)- Clarity and Specificity - Appendix A- Client Agent - Chapter 15: Inter-Agent Communication (A2A)- Code Generation - Chapter 1: Prompt Chaining, Chapter 4: Reflection- Code Prompting - Appendix A- CoD (Chain of Debates) - Chapter 17: Reasoning Techniques- CoT (Chain of Thought) - Chapter 17: Reasoning Techniques, Appendix A- Collaboration - Chapter 7: Multi-Agent Collaboration- Compliance - Chapter 19: Evaluation and Monitoring- Conciseness - Appendix A- Content Generation - Chapter 1: Prompt Chaining, Chapter 4: Reflection- Context Engineering - Chapter 1: Prompt Chaining- Context Window - Glossary- Contextual Pruning & Summarization - Chapter 16: Resource-Aware Optimization- Contextual Prompting - Appendix A- Contractor Model - Chapter 19: Evaluation and Monitoring- ConversationBufferMemory - Chapter 8: Memory Management- Conversational Agents - Chapter 1: Prompt Chaining, Chapter 4: Reflection- Cost-Sensitive Exploration - Chapter 16: Resource-Aware Optimization- CrewAI - Chapter 3: Parallelization, Chapter 5: Tool Use, Chapter 6: Planning, Chapter 7: Multi-Agent Collaboration, Chapter 18: Guardrails/Safety Patterns, Appendix C- Critique Agent - Chapter 16: Resource-Aware Optimization- Critique Model - Glossary- Customer Support - Chapter 13: Human-in-the-Loop  \n",
      "\n",
      "\n",
      "D  \n",
      "\n",
      "\n",
      "- Data Extraction - Chapter 1: Prompt Chaining- Data Labeling - Chapter 13: Human-in-the-Loop- Database Integration - Chapter 10: Model Context Protocol (MCP)- DatabaseSessionService - Chapter 8: Memory Management\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Debate and Consensus \n",
      "- Chapter 7: Multi-Agent Collaboration- Decision Augmentation \n",
      "- Chapter 13: Human-in-the-Loop- Decomposition \n",
      "- Appendix A- Deep Research \n",
      "- Chapter 6: Planning, Chapter 17: Reasoning Techniques, Glossary- Delimiters \n",
      "- Appendix A- Denoising Objectives \n",
      "- Glossary- Dependencies \n",
      "- Chapter 20: Prioritization- Diffusion Models \n",
      "- Glossary- Direct Preference Optimization (DPO) \n",
      "- Chapter 9: Learning and Adaptation- Discoverability \n",
      "- Chapter 10: Model Context Protocol (MCP)- Drift Detection \n",
      "- Chapter 19: Evaluation and Monitoring- Dynamic Model Switching \n",
      "- Chapter 16: Resource-Aware Optimization- Dynamic Re-prioritization \n",
      "- Chapter 20: Prioritization  \n",
      "\n",
      "\n",
      "## E  \n",
      "\n",
      "\n",
      "- Embeddings \n",
      "- Chapter 14: Knowledge Retrieval (RAG)- Embodiment \n",
      "- What makes an AI system an Agent?- Energy-Efficient Deployment \n",
      "- Chapter 16: Resource-Aware Optimization- Episodic Memory \n",
      "- Chapter 8: Memory Management- Error Detection \n",
      "- Chapter 12: Exception Handling and Recovery- Error Handling \n",
      "- Chapter 12: Exception Handling and Recovery- Escalation Policies \n",
      "- Chapter 13: Human-in-the-Loop- Evaluation \n",
      "- Chapter 19: Evaluation and Monitoring- Exception Handling \n",
      "- Chapter 12: Exception Handling and Recovery- Expert Teams \n",
      "- Chapter 7: Multi-Agent Collaboration- Exploration and Discovery \n",
      "- Chapter 21: Exploration and Discovery- External Moderation APIs \n",
      "- Chapter 18: Guardrails/Safety Patterns  \n",
      "\n",
      "\n",
      "## F  \n",
      "\n",
      "\n",
      "- Factored Cognition \n",
      "- Appendix A- FastMCP \n",
      "- Chapter 10: Model Context Protocol (MCP)- Fault Tolerance \n",
      "- Chapter 18: Guardrails/Safety Patterns- Few-Shot Learning \n",
      "- Chapter 9: Learning and Adaptation- Few-Shot Prompting \n",
      "- Appendix A- Fine-tuning \n",
      "- Glossary- Formalized Contract \n",
      "- Chapter 19: Evaluation and Monitoring- Function Calling \n",
      "- Chapter 5: Tool Use, Appendix A  \n",
      "\n",
      "\n",
      "## G  \n",
      "\n",
      "\n",
      "- Gemini Live \n",
      "- Appendix B- Gems \n",
      "- Appendix A- Generative Media Orchestration \n",
      "- Chapter 10: Model Context Protocol (MCP)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Goal Setting \n",
      "- Chapter 11: Goal Setting and Monitoring- GoD (Graph of Debates) \n",
      "- Chapter 17: Reasoning Techniques- Google Agent Development Kit (ADK) \n",
      "- Chapter 2: Routing, Chapter 3: Parallelization, Chapter 4: Reflection, Chapter 5: Tool Use, Chapter 7: Multi-Agent Collaboration, Chapter 8: Memory Management, Chapter 12: Exception Handling and Recovery, Chapter 13: Human-in-the-Loop, Chapter 15: Inter-Agent Communication (A2A), Chapter 16: Resource-Aware Optimization, Chapter 19: Evaluation and Monitoring, Appendix C- Google Co-Scientist \n",
      "- Chapter 21: Exploration and Discovery- Google DeepResearch \n",
      "- Chapter 6: Planning- Google Project Mariner \n",
      "- Appendix B- Graceful Degradation \n",
      "- Chapter 12: Exception Handling and Recovery, Chapter 16: Resource-Aware Optimization- Graph of Debates (GoD) \n",
      "- Chapter 17: Reasoning Techniques- Grounding \n",
      "- Glossary- Guardrails \n",
      "- Chapter 18: Guardrails/Safety Patterns  \n",
      "\n",
      "\n",
      "## H  \n",
      "\n",
      "\n",
      "- Haystack \n",
      "- Appendix C- Hierarchical Decomposition \n",
      "- Chapter 19: Evaluation and Monitoring- Hierarchical Structures \n",
      "- Chapter 7: Multi-Agent Collaboration- HITL (Human-in-the-Loop) \n",
      "- Chapter 13: Human-in-the-Loop- Human-in-the-Loop (HITL) \n",
      "- Chapter 13: Human-in-the-Loop- Human-on-the-loop \n",
      "- Chapter 13: Human-in-the-Loop- Human Oversight \n",
      "- Chapter 13: Human-in-the-Loop, Chapter 18: Guardrails/Safety Patterns  \n",
      "\n",
      "\n",
      "## I  \n",
      "\n",
      "\n",
      "- In-Context Learning \n",
      "- Glossary- InMemoryMemoryService \n",
      "- Chapter 8: Memory Management- InMemorySessionService \n",
      "- Chapter 8: Memory Management- Input Validation/Sanitization \n",
      "- Chapter 18: Guardrails/Safety Patterns- Instructions Over Constraints \n",
      "- Appendix A- Inter-Agent Communication (A2A) \n",
      "- Chapter 15: Inter-Agent Communication (A2A)- Intervention and Correction \n",
      "- Chapter 13: Human-in-the-Loop- IoT Device Control \n",
      "- Chapter 10: Model Context Protocol (MCP)- Iterative Prompting / Refinement \n",
      "- Appendix A  \n",
      "\n",
      "\n",
      "## J  \n",
      "\n",
      "\n",
      "- Jailbreaking \n",
      "- Chapter 18: Guardrails/Safety Patterns  \n",
      "\n",
      "\n",
      "## K  \n",
      "\n",
      "\n",
      "- Kahneman-Tversky Optimization (KTO) \n",
      "- Glossary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Knowledge Retrieval (RAG) - Chapter 14: Knowledge Retrieval (RAG)  \n",
      "\n",
      "\n",
      "L  \n",
      "\n",
      "\n",
      "- LangChain - Chapter 1: Prompt Chaining, Chapter 2: Routing, Chapter 3: Parallelization, Chapter 4: Reflection, Chapter 5: Tool Use, Chapter 8: Memory Management, Chapter 20: Prioritization, Appendix C- LangGraph - Chapter 1: Prompt Chaining, Chapter 2: Routing, Chapter 3:Parallelization, Chapter 4: Reflection, Chapter 5: Tool Use, Chapter 8:Memory Management, Appendix C- Latency Monitoring - Chapter 19: Evaluation and Monitoring- Learned Resource Allocation Policies - Chapter 16: Resource-Aware Optimization- Learning and Adaptation - Chapter 9: Learning and Adaptation- LLM-as-a-Judge - Chapter 19: Evaluation and Monitoring- LlamaIndex - Appendix C- LoRA (Low-Rank Adaptation) - Glossary- Low-Rank Adaptation (LoRA) - Glossary  \n",
      "\n",
      "\n",
      "M  \n",
      "\n",
      "\n",
      "- Mamba - Glossary- Masked Language Modeling (MLM) - Glossary- MASS (Multi-Agent System Search) - Chapter 17: Reasoning Techniques- MCP (Model Context Protocol) - Chapter 10: Model Context Protocol (MCP)- Memory Management - Chapter 8: Memory Management- Memory-Based Learning - Chapter 9: Learning and Adaptation- MetaGPT - Appendix C- Microsoft AutoGen - Appendix C- Mixture of Experts (MoE) - Glossary- Model Context Protocol (MCP) - Chapter 10: Model Context Protocol (MCP)- Modularity - Chapter 18: Guardrails/Safety Patterns- Monitoring - Chapter 11: Goal Setting and Monitoring, Chapter 19: Evaluation and Monitoring- Multi-Agent Collaboration - Chapter 7: Multi-Agent Collaboration- Multi-Agent System Search (MASS) - Chapter 17: Reasoning Techniques- Multimodality - Glossary- Multimodal Prompting - Appendix A  \n",
      "\n",
      "\n",
      "N  \n",
      "\n",
      "\n",
      "- Negative Examples - Appendix A- Next Sentence Prediction (NSP) - Glossary  \n",
      "\n",
      "\n",
      "O  \n",
      "\n",
      "\n",
      "- Observability - Chapter 18: Guardrails/Safety Patterns\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- One-Shot Prompting \n",
      "- Appendix A- Online Learning \n",
      "- Chapter 9: Learning and Adaptation- OpenAI Deep Research API \n",
      "- Chapter 6: Planning- OpenEvolve \n",
      "- Chapter 9: Learning and Adaptation- OpenRouter \n",
      "- Chapter 16: Resource-Aware Optimization- Output Filtering/Post-processing \n",
      "- Chapter 18: Guardrails/Safety Patterns  \n",
      "\n",
      "\n",
      "## P  \n",
      "\n",
      "\n",
      "- PAL (Program-Aided Language Models) \n",
      "- Chapter 17: Reasoning Techniques- Parallelization \n",
      "- Chapter 3: Parallelization- Parallelization & Distributed Computing Awareness \n",
      "- Chapter 16: Resource-Aware Optimization- Parameter-Efficient Fine-Tuning (PEFT) \n",
      "- Glossary- PEFT (Parameter-Efficient Fine-Tuning) \n",
      "- Glossary- Performance Tracking \n",
      "- Chapter 19: Evaluation and Monitoring- Persona Pattern \n",
      "- Appendix A- Personalization \n",
      "- What makes an AI system an Agent?- Planning \n",
      "- Chapter 6: Planning, Glossary- Prioritization \n",
      "- Chapter 20: Prioritization- Principle of Least Privilege \n",
      "- Chapter 18: Guardrails/Safety Patterns- Proactive Resource Prediction \n",
      "- Chapter 16: Resource-Aware Optimization- Procedural Memory \n",
      "- Chapter 8: Memory Management- Program-Aided Language Models (PAL) \n",
      "- Chapter 17: Reasoning Techniques- Project Astra \n",
      "- Appendix B- Prompt \n",
      "- Glossary- Prompt Chaining \n",
      "- Chapter 1: Prompt Chaining- Prompt Engineering \n",
      "- Appendix A- Proximal Policy Optimization (PPO) \n",
      "- Chapter 9: Learning and Adaptation- Push Notifications \n",
      "- Chapter 15: Inter-Agent Communication (A2A)  \n",
      "\n",
      "\n",
      "## Q  \n",
      "\n",
      "\n",
      "- QLoRA \n",
      "- Glossary- Quality-Focused Iterative Execution \n",
      "- Chapter 19: Evaluation and Monitoring  \n",
      "\n",
      "\n",
      "## R  \n",
      "\n",
      "\n",
      "- RAG (Retrieval-Augmented Generation) \n",
      "- Chapter 8: Memory Management, Chapter 14: Knowledge Retrieval (RAG), Appendix A- ReAct (Reason and Act) \n",
      "- Chapter 17: Reasoning Techniques, Appendix A, Glossary- Reasoning \n",
      "- Chapter 17: Reasoning Techniques- Reasoning-Based Information Extraction \n",
      "- Chapter 10: Model Context Protocol (MCP)- Recovery \n",
      "- Chapter 12: Exception Handling and Recovery- Recurrent Neural Network (RNN) \n",
      "- Glossary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Reflection - Chapter 4: Reflection- Reinforcement Learning - Chapter 9: Learning and Adaptation- Reinforcement Learning from Human Feedback (RLHF) - Glossary- Reinforcement Learning with Verifiable Rewards (RLVR) - Chapter 17: Reasoning Techniques- Remote Agent - Chapter 15: Inter-Agent Communication (A2A)- Request/Response (Polling) - Chapter 15: Inter-Agent Communication (A2A)- Resource-Aware Optimization - Chapter 16: Resource-Aware Optimization- Retrieval-Augmented Generation (RAG) - Chapter 8: Memory Management, Chapter 14: Knowledge Retrieval (RAG), Appendix A- RLHF (Reinforcement Learning from Human Feedback) - Glossary- RLVR (Reinforcement Learning with Verifiable Rewards) - Chapter 17: Reasoning Techniques- RNN (Recurrent Neural Network) - Glossary- Role Prompting - Appendix A- Router Agent - Chapter 16: Resource-Aware Optimization- Routing - Chapter 2: Routing  \n",
      "\n",
      "\n",
      "## S  \n",
      "\n",
      "\n",
      "- Safety - Chapter 18: Guardrails/Safety Patterns- Scaling Inference Law - Chapter 17: Reasoning Techniques- Scheduling - Chapter 20: Prioritization- Self-Consistency - Appendix A- Self-Correction - Chapter 4: Reflection, Chapter 17: Reasoning Techniques- Self-Improving Coding Agent (SICA) - Chapter 9: Learning and Adaptation- Self-Refinement - Chapter 17: Reasoning Techniques- Semantic Kernel - Appendix C- Semantic Memory - Chapter 8: Memory Management- Semantic Similarity - Chapter 14: Knowledge Retrieval (RAG)- Separation of Concerns - Chapter 18: Guardrails/Safety Patterns- Sequential Handoffs - Chapter 7: Multi-Agent Collaboration- Server-Sent Events (SSE) - Chapter 15: Inter-Agent Communication (A2A)- Session - Chapter 8: Memory Management- SICA (Self-Improving Coding Agent) - Chapter 9: Learning and Adaptation- SMART Goals - Chapter 11: Goal Setting and Monitoring- State - Chapter 8: Memory Management- State Rollback - Chapter 12: Exception Handling and Recovery- Step-Back Prompting - Appendix A- Streaming Updates - Chapter 15: Inter-Agent Communication (A2A)- Structured Logging - Chapter 18: Guardrails/Safety Patterns- Structured Output - Chapter 1: Prompt Chaining, Appendix A- SuperAGI - Appendix C- Supervised Fine-Tuning (SFT) - Glossary- Supervised Learning - Chapter 9: Learning and Adaptation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- System Prompting - Appendix A  \n",
      "\n",
      "\n",
      "T  \n",
      "\n",
      "\n",
      "- Task Evaluation - Chapter 20: Prioritization- Text Similarity - Chapter 14: Knowledge Retrieval (RAG)- Token Usage - Chapter 19: Evaluation and Monitoring- Tool Use - Chapter 5: Tool Use, Appendix A- Tool Use Restrictions - Chapter 18: Guardrails/Safety Patterns- ToT (Tree of Thoughts) - Chapter 17: Reasoning Techniques, Appendix A, Glossary- Transformers - Glossary- Tree of Thoughts (ToT) - Chapter 17: Reasoning Techniques, Appendix A, Glossary  \n",
      "\n",
      "\n",
      "U  \n",
      "\n",
      "\n",
      "- Unsupervised Learning - Chapter 9: Learning and Adaptation- User Persona - Appendix A  \n",
      "\n",
      "\n",
      "V  \n",
      "\n",
      "\n",
      "- Validation - Chapter 3: Parallelization- Vector Search - Chapter 14: Knowledge Retrieval (RAG)- VertexAiRagMemoryService - Chapter 8: Memory Management- VertexAiSessionService - Chapter 8: Memory Management- Vibe Coding - Appendix B- Visual Perception - Appendix B  \n",
      "\n",
      "\n",
      "W  \n",
      "\n",
      "\n",
      "- Webhooks - Chapter 15: Inter-Agent Communication (A2A)  \n",
      "\n",
      "\n",
      "Z  \n",
      "\n",
      "\n",
      "- Zero-Shot Learning - Chapter 9: Learning and Adaptation- Zero-Shot Prompting - Appendix A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Prompt  \n",
      "\n",
      "\n",
      "Below is the prompt that was utilized to create this index of terms.  \n",
      "\n",
      "\n",
      "do you read https://docs.google.com/document/d/1rsaK53T3Lg5KoGwwf8ukOUvbeLRLth-V0LnOIFDxBryE/ edit?tab=t.0 and all the related documents in the first page Please extract all the titles for each chapter. and print them. Then process the content of all the individual chapters, and create a detailed index used for publishing, a list of words or phrases ('headings') and associated pointers ('locators') to where useful material relating to that heading can be found in a document or collection of documents. I don't want a sample index. I want the full index, with 100 index terms  \n",
      "\n",
      "\n",
      "## Gemini 2.5: Reasoning Steps  \n",
      "\n",
      "\n",
      "## Beginning Index Creation  \n",
      "\n",
      "\n",
      "I've initiated the process by reading the Google Doc provided. Currently, I'm focusing on understanding the user's request: extracting chapter titles to build a detailed index. I'm carefully reviewing the document, looking for clear structural elements that would indicate chapter breaks. I'm hoping to identify consistent formatting or keywords that will guide the indexing process.  \n",
      "\n",
      "\n",
      "## Defining Index Extraction Process  \n",
      "\n",
      "\n",
      "I'm now fully immersed in the task. I've broken down the user's request into actionable steps. My initial focus is using Workspaces to access the main Google Doc. Following this, I'll parse the document to locate and retrieve related documents, which will also be accessed using the same tool. Finally, I will extract all chapter titles from all the documents, and create a comprehensive index. I've planned the detailed process.  \n",
      "\n",
      "\n",
      "## Refining the Extraction Strategy  \n",
      "\n",
      "\n",
      "The user's instructions are clear: read a Google Doc, its related documents, and build a detailed index of chapter titles. I've devised a multi- step plan. First, Workspaces will access the main Google Doc. Then, I'll parse it to find and read related documents, also using Workspaces. I'm now focusing on extracting titles and forming the detailed index with the required terms. I'm prioritizing accuracy to meet the user's specific demands for a comprehensive index.  \n",
      "\n",
      "\n",
      "## 1. Establish user intent:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I've determined the user wants a chapter title list and comprehensive index from the Google Doc and related documents. Now I need to figure out the most effective method for this extraction and indexing process. I'm exploring potential API functionalities to streamline this task, and will need to assess the best strategy for handling different document structures.  \n",
      "\n",
      "\n",
      "## 3. Considering Tool Use  \n",
      "\n",
      "\n",
      "I've extracted the chapter URLs from the main document using a regular expression. Now, I'm ready to utilize Workspaces to retrieve the actual content of each chapter. Once I have the text for each chapter, I'll proceed with indexing.  \n",
      "\n",
      "\n",
      "## Accessing chapter content:  \n",
      "\n",
      "\n",
      "I've successfully identified the URLs for each chapter from the main document, which I can now use with Workspaces. My next step is to retrieve the content from these URLs, which will then allow me to generate the index. I'm focusing on efficiency, aiming to process this information quickly.  \n",
      "\n",
      "\n",
      "## Fetching Chapter Content  \n",
      "\n",
      "\n",
      "I've successfully identified the chapter URLs from the main document and am ready to utilize Workspaces. My plan involves extracting these URLs, batching the calls for efficiency, and then processing the retrieved content to create the desired index. This ensures all relevant information is captured, paving the way for a comprehensive and accurate result.  \n",
      "\n",
      "\n",
      "## Initiating URL Retrieval  \n",
      "\n",
      "\n",
      "I've now successfully extracted the chapter URLs from the main document. Currently, I'm setting up calls to the Workspaces tool, preparing to fetch the content of each chapter. The goal is to obtain the necessary text for indexing. This information will then facilitate the creation of the index with at least 100 terms as requested.  \n",
      "\n",
      "\n",
      "## Initiating Chapter Extraction  \n",
      "\n",
      "\n",
      "I've successfully identified and extracted the chapter URLs from the main document, which I've included above. I am now proceeding to use Workspaces for each URL to obtain the chapter content. The goal is to obtain the necessary text for indexing. This information will then facilitate the creationof the index with at least 100 terms as requested. I've begun to retrieve this information.  \n",
      "\n",
      "\n",
      "## Orchestrating Chapter Retrieval\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I've extracted the chapter URLs and initiated a call to Workspaces. I'm currently retrieving the content for each chapter. To ensure a smooth process, I'm batching the calls to prevent any rate- limiting issues. This should enable me to efficiently compile the text needed for the index.  \n",
      "\n",
      "\n",
      "## Decoding User Request  \n",
      "\n",
      "\n",
      "I've determined the user's need. They require two primary deliverables: first, a comprehensive list of chapter titles extracted from Google Docs, and second, a detailed index containing a minimum of one hundred key terms. The process of extracting titles seems straightforward, while curating the index will involve more nuanced analysis.  \n",
      "\n",
      "\n",
      "## Extracting Titles and Indexing  \n",
      "\n",
      "\n",
      "I've successfully identified the user's need: extracting chapter titles from the provided documents and compiling a comprehensive index. I've fetched the content of 31 Google Docs, including the main document and its chapters. I've confirmed that no additional tools are needed. My plan involves two steps: first, extracting chapter titles from the document filenames, and second, meticulously processing the text to build the index with key terms and chapter locators.  \n",
      "\n",
      "\n",
      "## Developing an Extraction Plan  \n",
      "\n",
      "\n",
      "I've refined my approach to tackle the user's request. I've now formulated a precise plan. Firstly, I will compile the chapter titles from the filenames of the 31 fetched documents. Secondly, and more complexly, I will meticulously analyze the content to create a comprehensive, alphabetically ordered index exceeding 100 entries. I have finalized my extraction and indexing strategy and can now commence execution.  \n",
      "\n",
      "\n",
      "## Crafting the Extraction Strategy  \n",
      "\n",
      "\n",
      "My approach is well- defined. I will compile chapter titles from the filenames of the 31 fetched documents. Subsequently, I'll analyze the content meticulously to construct an alphabetically organized index exceeding 100 entries. I've finalized the extraction and indexing strategy and can now commence implementation. The user's goal of a detailed index, covering content from diverse chapters and appendices within the Agentic Design Patterns series, is now within reach. I'll focus on delivering a thorough response, going beyond a mere sample index.  \n",
      "\n",
      "\n",
      "## Defining the Approach  \n",
      "\n",
      "\n",
      "I've clarified the user's need. I will extract chapter titles from the document filenames. Following that, I will carefully create an index exceeding 100 entries, arranging them\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "alphabetically and noting their chapter locations. I am prepared to begin the indexing and extraction process.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Frequently Asked Questions: Agentic Design Patterns  \n",
      "\n",
      "\n",
      "What is an \"agentic design pattern\"? An agentic design pattern is a reusable, high- level solution to a common problem encountered when building intelligent, autonomous systems (agents). These patterns provide a structured framework for designing agent behaviors, much like software design patterns do for traditional programming. They help developers build more robust, predictable, and effective AI agents.  \n",
      "\n",
      "\n",
      "What is the main goal of this guide? The guide aims to provide a practical, hands- on introduction to designing and building agentic systems. It moves beyond theoretical discussions to offer concrete architectural blueprints that developers can use to create agents capable of complex, goal- oriented behavior in a reliable way.  \n",
      "\n",
      "\n",
      "Who is the intended audience for this guide? This guide is written for AI developers, software engineers, and system architects who are building applications with large language models (LLMs) and other AI components. It is for those who want to move from simple prompt- response interactions to creating sophisticated, autonomous agents.  \n",
      "\n",
      "\n",
      "4. What are some of the key agentic patterns discussed? Based on the table of contents, the guide covers several key patterns, including:  \n",
      "\n",
      "\n",
      "Reflection: The ability of an agent to critique its own actions and outputs to improve performance. Planning: The process of breaking down a complex goal into smaller, manageable steps or tasks. Tool Use: The pattern of an agent utilizing external tools (like code interpreters, search engines, or other APIs) to acquire information or perform actions it cannot do on its own. Multi-Agent Collaboration: The architecture for having multiple specialized agents work together to solve a problem, often involving a \"leader\" or \"orchestrator\" agent. Human- in- the- Loop: The integration of human oversight and intervention, allowing for feedback, correction, and approval of an agent's actions.  \n",
      "\n",
      "\n",
      "Why is \"planning\" an important pattern? Planning is crucial because it allows an agent to tackle complex, multi- step tasks that cannot be solved with a single action. By creating a plan, the agent can maintain a coherent strategy, track its progress, and handle errors or unexpected obstacles in a structured manner. This prevents the agent from getting \"stuck\" or deviating from the user's ultimate goal.  \n",
      "\n",
      "\n",
      "What is the difference between a \"tool\" and a \"skill\" for an agent? While the terms are often used interchangeably, a \"tool\" generally refers to an external resource the agent can call upon (e.g., a weather API, a calculator). A \"skill\" is a more integrated capability that the agent has learned, often combining tool use with internal reasoning to perform a specific function (e.g., the skill of \"booking a flight\" might involve using calendar and airline APIs).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "How does the \"Reflection\" pattern improve an agent's performance? Reflection acts as a form of self- correction. After generating a response or completing a task, the agent can be prompted to review its work, check for errors, assess its quality against certain criteria, or consider alternative approaches. This iterative refinement process helps the agent produce more accurate, relevant, and high- quality results.  \n",
      "\n",
      "\n",
      "What is the core idea of the Reflection pattern? The Reflection pattern gives an agent the ability to step back and critique its own work. Instead of producing a final output in one go, the agent generates a draft and then \"reflects\" on it, identifying flaws, missing information, or areas for improvement. This self- correction process is key to enhancing the quality and accuracy of its responses.  \n",
      "\n",
      "\n",
      "Why is simple \"prompt chaining\" not enough for high- quality output? Simple prompt chaining (where the output of one prompt becomes the input for the next) is often too basic. The model might just rephrase its previous output without genuinely improving it. A true Reflection pattern requires a more structured critique, prompting the agent to analyze its work against specific standards, check for logical errors, or verify facts.  \n",
      "\n",
      "\n",
      "What are the two main types of reflection mentioned in this chapter? The chapter discusses two primary forms of reflection:  \n",
      "\n",
      "\n",
      "\"Check your work\" Reflection: This is a basic form where the agent is simply asked to review and fix its previous output. It's a good starting point for catching simple errors. \"Internal Critic\" Reflection: This is a more advanced form where a separate, \"critic\" agent (or a dedicated prompt) is used to evaluate the output of the \"worker\" agent. This critic can be given specific criteria to look for, leading to more rigorous and targeted improvements.  \n",
      "\n",
      "\n",
      "How does reflection help in reducing \"hallucinations\"? By prompting an agent to review its work, especially by comparing its statements against a known source or by checking its own reasoning steps, the Reflection pattern can significantly reduce the likelihood of hallucinations (making up facts). The agent is forced to be more grounded in the provided context and less likely to generate unsupported information.  \n",
      "\n",
      "\n",
      "Can the Reflection pattern be applied more than once? Yes, reflection can be an iterative process. An agent can be made to reflect on its work multiple times, with each loop refining the output further. This is particularly useful for complex tasks where the first or second attempt may still contain subtle errors or could be substantially improved.  \n",
      "\n",
      "\n",
      "What is the Planning pattern in the context of AI agents? The Planning pattern involves enabling an agent to break down a complex, high- level goal into a sequence of smaller, actionable steps. Instead of trying to solve a big problem at once, the agent first creates a \"plan\" and then executes each step in the plan, which is a much more reliable approach.  \n",
      "\n",
      "\n",
      "Why is planning necessary for complex tasks? LLMs can struggle with tasks that require multiple steps or dependencies. Without a plan, an agent might lose track of the overall\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "objective, miss crucial steps, or fail to handle the output of one step as the input for the next. A plan provides a clear roadmap, ensuring all requirements of the original request are met in a logical order.  \n",
      "\n",
      "\n",
      "What is a common way to implement the Planning pattern? A common implementation is to have the agent first generate a list of steps in a structured format (like a JSON array or a numbered list). The system can then iterate through this list, executing each step one by one and feeding the result back to the agent to inform the next action.  \n",
      "\n",
      "\n",
      "How does the agent handle errors or changes during execution? A robust planning pattern allows for dynamic adjustments. If a step fails or the situation changes, the agent can be prompted to \"re- plan\" from the current state. It can analyze the error, modify the remaining steps, or even add new ones to overcome the obstacle.  \n",
      "\n",
      "\n",
      "Does the user see the plan? This is a design choice. In many cases, showing the plan to the user first for approval is a great practice. This aligns with the \"Human- in- the- Loop\" pattern, giving the user transparency and control over the agent's proposed actions before they are executed.  \n",
      "\n",
      "\n",
      "What does the \"Tool Use\" pattern entail? The Tool Use pattern allows an agent to extend its capabilities by interacting with external software or APIs. Since an LLM's knowledge is static and it can't perform real- world actions on its own, tools give it access to live information (e.g., Google Search), proprietary data (e.g., a company's database), or the ability to perform actions (e.g., send an email, book a meeting).  \n",
      "\n",
      "\n",
      "How does an agent decide which tool to use? The agent is typically given a list of available tools along with descriptions of what each tool does and what parameters it requires. When faced with a request it can't handle with its internal knowledge, the agent's reasoning ability allows it to select the most appropriate tool from the list to accomplish the task.  \n",
      "\n",
      "\n",
      "What is the \"ReAct\" (Reason and Act) framework mentioned in this context? ReAct is a popular framework that integrates reasoning and acting. The agent follows a loop of Thought (reasoning about what it needs to do), Action (deciding which tool to use and with what inputs), and Observation (seeing the result from the tool). This loop continues until it has gathered enough information to fulfill the user's request.  \n",
      "\n",
      "\n",
      "What are some challenges in implementing tool use? Key challenges include:  \n",
      "\n",
      "\n",
      "- Error Handling: Tools can fail, return unexpected data, or time out. The agent needs to be able to recognize these errors and decide whether to try again, use a different tool, or ask the user for help.- Security: Giving an agent access to tools, especially those that perform actions, has security implications. It's crucial to have safeguards, permissions, and often human approval for sensitive operations.- Prompting: The agent must be prompted effectively to generate correctly formatted tool calls (e.g., the right function name and parameters).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What is the Human- in- the- Loop (HITL) pattern? HITL is a pattern that integrates human oversight and interaction into the agent's workflow. Instead of being fully autonomous, the agent pauses at critical junctures to ask for human feedback, approval, clarification, or direction.  \n",
      "\n",
      "\n",
      "Why is HITL important for agentic systems? It's crucial for several reasons:  \n",
      "\n",
      "\n",
      "- Safety and Control: For high-stakes tasks (e.g., financial transactions, sending official communications), HITL ensures a human verifies the agent's proposed actions before they are executed.- Improving Quality: Humans can provide corrections or nuanced feedback that the agent can use to improve its performance, especially in subjective or ambiguous tasks.- Building Trust: Users are more likely to trust and adopt an AI system that they can guide and supervise.  \n",
      "\n",
      "\n",
      "At what points in a workflow should you include a human? Common points for human intervention include:  \n",
      "\n",
      "\n",
      "- Plan Approval: Before executing a multi-step plan.- Tool Use Confirmation: Before using a tool that has real-world consequences or costs money.- Ambiguity Resolution: When the agent is unsure how to proceed or needs more information from the user.- Final Output Review: Before delivering the final result to the end-user or system.  \n",
      "\n",
      "\n",
      "Isn't constant human intervention inefficient? It can be, which is why the key is to find the right balance. HITL should be implemented at critical checkpoints, not for every single action. The goal is to build a collaborative partnership between the human and the agent, where the agent handles the bulk of the work and the human provides strategic guidance.  \n",
      "\n",
      "\n",
      "What is the Multi- Agent Collaboration pattern? This pattern involves creating a system composed of multiple specialized agents that work together to achieve a common goal. Instead of one \"generalist\" agent trying to do everything, you create a team of \"specialist\" agents, each with a specific role or expertise.  \n",
      "\n",
      "\n",
      "## What are the benefits of a multi-agent system?  \n",
      "\n",
      "\n",
      "- Modularity and Specialization: Each agent can be fine-tuned and prompted for its specific task (e.g., a \"researcher\" agent, a \"writer\" agent, a \"code\" agent), leading to higher quality results.- Reduced Complexity: Breaking a complex workflow down into specialized roles makes the overall system easier to design, debug, and maintain.- Simulated Brainstorming: Different agents can offer different perspectives on a problem, leading to more creative and robust solutions, similar to how a human team works.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What is a common architecture for multi- agent systems? A common architecture involves an Orchestrator Agent (sometimes called a \"manager\" or \"conductor\"). The orchestrator understands the overall goal, breaks it down, and delegates sub- tasks to the appropriate specialist agents. It then collects the results from the specialists and synthesizes them into a final output.  \n",
      "\n",
      "\n",
      "How do the agents communicate with each other? Communication is often managed by the orchestrator. For example, the orchestrator might pass the output of the \"researcher\" agent to the \"writer\" agent as context. A shared \"scratchpad\" or message bus where agents can post their findings is another common communication method.  \n",
      "\n",
      "\n",
      "Why is evaluating an agent more difficult than evaluating a traditional software program? Traditional software has deterministic outputs (the same input always produces the same output). Agents, especially those using LLMs, are non- deterministic and their performance can be subjective. Evaluating them requires assessing the quality and relevance of their output, not just whether it's technically \"correct.\"  \n",
      "\n",
      "\n",
      "What are some common methods for evaluating agent performance? The guide suggests a few methods:  \n",
      "\n",
      "\n",
      "- Outcome-based Evaluation: Did the agent successfully achieve the final goal? For example, if the task was \"book a flight,\" was a flight actually booked correctly? This is the most important measure.- Process-based Evaluation: Was the agent's process efficient and logical? Did it use the right tools? Did it follow a sensible plan? This helps debug why an agent might be failing.- Human Evaluation: Having humans score the agent's performance on a scale (e.g., 1-5) based on criteria like helpfulness, accuracy, and coherence. This is crucial for user-facing applications.  \n",
      "\n",
      "\n",
      "What is an \"agent trajectory\"? An agent trajectory is the complete log of an agent's steps while performing a task. It includes all its thoughts, actions (tool calls), and observations. Analyzing these trajectories is a key part of debugging and understanding agent behavior.  \n",
      "\n",
      "\n",
      "How can you create reliable tests for a non- deterministic system? While you can't guarantee the exact wording of an agent's output, you can create tests that check for key elements. For example, you can write a test that verifies if the agent's final response contains specific information or if it successfully called a certain tool with the right parameters. This is often done using mock tools in a dedicated testing environment.  \n",
      "\n",
      "\n",
      "How is prompting an agent different from a simple ChatGPT prompt? Prompting an agent involves creating a detailed \"system prompt\" or constitution that acts as its operating instructions. This goes beyond a single user query; it defines the agent's role, its available tools, the patterns it should follow (like ReAct or Planning), its constraints, and its personality.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What are the key components of a good system prompt for an agent? A strong system prompt typically includes:  \n",
      "\n",
      "\n",
      "- Role and Goal: Clearly define who the agent is and what its primary purpose is.- Tool Definitions: A list of available tools, their descriptions, and how to use them (e.g., in a specific function-calling format).- Constraints and Rules: Explicit instructions on what the agent should not do (e.g., \"Do not use tools without approval,\" \"Do not provide financial advice\").- Process Instructions: Guidance on which patterns to use. For example, \"First, create a plan. Then, execute the plan step-by-step.\"- Example Trajectories: Providing a few examples of successful \"thought-action-observation\" loops can significantly improve the agent's reliability.  \n",
      "\n",
      "\n",
      "What is \"prompt leakage\"? Prompt leakage occurs when parts of the system prompt (like tool definitions or internal instructions) are inadvertently revealed in the agent's final response to the user. This can be confusing for the user and expose underlying implementation details. Techniques like using separate prompts for reasoning and for generating the final answer can help prevent this.  \n",
      "\n",
      "\n",
      "What are some future trends in agentic systems? The guide points towards a future with:  \n",
      "\n",
      "\n",
      "- More Autonomous Agents: Agents that require less human intervention and can learn and adapt on their own.- Highly Specialized Agents: An ecosystem of agents that can be hired or subscribed to for specific tasks (e.g., a travel agent, a research agent).- Better Tools and Platforms: The development of more sophisticated frameworks and platforms that make it easier to build, test, and deploy robust multi-agent systems.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Follow these rules at all times:\n",
      "\n",
      "  1. Human-Like Technical Questions (Top Priority)\n",
      "  Your questions must resemble what a real technical reader would ask, such as:\n",
      "\n",
      "    a developer trying to understand a concept\n",
      "    a student confused about a detail\n",
      "    an engineer trying to apply the idea in practice\n",
      "    a researcher checking nuances\n",
      "\n",
      "  Avoid:\n",
      "\n",
      "    exam-style phrasing (“What is the definition of …?”)\n",
      "    vague phrasing (“What is the primary goal…?”)\n",
      "    meta-referential phrasing (“According to the text…”)\n",
      "    generic, template-like questions\n",
      "\n",
      "  Prefer:\n",
      "\n",
      "    clarification questions\n",
      "    “why” and “how” technical questions\n",
      "    application-minded questions\n",
      "    requests for nuance\n",
      "    concrete scenario-based questions, if the text supports them\n",
      "\n",
      "  Example transformation\n",
      "\n",
      "  Bad:\n",
      "\n",
      "    “What does the passage say about zero-shot prompting?”\n",
      "\n",
      "  Good:\n",
      "\n",
      "    “When would zero-shot prompting be enough instead of adding examples?”\n",
      "\n",
      "  Bad:\n",
      "\n",
      "    “What is sentiment classification?”\n",
      "\n",
      "  Good:\n",
      "\n",
      "    “Why do we bother labeling reviews as positive, neutral, or negative — what does this help with?”\n",
      "\n",
      "  (But only if the text actually supports it.)\n",
      "\n",
      "  2. Strict Grounding in the Text\n",
      "\n",
      "    Answers must be fully supported by the passage.\n",
      "    Do not infer things that are not logically guaranteed by the text.\n",
      "    No outside knowledge or invented details.\n",
      "    If the passage cannot support the requested number of distinct questions, generate fewer — never hallucinate.\n",
      "\n",
      "  3. Depth & Diversity\n",
      "\n",
      "  Provide a balanced set of technical question types:\n",
      "\n",
      "    Explicit → directly stated in the text\n",
      "    Implicit → requires reading multiple lines and summarizing\n",
      "    Inference → requires logical follow-through fully supported by the text\n",
      "\n",
      "  Questions should vary across:\n",
      "\n",
      "    conceptual understanding\n",
      "    practical usage\n",
      "    subtle distinctions\n",
      "    causes or reasons\n",
      "    consequences or implications\n",
      "\n",
      "  4. Persona Alignment\n",
      "\n",
      "  Adopt the style, knowledge level, and motivation of the persona provided in the user message.\n",
      "\n",
      "  Examples:\n",
      "\n",
      "    A junior developer = simpler questions, more confusion\n",
      "    A senior engineer = deeper questions, curious about nuances\n",
      "    A researcher = more abstract or conceptual queries\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a17573a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate 10 question–answer pairs based on the following book passage.\n",
      "Assume the person asking the questions has the following persona: student.\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afd679",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = [\n",
    "     \"computer science student\", \n",
    "     \"Junior AI/ML Engineer\", \n",
    "     \"Senior AI/ML Engineer or Architect\",\n",
    "     \"Researcher in AI / Autonomous Systems\",\n",
    "     \"Product Manager (AI-focused)\",\n",
    "     \"Software Engineer Exploring AI Adoption\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dacd5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "    \n",
    "class QAList(BaseModel):\n",
    "    q_a_pairs: list[QuestionAnswer]\n",
    "    \n",
    "    \n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt\n",
    "        }\n",
    "    ],\n",
    "    text_format=QAList\n",
    ")\n",
    "\n",
    "qa_pairs = response.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68044fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is zero-shot prompting, and when should it be used?',\n",
       " \"Zero-shot prompting involves providing a prompt without any examples, relying solely on the model's pre-existing knowledge to generate a response. It is typically used when a user expects the model to understand and respond to a request without needing prior illustrations.\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pairs.q_a_pairs[0].question, qa_pairs.q_a_pairs[0].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e4eb72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
