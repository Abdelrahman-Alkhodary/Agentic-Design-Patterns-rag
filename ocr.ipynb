{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8510e6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "saving the Extracted images from the pdf:   3%|▎         | 14/482 [00:02<01:26,  5.40it/s]"
     ]
    }
   ],
   "source": [
    "from src.preprocessing.preprocess_ocr import preprocess_pdf_4_ocr\n",
    "\n",
    "pdf_path = './data/raw/Agentic_Design_Patterns.pdf'\n",
    "output_path = './data/raw'\n",
    "\n",
    "pdf_data = preprocess_pdf_4_ocr(\n",
    "    pdf_path=pdf_path,\n",
    "    out_dir=output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86714f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Some weights of DeepseekOCRForCausalLM were not initialized from the model checkpoint at deepseek-ai/DeepSeek-OCR and are newly initialized: ['model.vision_model.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "model_name = \"deepseek-ai/DeepSeek-OCR\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, cache_dir=\"./models/ocr/\")\n",
    "model = AutoModel.from_pretrained(model_name, _attn_implementation='flash_attention_2', trust_remote_code=True, use_safetensors=True, cache_dir=\"./models/ocr/\")\n",
    "model = model.eval().cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c737469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/raw/Agentic_Design_Patterns/page_0001.png')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff9bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"<image>\\nFree OCR. \"\n",
    "prompt = \"<image>\\n<|grounding|>Convert the document to markdown. \"\n",
    "image_file = pdf_data[0]\n",
    "output_path = './outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84960727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/anaconda3/envs/rag/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n",
      "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>sub_title<|/ref|><|det|>[[115, 105, 398, 129]]<|/det|>\n",
      "## Agentic Design Patterns  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 145, 625, 260]]<|/det|>\n",
      "A Hands- On Guide to Building Intelligent Systems', Antonio Gulli Table of Contents - total 424 pages \\(= 1 + 2 + 1 + 1 + 4 + 9 + 103 + 61 + 34 + 114 + 74 + 5 + 4\\) 11 Dedication, 1 page Acknowledgment, 2 pages [final, last read done] Foreword, 1 page [final, last read done] A Thought Leader's Perspective: Power and Responsibility [final, last read done] Introduction, 4 pages [final, last read done] What makes an AI system an \"agent\"? 9 pages [final, last read done]  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 273, 293, 288]]<|/det|>\n",
      "Part One, (Total: 103 pages)  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[144, 288, 647, 388]]<|/det|>\n",
      "1. Chapter 1: Prompt Chaining (code), 12 pages [final, last read done, code ok]  \n",
      "2. Chapter 2: Routing (code), 13 pages [final, last read done, code ok]  \n",
      "3. Chapter 3: Parallelization (code), 15 pages [final, last read done, code ok]  \n",
      "4. Chapter 4: Reflection (code), 13 pages [final, last read done, code ok]  \n",
      "5. Chapter 5: Tool Use (code), 20 pages [final, last read done, code ok]  \n",
      "6. Chapter 6: Planning (code), 13 pages [final, last read done, code ok]  \n",
      "7. Chapter 7: Multi-Agent (code), 17 pages [final, last read done, code ok], 121  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 401, 280, 415]]<|/det|>\n",
      "Part Two (Total: 61 pages)  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[144, 415, 745, 472]]<|/det|>\n",
      "8. Chapter 8: Memory Management (code), 21 pages [final, last read done, code ok]  \n",
      "9. Chapter 9: Learning and Adaptation (code), 12 pages [final, last read done, code ok]  \n",
      "10. Chapter 10: Model Context Protocol (MCP) (code), 16 pages [final, last read done, code ok]  \n",
      "11. Chapter 11: Goal Setting and Monitoring (code), 12 pages [final, last read done, code ok], 182  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 486, 290, 500]]<|/det|>\n",
      "Part Three (Total: 34 pages)  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[144, 500, 756, 544]]<|/det|>\n",
      "12. Chapter 12: Exception Handling and Recovery (code), 8 pages [final, last read done, code ok]  \n",
      "13. Chapter 13: Human-in-the-Loop (code), 9 pages [final, last read done, code ok]  \n",
      "14. Chapter 14: Knowledge Retrieval (RAG) (code), 17 pages [final, last read done, code ok], 216  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 558, 290, 572]]<|/det|>\n",
      "Part Four (Total: 114 pages)  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[144, 572, 758, 671]]<|/det|>\n",
      "15. Chapter 15: Inter-Agent Communication (A2A) (code), 15 pages [final, last read done, code ok]  \n",
      "16. Chapter 16: Resource-Aware Optimization (code), 15 pages [final, last read done, code ok]  \n",
      "17. Chapter 17: Reasoning Techniques (code), 24 pages [final, last read done, code ok]  \n",
      "18. Chapter 18: Guardrails/Safety Patterns (code), 19 pages [final, last read done, code ok]  \n",
      "19. Chapter 19: Evaluation and Monitoring (code), 18 pages [final, last read done, code ok]  \n",
      "20. Chapter 20: Prioritization (code), 10 pages [final, last read done, code ok]  \n",
      "21. Chapter 21: Exploration and Discovery (code), 13 pages [final, last read done, code ok], 330  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 685, 283, 699]]<|/det|>\n",
      "Appendix (Total: 74 pages)  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[144, 699, 825, 792]]<|/det|>\n",
      "22. Appendix A: Advanced Prompting Techniques, 28 pages [final, last read done, code ok]  \n",
      "23. Appendix B - AI Agentic ...: From GUI to Real world environment, 6 pages [final, last read done, code ok]  \n",
      "24. Appendix C - Quick overview of Agentic Frameworks, 8 pages [final, last read done, code ok],  \n",
      "25. Appendix D - Building an Agent with AgentSpace (on-line only), 6 pages [final, last read done, code ok]  \n",
      "26. Appendix E - AI Agents on the CLI (online), 5 pages [final, last read done, code ok]  \n",
      "27. Appendix F - Under the Hood: An Inside Look at the Agents' Reasoning Engines, 14 pages [final, lrd, code ok],  \n",
      "28. Appendix G - Coding agents, 7 pages 406  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 797, 360, 810]]<|/det|>\n",
      "Conclusion, 5 pages [final, last read done]  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 811, 365, 825]]<|/det|>\n",
      "Glossary, 4 pages [final, last read done]  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 826, 785, 855]]<|/det|>\n",
      "Index of Terms, 11 pages (Generated by Gemini. Reasoning step included as an agentic example) [final, lrd] Online contribution - Frequently Asked Questions: Agentic Design Patterns  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 856, 736, 870]]<|/det|>\n",
      "Pre Print: https://www.amazon.com/Agentic- Design- Patterns- Hands- Intelligent/dp/3032014018/\n",
      "==================================================\n",
      "image size:  (2550, 3301)\n",
      "valid image tokens:  797\n",
      "output texts tokens (valid):  1334\n",
      "compression ratio:  1.67\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 16/16 [00:00<00:00, 206488.81it/s]\n"
     ]
    }
   ],
   "source": [
    "res = model.infer(\n",
    "    tokenizer,\n",
    "    prompt=prompt, \n",
    "    image_file=image_file, \n",
    "    output_path=output_path, \n",
    "    base_size=1024, \n",
    "    image_size=640, \n",
    "    crop_mode=True, \n",
    "    save_results=True, \n",
    "    test_compress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78456370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/anaconda3/envs/rag/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>sub_title<|/ref|><|det|>[[115, 105, 398, 129]]<|/det|>\n",
      "## Agentic Design Patterns  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 145, 625, 260]]<|/det|>\n",
      "A Hands- On Guide to Building Intelligent Systems', Antonio Gulli Table of Contents - total 424 pages \\(= 1 + 2 + 1 + 1 + 4 + 9 + 103 + 61 + 34 + 114 + 74 + 5 + 4\\) 11 Dedication, 1 page Acknowledgment, 2 pages [final, last read done] Foreword, 1 page [final, last read done] A Thought Leader's Perspective: Power and Responsibility [final, last read done] Introduction, 4 pages [final, last read done] What makes an AI system an \"agent\"? 9 pages [final, last read done]  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 273, 293, 288]]<|/det|>\n",
      "Part One, (Total: 103 pages)  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[144, 288, 647, 388]]<|/det|>\n",
      "1. Chapter 1: Prompt Chaining (code), 12 pages [final, last read done, code ok]  \n",
      "2. Chapter 2: Routing (code), 13 pages [final, last read done, code ok]  \n",
      "3. Chapter 3: Parallelization (code), 15 pages [final, last read done, code ok]  \n",
      "4. Chapter 4: Reflection (code), 13 pages [final, last read done, code ok]  \n",
      "5. Chapter 5: Tool Use (code), 20 pages [final, last read done, code ok]  \n",
      "6. Chapter 6: Planning (code), 13 pages [final, last read done, code ok]  \n",
      "7. Chapter 7: Multi-Agent (code), 17 pages [final, last read done, code ok], 121  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 401, 280, 415]]<|/det|>\n",
      "Part Two (Total: 61 pages)  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[144, 415, 745, 472]]<|/det|>\n",
      "8. Chapter 8: Memory Management (code), 21 pages [final, last read done, code ok]  \n",
      "9. Chapter 9: Learning and Adaptation (code), 12 pages [final, last read done, code ok]  \n",
      "10. Chapter 10: Model Context Protocol (MCP) (code), 16 pages [final, last read done, code ok]  \n",
      "11. Chapter 11: Goal Setting and Monitoring (code), 12 pages [final, last read done, code ok], 182  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 486, 290, 500]]<|/det|>\n",
      "Part Three (Total: 34 pages)  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[144, 500, 756, 544]]<|/det|>\n",
      "12. Chapter 12: Exception Handling and Recovery (code), 8 pages [final, last read done, code ok]  \n",
      "13. Chapter 13: Human-in-the-Loop (code), 9 pages [final, last read done, code ok]  \n",
      "14. Chapter 14: Knowledge Retrieval (RAG) (code), 17 pages [final, last read done, code ok], 216  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 558, 290, 572]]<|/det|>\n",
      "Part Four (Total: 114 pages)  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[144, 572, 758, 671]]<|/det|>\n",
      "15. Chapter 15: Inter-Agent Communication (A2A) (code), 15 pages [final, last read done, code ok]  \n",
      "16. Chapter 16: Resource-Aware Optimization (code), 15 pages [final, last read done, code ok]  \n",
      "17. Chapter 17: Reasoning Techniques (code), 24 pages [final, last read done, code ok]  \n",
      "18. Chapter 18: Guardrails/Safety Patterns (code), 19 pages [final, last read done, code ok]  \n",
      "19. Chapter 19: Evaluation and Monitoring (code), 18 pages [final, last read done, code ok]  \n",
      "20. Chapter 20: Prioritization (code), 10 pages [final, last read done, code ok]  \n",
      "21. Chapter 21: Exploration and Discovery (code), 13 pages [final, last read done, code ok], 330  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 685, 283, 699]]<|/det|>\n",
      "Appendix (Total: 74 pages)  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[144, 699, 825, 792]]<|/det|>\n",
      "22. Appendix A: Advanced Prompting Techniques, 28 pages [final, last read done, code ok]  \n",
      "23. Appendix B - AI Agentic ...: From GUI to Real world environment, 6 pages [final, last read done, code ok]  \n",
      "24. Appendix C - Quick overview of Agentic Frameworks, 8 pages [final, last read done, code ok],  \n",
      "25. Appendix D - Building an Agent with AgentSpace (on-line only), 6 pages [final, last read done, code ok]  \n",
      "26. Appendix E - AI Agents on the CLI (online), 5 pages [final, last read done, code ok]  \n",
      "27. Appendix F - Under the Hood: An Inside Look at the Agents' Reasoning Engines, 14 pages [final, lrd, code ok],  \n",
      "28. Appendix G - Coding agents, 7 pages 406  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 797, 360, 810]]<|/det|>\n",
      "Conclusion, 5 pages [final, last read done]  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 811, 365, 825]]<|/det|>\n",
      "Glossary, 4 pages [final, last read done]  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 826, 785, 855]]<|/det|>\n",
      "Index of Terms, 11 pages (Generated by Gemini. Reasoning step included as an agentic example) [final, lrd] Online contribution - Frequently Asked Questions: Agentic Design Patterns  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 856, 736, 870]]<|/det|>\n",
      "Pre Print: https://www.amazon.com/Agentic- Design- Patterns- Hands- Intelligent/dp/3032014018/\n",
      "==================================================\n",
      "image size:  (2550, 3301)\n",
      "valid image tokens:  797\n",
      "output texts tokens (valid):  1334\n",
      "compression ratio:  1.67\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 16/16 [00:00<00:00, 199136.09it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>image<|/ref|><|det|>[[111, 103, 888, 655]]<|/det|>\n",
      "==================================================\n",
      "image size:  (2550, 3301)\n",
      "valid image tokens:  797\n",
      "output texts tokens (valid):  18\n",
      "compression ratio:  0.02\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 100%|██████████| 1/1 [00:00<00:00, 26214.40it/s]\n",
      "other: 0it [00:00, ?it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>text<|/ref|><|det|>[[116, 105, 261, 121]]<|/det|>\n",
      "To my son, Bruno,  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 137, 872, 174]]<|/det|>\n",
      "who at two years old, brought a new and brilliant light into my life. As I explore the systems that will define our tomorrow, it is the world you will inherit that is foremost in my thoughts.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[116, 189, 606, 207]]<|/det|>\n",
      "To my sons, Leonardo and Lorenzo, and my daughter Aurora,  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 222, 867, 259]]<|/det|>\n",
      "My heart is filled with pride for the women and men you have become and the wonderful world you are building.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 274, 877, 348]]<|/det|>\n",
      "This book is about how to build intelligent tools, but it is dedicated to the profound hope that your generation will guide them with wisdom and compassion. The future is incredibly bright, for you and for us all, if we learn to use these powerful technologies to serve humanity and help it progress.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[116, 363, 247, 380]]<|/det|>\n",
      "With all my love.\n",
      "==================================================\n",
      "image size:  (2550, 3301)\n",
      "valid image tokens:  797\n",
      "output texts tokens (valid):  259\n",
      "compression ratio:  0.32\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 6/6 [00:00<00:00, 193583.26it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>sub_title<|/ref|><|det|>[[115, 108, 442, 142]]<|/det|>\n",
      "## Acknowledgment  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 162, 839, 201]]<|/det|>\n",
      "I would like to express my sincere gratitude to the many individuals and teams who made this book possible.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 217, 850, 257]]<|/det|>\n",
      "First and foremost, I thank Google for adhering to its mission, empowering Googlers, and respecting the opportunity to innovate.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 272, 848, 333]]<|/det|>\n",
      "I am grateful to the Office of the CTO for giving me the opportunity to explore new areas, for adhering to its mission of \"practical magic,\" and for its capacity to adapt to new emerging opportunities.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 347, 880, 528]]<|/det|>\n",
      "I would like to extend my heartfelt thanks to Will Grannis, our VP, for the trust he puts in people and for being a servant leader. To John Abel, my manager, for encouraging me to pursue my activities and for always providing great guidance with his British acumen.I extend my gratitude to Antoine Larmanjat for our work on LLMs in code, Hann Hann Wang for agent discussions, and Yingchao Huang for time series insights. Thanks to Ashwin Ram for leadership, Massy Mascaro for inspiring work, Jennifer Bennett for technical expertise, Brett Slatkin for engineering, and Eric Schen for stimulating discussions. The OCTO team, especially Scott Penberthy, deserves recognition. Finally, deep appreciation to Patricia Florissi for her inspiring vision of Agents' societal impact.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 543, 880, 622]]<|/det|>\n",
      "My appreciation also goes to Marco Argenti for the challenging and motivating vision of agents augmenting the human workforce. My thanks also go to Jim Lanzone and Jordi Ribas for pushing the bar on the relationship between the world of Search and the world of Agents.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 638, 872, 819]]<|/det|>\n",
      "I am also indebted to the Cloud AI teams, especially their leader Saurabh Tiwary, for driving the AI organization towards principled progress. Thank you to Salem Salem Haykal, the Area Technical Leader, for being an inspiring colleague. My thanks to Vladimir Vuskovic, co- founder of Google Agentspace, Kate (Katarzyna) Olszewska for our Agentic collaboration on Kaggle Game Arena, and Nate Keating for driving Kaggle with passion, a community that has given so much to AI. My thanks also to Kamelia Aryafa, leading applied AI and ML teams focused on Agentspace and Enterprise NotebookLM, and to Jahn Wooland, a true leader focused on delivering and a personal friend always there to provide advice.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 834, 875, 874]]<|/det|>\n",
      "A special thanks to Yingchao Huang for being a brilliant AI engineer with a great career in front of you, Hann Wang for challenging me to return to my interest in Agents after an\n",
      "==================================================\n",
      "image size:  (2550, 3301)\n",
      "valid image tokens:  797\n",
      "output texts tokens (valid):  652\n",
      "compression ratio:  0.82\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 8/8 [00:00<00:00, 170327.07it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>text<|/ref|><|det|>[[115, 89, 782, 129]]<|/det|>\n",
      "initial interest in 1994, and to Lee Boonstra for your amazing work on prompt engineering.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 143, 870, 203]]<|/det|>\n",
      "My thanks also go to the 5 Days of GenAI team, including our VP Alison Wagonfeld for the trust put in the team, Anant Nawalgaria for always delivering, and Paige Bailey for her can- do attitude and leadership.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 219, 879, 258]]<|/det|>\n",
      "I am also deeply grateful to Mike Styer, Turan Bulmus, and Kanchana Patlolla for helping me ship three Agents at Google I/O 2025. Thank you for your immense work.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 273, 875, 374]]<|/det|>\n",
      "I want to express my sincere gratitude to Thomas Kurian for his unwavering leadership, passion, and trust in driving the Cloud and AI initiatives. I also deeply appreciate Emanuel Taropa, whose inspiring \"can- do\" attitude made him the most exceptional colleague I've encountered at Google, setting a truly profound example. Finally, thanks to Fiona Cicconi for our engaging discussions about Google.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 388, 877, 488]]<|/det|>\n",
      "I extend my gratitude to Demis Hassabis, Pushmeet Kohli, and the entire GDM team for their passionate efforts in developing Gemini, AlphaFold, AlphaGo, and AlphaGenome, among other projects, and for their contributions to advancing science for the benefit of society. A special thank you to Yossi Matias for his leadership of Google Research and for consistently offering invaluable advice. I have learned a great deal from you.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 504, 872, 584]]<|/det|>\n",
      "A special thanks to Patti Maes, who pioneered the concept of Software Agents in the 90s and remains focused on the question of how computer systems and digital devices might augment people and assist them with issues such as memory, learning, decision making, health, and wellbeing. Your vision back in '91 became a reality today.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 599, 812, 639]]<|/det|>\n",
      "I also want to extend my gratitude to Paul Drougas and all the Publisher team at Springer for making this book possible.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 654, 881, 875]]<|/det|>\n",
      "I am deeply indebted to the many talented people who helped bring this book to life. My heartfelt thanks go to Marco Fago for his immense contributions, from code and diagrams to reviewing the entire text. I'm also grateful to Mahtab Syed for his coding work and to Ankita Guha for her incredibly detailed feedback on so many chapters. The book was significantly improved by the insightful amendments from Priya Saxena, the careful reviews from Jae Lee, and the dedicated work of Mario da Roza in creating the NotebookLM version. I was fortunate to have a team of expert reviewers for the initial chapters, and I thank Dr. Amita Kapoor, Fatma Tarlaci, PhD, Dr. Alessandro Cornacchia, and Aditya Mandlekar for lending their expertise. My sincere appreciation also goes to Ashley Miller, A Amir John, and Palak Kamdar (Vasani) for their unique contributions. For their steadfast support and encouragement, a final, warm thank you is due to Rajat\n",
      "==================================================\n",
      "image size:  (2550, 3301)\n",
      "valid image tokens:  797\n",
      "output texts tokens (valid):  733\n",
      "compression ratio:  0.92\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 8/8 [00:00<00:00, 106861.25it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>text<|/ref|><|det|>[[115, 88, 857, 128]]<|/det|>\n",
      "Jain, Aldo Pahor, Gaurav Verma, Pavithra Sainath, Mariusz Koczwara, Abhijit Kumar, Armstrong Foundjem, Haiming Ran, Udita Patel, and Kaurnakar Kotha.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 144, 861, 183]]<|/det|>\n",
      "This project truly would not have been possible without you. All the credit goes to you, and all the mistakes are mine.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[172, 199, 606, 218]]<|/det|>\n",
      "All my royalties are donated to Save the Children.\n",
      "==================================================\n",
      "image size:  (2550, 3301)\n",
      "valid image tokens:  797\n",
      "output texts tokens (valid):  146\n",
      "compression ratio:  0.18\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 3/3 [00:00<00:00, 107546.26it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>sub_title<|/ref|><|det|>[[116, 116, 255, 142]]<|/det|>\n",
      "## Foreword  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 172, 872, 269]]<|/det|>\n",
      "The field of artificial intelligence is at a fascinating inflection point. We are moving beyond building models that can simply process information to creating intelligent systems that can reason, plan, and act to achieve complex goals with ambiguous tasks. These \"agentic\" systems, as this book so aptly describes them, represent the next frontier in AI, and their development is a challenge that excites and inspires us at Google.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 287, 880, 422]]<|/det|>\n",
      "\"Agentic Design Patterns: A Hands- On Guide to Building Intelligent Systems\" arrives at the perfect moment to guide us on this journey. The book rightly points out that the power of large language models, the cognitive engines of these agents, must be harnessed with structure and thoughtful design. Just as design patterns revolutionized software engineering by providing a common language and reusable solutions to common problems, the agentic patterns in this book will be foundational for building robust, scalable, and reliable intelligent systems.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 440, 866, 576]]<|/det|>\n",
      "The metaphor of a \"canvas\" for building agentic systems is one that resonates deeply with our work on Google's Vertex AI platform. We strive to provide developers with the most powerful and flexible canvas on which to build the next generation of AI applications. This book provides the practical, hands- on guidance that will empower developers to use that canvas to its full potential. By exploring patterns from prompt chaining and tool use to agent- to- agent collaboration, self- correction, safety and guardrails, this book offers a comprehensive toolkit for any developer looking to build sophisticated AI agents.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 594, 870, 671]]<|/det|>\n",
      "The future of AI will be defined by the creativity and ingenuity of developers who can build these intelligent systems. \"Agentic Design Patterns\" is an indispensable resource that will help to unlock that creativity. It provides the essential knowledge and practical examples to not only understand the \"what\" and \"why\" of agentic systems, but also the \"how.\"  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 696, 880, 753]]<|/det|>\n",
      "I am thrilled to see this book in the hands of the developer community. The patterns and principles within these pages will undoubtedly accelerate the development of innovative and impactful AI applications that will shape our world for years to come.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[108, 778, 472, 819]]<|/det|>\n",
      "Saurabh Tiwary  VP & General Manager, CloudAI @ Google\n",
      "==================================================\n",
      "image size:  (2550, 3301)\n",
      "valid image tokens:  797\n",
      "output texts tokens (valid):  561\n",
      "compression ratio:  0.7\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 7/7 [00:00<00:00, 145347.17it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>sub_title<|/ref|><|det|>[[115, 91, 865, 172]]<|/det|>\n",
      "## A Thought Leader's Perspective: Power and Responsibility  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 196, 881, 362]]<|/det|>\n",
      "Of all the technology cycles I've witnessed over the past four decades—from the birth of the personal computer and the web, to the revolutions in mobile and cloud—none has felt quite like this one. For years, the discourse around Artificial Intelligence was a familiar rhythm of hype and disillusionment, the so- called \"AI summers\" followed by long, cold winters. But this time, something is different. The conversation has palpably shifted. If the last eighteen months were about the engine—the breathtaking, almost vertical ascent of Large Language Models (LLMs)—the next era will be about the car we build around it. It will be about the frameworks that harness this raw power, transforming it from a generator of plausible text into a true agent of action.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 380, 879, 490]]<|/det|>\n",
      "I admit, I began as a skeptic. Plausibility, I've found, is often inversely proportional to one's own knowledge of a subject. Early models, for all their fluency, felt like they were operating with a kind of impostor syndrome, optimized for credibility over correctness. But then came the inflection point, a step- change brought about by a new class of \"reasoning\" models. Suddenly, we weren't just conversing with a statistical machine that predicted the next word in a sequence; we were getting a peek into a nascent form of cognition.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 508, 880, 637]]<|/det|>\n",
      "The first time I experimented with one of the new agentic coding tools, I felt that familiar spark of magic. I tasked it with a personal project I'd never found the time for: migrating a charity website from a simple web builder to a proper, modern CI/CD environment. For the next twenty minutes, it went to work, asking clarifying questions, requesting credentials, and providing status updates. It felt less like using a tool and more like collaborating with a junior developer. When it presented me with a fully deployable package, complete with impeccable documentation and unit tests, I was floored.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 656, 878, 784]]<|/det|>\n",
      "Of course, it wasn't perfect. It made mistakes. It got stuck. It required my supervision and, crucially, my judgment to steer it back on course. The experience drove home a lesson I've learned the hard way over a long career: you cannot afford to trust blindly. Yet, the process was fascinating. Peeking into its \"chain of thought\" was like watching a mind at work—messy, non- linear, full of starts, stops, and self- corrections, not unlike our own human reasoning. It wasn't a straight line; it was a random walk toward a solution. Here was the kernel of something new: not just an intelligence that could generate content, but one that could generate a plan.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 803, 877, 895]]<|/det|>\n",
      "This is the promise of agentic frameworks. It's the difference between a static subway map and a dynamic GPS that reroutes you in real- time. A classic rules- based automaton follows a fixed path; when it encounters an unexpected obstacle, it breaks. An AI agent, powered by a reasoning model, has the potential to observe, adapt, and find another way. It possesses a form of digital common sense that allows it to navigate the countless edge cases of reality. It\n",
      "==================================================\n",
      "image size:  (2550, 3301)\n",
      "valid image tokens:  797\n",
      "output texts tokens (valid):  756\n",
      "compression ratio:  0.95\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 6/6 [00:00<00:00, 99469.66it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>text<|/ref|><|det|>[[115, 89, 808, 125]]<|/det|>\n",
      "represents a shift from simply telling a computer what to do, to explaining why we need something done and trusting it to figure out the how.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 143, 874, 290]]<|/det|>\n",
      "As exhilarating as this new frontier is, it brings a profound sense of responsibility, particularly from my vantage point as the CIO of a global financial institution. The stakes are immeasurably high. An agent that makes a mistake while creating a recipe for a \"Chicken Salmon Fusion Pie\" is a fun anecdote. An agent that makes a mistake while executing a trade, managing risk, or handling client data is a real problem. I've read the disclaimers and the cautionary tales: the web automation agent that, after failing a login, decided to email a member of parliament to complain about login walls. It's a darkly humorous reminder that we are dealing with a technology we don't fully understand.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 309, 876, 418]]<|/det|>\n",
      "This is where craft, culture, and a relentless focus on our principles become our essential guide. Our Engineering Tenets are not just words on a page; they are our compass. We must Build with Purpose, ensuring that every agent we design starts from a clear understanding of the client problem we are solving. We must Look Around Corners, anticipating failure modes and designing systems that are resilient by design. And above all, we must Inspire Trust, by being transparent about our methods and accountable for our outcomes.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[114, 437, 881, 601]]<|/det|>\n",
      "In an agentic world, these tenets take on new urgency. The hard truth is that you cannot simply overlay these powerful new tools onto messy, inconsistent systems and expect good results. Messy systems plus agents are a recipe for disaster. An AI trained on \"garbage\" data doesn't just produce garbage- out; it produces plausible, confident garbage that can poison an entire process. Therefore, our first and most critical task is to prepare the ground. We must invest in clean data, consistent metadata, and well- defined APIs. We have to build the modern \"interstate system\" that allows these agents to operate safely and at high velocity. It is the hard, foundational work of building a programmable enterprise, an \"enterprise as software,\" where our processes are as well- architected as our code.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 620, 879, 730]]<|/det|>\n",
      "Ultimately, this journey is not about replacing human ingenuity, but about augmenting it. It demands a new set of skills from all of us: the ability to explain a task with clarity, the wisdom to delegate, and the diligence to verify the quality of the output. It requires us to be humble, to acknowledge what we don't know, and to never stop learning. The pages that follow in this book offer a technical map for building these new frameworks. My hope is that you will use them not just to build what is possible, but to build what is right, what is robust, and what is responsible.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 749, 852, 766]]<|/det|>\n",
      "The world is asking every engineer to step up. I am confident we are ready for the challenge.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[116, 787, 258, 804]]<|/det|>\n",
      "Enjoy the journey.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[116, 823, 410, 840]]<|/det|>\n",
      "Marco Argenti, CIO, Goldman Sachs\n",
      "==================================================\n",
      "image size:  (2550, 3301)\n",
      "valid image tokens:  797\n",
      "output texts tokens (valid):  747\n",
      "compression ratio:  0.94\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 8/8 [00:00<00:00, 162098.71it/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "BASE:  torch.Size([1, 256, 1280])\n",
      "PATCHES:  torch.Size([6, 100, 1280])\n",
      "=====================\n",
      "<|ref|>sub_title<|/ref|><|det|>[[116, 107, 230, 133]]<|/det|>\n",
      "## Preface  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 152, 861, 272]]<|/det|>\n",
      "Welcome to \"Agentic Design Patterns: A Hands- On Guide to Building Intelligent Systems.\" As we look across the landscape of modern artificial intelligence, we see a clear evolution from simple, reactive programs to sophisticated, autonomous entities capable of understanding context, making decisions, and interacting dynamically with their environment and other systems. These are the intelligent agents and the agentic systems they comprise.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 287, 875, 407]]<|/det|>\n",
      "The advent of powerful large language models (LLMs) has provided unprecedented capabilities for understanding and generating human- like content such as text and media, serving as the cognitive engine for many of these agents. However, orchestrating these capabilities into systems that can reliably achieve complex goals requires more than just a powerful model. It requires structure, design, and a thoughtful approach to how the agent perceives, plans, acts, and interacts.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 422, 880, 522]]<|/det|>\n",
      "Think of building intelligent systems as creating a complex work of art or engineering on a canvas. This canvas isn't a blank visual space, but rather the underlying infrastructure and frameworks that provide the environment and tools for your agents to exist and operate. It's the foundation upon which you'll build your intelligent application, managing state, communication, tool access, and the flow of logic.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 537, 870, 658]]<|/det|>\n",
      "Building effectively on this agentic canvas demands more than just throwing components together. It requires understanding proven techniques - patterns - that address common challenges in designing and implementing agent behavior. Just as architectural patterns guide the construction of a building, or design patterns structure software, agentic design patterns provide reusable solutions for the recurring problems you'll face when bringing intelligent agents to life on your chosen canvas.  \n",
      "\n",
      "<|ref|>sub_title<|/ref|><|det|>[[115, 675, 520, 704]]<|/det|>\n",
      "## What are Agentic Systems?  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 721, 863, 821]]<|/det|>\n",
      "At its core, an agentic system is a computational entity designed to perceive its environment (both digital and potentially physical), make informed decisions based on those perceptions and a set of predefined or learned goals, and execute actions to achieve those goals autonomously. Unlike traditional software, which follows rigid, step- by- step instructions, agents exhibit a degree of flexibility and initiative.  \n",
      "\n",
      "<|ref|>text<|/ref|><|det|>[[115, 837, 857, 896]]<|/det|>\n",
      "Imagine you need a system to manage customer inquiries. A traditional system might follow a fixed script. An agentic system, however, could perceive the nuances of a customer's query, access knowledge bases, interact with other internal systems (like\n",
      "==================================================\n",
      "image size:  (2550, 3301)\n",
      "valid image tokens:  797\n",
      "output texts tokens (valid):  595\n",
      "compression ratio:  0.75\n",
      "==================================================\n",
      "===============save results:===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image: 0it [00:00, ?it/s]\n",
      "other: 100%|██████████| 8/8 [00:00<00:00, 106861.25it/s]\n"
     ]
    }
   ],
   "source": [
    "for img in pdf_data[:10]:\n",
    "    # prompt = \"<image>\\nFree OCR. \"\n",
    "    prompt = \"<image>\\n<|grounding|>Convert the document to markdown. \"\n",
    "    image_file = img\n",
    "    output_path = './outputs/' + str(img)\n",
    "\n",
    "    res = model.infer(\n",
    "        tokenizer,\n",
    "        prompt=prompt, \n",
    "        image_file=image_file, \n",
    "        output_path=output_path, \n",
    "        base_size=1024, \n",
    "        image_size=640, \n",
    "        crop_mode=True, \n",
    "        save_results=True, \n",
    "        test_compress=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caa7aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = os.path.join(output_path, \"result.mmd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46c499e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./outputs/data/raw/Agentic_Design_Patterns/page_0010.png/result.mmd'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb9556fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Preface  \n",
      "\n",
      "\n",
      "Welcome to \"Agentic Design Patterns: A Hands- On Guide to Building Intelligent Systems.\" As we look across the landscape of modern artificial intelligence, we see a clear evolution from simple, reactive programs to sophisticated, autonomous entities capable of understanding context, making decisions, and interacting dynamically with their environment and other systems. These are the intelligent agents and the agentic systems they comprise.  \n",
      "\n",
      "\n",
      "The advent of powerful large language models (LLMs) has provided unprecedented capabilities for understanding and generating human- like content such as text and media, serving as the cognitive engine for many of these agents. However, orchestrating these capabilities into systems that can reliably achieve complex goals requires more than just a powerful model. It requires structure, design, and a thoughtful approach to how the agent perceives, plans, acts, and interacts.  \n",
      "\n",
      "\n",
      "Think of building intelligent systems as creating a complex work of art or engineering on a canvas. This canvas isn't a blank visual space, but rather the underlying infrastructure and frameworks that provide the environment and tools for your agents to exist and operate. It's the foundation upon which you'll build your intelligent application, managing state, communication, tool access, and the flow of logic.  \n",
      "\n",
      "\n",
      "Building effectively on this agentic canvas demands more than just throwing components together. It requires understanding proven techniques - patterns - that address common challenges in designing and implementing agent behavior. Just as architectural patterns guide the construction of a building, or design patterns structure software, agentic design patterns provide reusable solutions for the recurring problems you'll face when bringing intelligent agents to life on your chosen canvas.  \n",
      "\n",
      "\n",
      "## What are Agentic Systems?  \n",
      "\n",
      "\n",
      "At its core, an agentic system is a computational entity designed to perceive its environment (both digital and potentially physical), make informed decisions based on those perceptions and a set of predefined or learned goals, and execute actions to achieve those goals autonomously. Unlike traditional software, which follows rigid, step- by- step instructions, agents exhibit a degree of flexibility and initiative.  \n",
      "\n",
      "\n",
      "Imagine you need a system to manage customer inquiries. A traditional system might follow a fixed script. An agentic system, however, could perceive the nuances of a customer's query, access knowledge bases, interact with other internal systems (like\n"
     ]
    }
   ],
   "source": [
    "# 'utf-8' encoding is important to correctly handle emojis or special characters often found in OCR output\n",
    "with open(result_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5ba82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
